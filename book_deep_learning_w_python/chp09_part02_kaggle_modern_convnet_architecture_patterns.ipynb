{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MXdVmjkvRka"
   },
   "source": [
    "# Chp 9.2 Case where the target block changes the number of output filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oT35bnpvRkk"
   },
   "source": [
    "**Case where the target block changes the number of output filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wDbFkK2KvRkl"
   },
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# inputs = keras.Input(shape=(32, 32, 3))\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "# residual = x\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "# residual = layers.Conv2D(64, 1)(residual)\n",
    "# x = layers.add([x, residual])\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCjvd4atvRkm"
   },
   "source": [
    "**Case where the target block includes a max pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4uyTWcSMvRko"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 15, 15, 64), dtype=tf.float32, name=None), name='add_4/add:0', description=\"created by layer 'add_4'\")\n"
     ]
    }
   ],
   "source": [
    "# inputs = keras.Input(shape=(32, 32, 3))\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "# residual = x\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "# x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "# residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
    "# x = layers.add([x, residual])\n",
    "\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVFhnkn-vRkp",
    "outputId": "78700974-54c3-4f84-ca98-a85347b79136"
   },
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=(32, 32, 3))\n",
    "# x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "\n",
    "# def residual_block(x, filters, pooling=False):\n",
    "#     residual = x\n",
    "#     x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "#     if pooling:\n",
    "#         x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "#         residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "#     elif filters != residual.shape[-1]:\n",
    "#         residual = layers.Conv2D(filters, 1)(residual)\n",
    "#     x = layers.add([x, residual])\n",
    "#     return x\n",
    "\n",
    "# x = residual_block(x, filters=32, pooling=True)\n",
    "# x = residual_block(x, filters=64, pooling=True)\n",
    "# x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLxya4g0vRkq"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfe-yr2UvRkr"
   },
   "source": [
    "### Depthwise separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwsjBphevRkr"
   },
   "source": [
    "### Putting it together: a mini Xception-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQRqQhp6vRkv",
    "outputId": "b85e4288-947a-4ddf-b867-b89156807652"
   },
   "outputs": [],
   "source": [
    "!rm -fr chp09_convnet\n",
    "\n",
    "def init_datadir():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "\n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "     \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats --path ./chp09_convnet/src\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        #!unzip -qq train.zip\n",
    "        !unzip -qq ./chp09_convnet/src/train.zip -d ./chp09_convnet/data\n",
    "\n",
    "    print(\"Finished downloading data..\")\n",
    "\n",
    "\n",
    "def listing9_3_5():\n",
    "    import os, shutil, pathlib\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "    # download data\n",
    "    init_datadir()\n",
    "\n",
    "    original_dir = pathlib.Path(\"chp09_convnet/data/train\")\n",
    "    new_base_dir = pathlib.Path(\"chp09_convnet/data/cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok = True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32)\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32)\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32)\n",
    "\n",
    "    ####################\n",
    "\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ####################\n",
    "\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "    for size in [32, 64, 128, 256, 512]:\n",
    "        residual = x\n",
    "\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        residual = layers.Conv2D(\n",
    "            size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ####################\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Fitting the model using a Dataset\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"chp09_convnet/models/chp9_convnet_patterns.keras\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=50,\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(history.history.keys())\n",
    "    # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "    ####################\n",
    "\n",
    "listing9_3_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chapter09_part02_kaggle_modern_convnet_architecture_patterns.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
