{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyPTejNVmkft"
   },
   "source": [
    "# Chp 8: Introduction to deep learning for computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convnet takes as input tensors of shape (img_height, img_width, img_channels),\n",
    "# not including the batch dimension\n",
    "def listing8_1():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    from IPython.display import Image, display_png\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "    png_file = './images/chp08-listing8_1.png'  \n",
    "    \n",
    "    keras.utils.plot_model(\n",
    "        model, \n",
    "        png_file,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        dpi=82,\n",
    "        rankdir='TB', #'LR',\n",
    "    )\n",
    "    display_png(Image(png_file))\n",
    "    \n",
    "listing8_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing8_3():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    \n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    train_images = train_images.reshape((60_000, 28, 28, 1))\n",
    "    train_images = train_images.astype(\"float32\") / 255\n",
    "    test_images = test_images.reshape((10_000, 28, 28, 1))\n",
    "    test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    hist = model.fit(\n",
    "        train_images,\n",
    "        train_labels, \n",
    "        epochs=5,\n",
    "        batch_size=64,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(hist.history.keys())\n",
    "    print()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        test_images, test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {test_acc :.3f}\")\n",
    "    print(f\"Test loss: {test_loss :.3f}\")\n",
    "    \n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    from IPython.display import Image, display_png\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "    png_file = './images/chp08-listing8_3.png'  \n",
    "    \n",
    "    keras.utils.plot_model(\n",
    "        model, \n",
    "        png_file,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        dpi=82,\n",
    "        rankdir='TB', #'LR',\n",
    "    )\n",
    "    display_png(Image(png_file))\n",
    "    \n",
    "listing8_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrectly-structured convnet missing its max pooling layers\n",
    "\n",
    "def listing8_5():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    \n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    train_images = train_images.reshape((60_000, 28, 28, 1))\n",
    "    train_images = train_images.astype(\"float32\") / 255\n",
    "    test_images = test_images.reshape((10_000, 28, 28, 1))\n",
    "    test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "    \n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    hist = model.fit(\n",
    "        train_images,\n",
    "        train_labels, \n",
    "        epochs=5,\n",
    "        batch_size=64,\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    print(hist.history.keys())\n",
    "    print()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        test_images, test_labels\n",
    "    )\n",
    "    print(f\"Test accuracy: {test_acc :.3f}\")\n",
    "    print(f\"Test loss: {test_loss :.3f}\")\n",
    "    \n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    from IPython.display import Image, display_png\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "    png_file = './images/chp08-listing8_5.png'  \n",
    "    \n",
    "    keras.utils.plot_model(\n",
    "        model, \n",
    "        png_file,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        dpi=82,\n",
    "        rankdir='TB', #'LR',\n",
    "    )\n",
    "    display_png(Image(png_file))\n",
    "    \n",
    "listing8_5()\n",
    "\n",
    "# Epoch 1/5\n",
    "# 938/938 - 7s - loss: 0.1180 - accuracy: 0.9642\n",
    "# Epoch 2/5\n",
    "# 938/938 - 6s - loss: 0.0422 - accuracy: 0.9874\n",
    "# Epoch 3/5\n",
    "# 938/938 - 6s - loss: 0.0317 - accuracy: 0.9907\n",
    "# Epoch 4/5\n",
    "# 938/938 - 6s - loss: 0.0262 - accuracy: 0.9927\n",
    "# Epoch 5/5\n",
    "# 938/938 - 6s - loss: 0.0215 - accuracy: 0.9938\n",
    "\n",
    "# dict_keys(['loss', 'accuracy'])\n",
    "\n",
    "# 313/313 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9906\n",
    "# Test accuracy: 0.991\n",
    "# Test loss: 0.030\n",
    "\n",
    "\n",
    "# Model: \"model_2\"\n",
    "# _________________________________________________________________\n",
    "# Layer (type)                 Output Shape              Param #   \n",
    "# =================================================================\n",
    "# input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
    "# _________________________________________________________________\n",
    "# conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
    "# _________________________________________________________________\n",
    "# conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
    "# _________________________________________________________________\n",
    "# conv2d_8 (Conv2D)            (None, 22, 22, 128)       73856     \n",
    "# _________________________________________________________________\n",
    "# flatten_2 (Flatten)          (None, 61952)             0         \n",
    "# _________________________________________________________________\n",
    "# dense_2 (Dense)              (None, 10)                619530    \n",
    "# =================================================================\n",
    "# Total params: 712,202\n",
    "# Trainable params: 712,202\n",
    "# Non-trainable params: 0\n",
    "# ____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT: downsampling\n",
    "\n",
    "Reasons to use downsampling:\n",
    "\n",
    "1. Reduce the number of feature-map coefficients to process. This helps reduce overfitting.\n",
    "\n",
    "2. Induce spatial-filter hierarchies by making successive convolution layers look at increasingly large windows (**in terms of the fraction of the original input they cover**). This helps in learning a spatial hierarchy of features.\n",
    "\n",
    "The most reasonable subsampling strategy is to first produce dense maps of features (via unstrided convolutions), and then look at the maximal activation of the features over small patches.\n",
    "\n",
    "This is more effective than looking at sparser windows of the inputs (via strided convolutions) or averaging input patches, which could cause you to miss or dilute feature-presence information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8.2 Training a convnet from scratch on a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_jupyter_lab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# GOOD\n",
    "# Epoch 20/20\n",
    "# 63/63 - 4s - loss: 0.0619 - accuracy: 0.9795 - val_loss: 1.5096 - val_accuracy: 0.7430\n",
    "# dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "def listing8_2():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        \n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "    \n",
    "    # make sure the project space is clean\n",
    "    # remove existing dirs\n",
    "    if Path('cats_vs_dogs_small').is_dir():\n",
    "        shutil.rmtree('cats_vs_dogs_small')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree('train')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree(data_dir)\n",
    "    if Path('sample_data').is_dir():\n",
    "        shutil.rmtree('sample_data')\n",
    "    if Path('/root/.kaggle').is_dir():\n",
    "        shutil.rmtree('/root/.kaggle')\n",
    "\n",
    "    # remove existing files\n",
    "    if Path('train.zip').is_file():\n",
    "        os.remove('train.zip')\n",
    "    if Path('test1.zip').is_file():\n",
    "        os.remove('test1.zip')\n",
    "    if Path('kaggle.json').is_file():\n",
    "        os.remove('kaggle.json')\n",
    "\n",
    "    \n",
    "    \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    import os, shutil, pathlib\n",
    "\n",
    "    original_dir = pathlib.Path(\"train\")\n",
    "    new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "    ############################\n",
    "    \n",
    "    # Instantiating a small convnet for dogs vs. cats classification\n",
    "    \n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # Data preprocessing\n",
    "    \n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    for data_batch, labels_batch in train_dataset:\n",
    "        print(\"data batch shape:\\t\", data_batch.shape)\n",
    "        print(\"labels batch shape:\\t\", labels_batch.shape)\n",
    "        break\n",
    "        \n",
    "    ##########\n",
    "    \n",
    "    # Fitting the model using a Dataset\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"models/convnet_from_scratch.keras\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=20,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "    \n",
    "    print(history.history.keys())\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "    plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # Evaluating the model on the test set\n",
    "    test_model = keras.models.load_model(\"models/convnet_from_scratch.keras\")\n",
    "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {test_acc :.3f}\")\n",
    "    \n",
    "    print(\"\\nFinished..\")\n",
    "\n",
    "listing8_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data augmentation\n",
    "# Training regularized convnet\n",
    "\n",
    "# Notes\n",
    "# OK\n",
    "# Epoch 50/50\n",
    "# 63/63  86ms/step - loss: 0.0499 - accuracy: 0.9895 - val_loss: 2.6240 - val_accuracy: 0.7430\n",
    "\n",
    "def listing8_18():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "    import os, shutil, pathlib\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    \n",
    "        \n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        \n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "    \n",
    "    # make sure the project space is clean\n",
    "    # remove existing dirs\n",
    "    if Path('cats_vs_dogs_small').is_dir():\n",
    "        shutil.rmtree('cats_vs_dogs_small')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree('train')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree(data_dir)\n",
    "    if Path('models').is_dir():\n",
    "        shutil.rmtree('models')\n",
    "    if Path('sample_data').is_dir():\n",
    "        shutil.rmtree('sample_data')\n",
    "    if Path('/root/.kaggle').is_dir():\n",
    "        shutil.rmtree('/root/.kaggle')\n",
    "\n",
    "    # remove existing files\n",
    "    if Path('train.zip').is_file():\n",
    "        os.remove('train.zip')\n",
    "    if Path('test1.zip').is_file():\n",
    "        os.remove('test1.zip')\n",
    "    if Path('kaggle.json').is_file():\n",
    "        os.remove('kaggle.json')\n",
    "\n",
    "        \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    original_dir = pathlib.Path(\"train\")\n",
    "    new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # Data preprocessing\n",
    "        \n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    for data_batch, labels_batch in train_dataset:\n",
    "        print(\"data batch shape:\\t\", data_batch.shape)\n",
    "        print(\"labels batch shape:\\t\", labels_batch.shape)\n",
    "        break\n",
    "        \n",
    "    ##########\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, _  in train_dataset.take(1):\n",
    "        for i in range(9):\n",
    "            augmented_images = data_augmentation(images)\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "    ############################\n",
    "    \n",
    "    # Instantiating a small convnet for dogs vs. cats classification\n",
    "    \n",
    "\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    ################\n",
    "    \n",
    "    # Fitting the model using a Dataset\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=\"models/convnet_from_scratch_with_augmentation.keras\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=50,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "    \n",
    "    print(history.history.keys())\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot()\n",
    "    ax1.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "    ax1.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "    ax1.set_title(\"Training and validation accuracy\")\n",
    "    ax1.legend()\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.add_subplot()\n",
    "    ax2.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    ax2.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    ax2.set_title(\"Training and validation loss\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    ##########\n",
    "        \n",
    "    # Evaluating the model on the test set\n",
    "    test_model = keras.models.load_model(\n",
    "        \"models/convnet_from_scratch_with_augmentation.keras\"\n",
    "    )\n",
    "    \n",
    "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "    \n",
    "    \n",
    "     ##########\n",
    "        \n",
    "    print(\"\\nFinished..\")\n",
    "    \n",
    "listing8_18()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8.3.1 Feature extraction with a pretrained model\n",
    "\n",
    "GB: If you can use pre-trained models, do you really need a GPU / TPU for training, or can you get by with a CPU for a mainly inferential-workload???\n",
    "\n",
    "Actually, we are still training the model on our data, but using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 180, 180, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 180, 180, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 90, 90, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 90, 90, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 45, 45, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 45, 45, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 45, 45, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 22, 22, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 22, 22, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 11, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# VCG16 CNN base\n",
    "# Instantiating the VGG16 convolutional base\n",
    "\n",
    "def listing8_23():\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras import applications\n",
    "    \n",
    "    conv_base = keras.applications.vgg16.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(180, 180, 3)\n",
    "    )\n",
    "    \n",
    "    print(conv_base.summary())\n",
    "    \n",
    "listing8_23()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST FEATURE EXTRACTION WITHOUT DATA AUGMENTATION\n",
    "# Running the convolutional base over your dataset, recording its output \n",
    "# to a NumPy array on disk, and then using this data as input to a \n",
    "# standalone, densely-connected classifier\n",
    "\n",
    "# Note: Input(shape=(5, 5, 512))\n",
    "# Note: Always show the test-result, so we can know it is valid or not:\n",
    "# GOOD:\n",
    "# Epoch 20/20\n",
    "# 63/63 - 0s - loss: 0.1680 - accuracy: 0.9995 - val_loss: 4.7224 - val_accuracy: 0.9790\n",
    "\n",
    "\n",
    "def listing8_24():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "    import os, shutil, pathlib\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras import applications\n",
    "    import numpy as np\n",
    "    \n",
    "        \n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        \n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "    \n",
    "\n",
    "    # make sure the project space is clean\n",
    "    # remove existing dirs\n",
    "    if Path('cats_vs_dogs_small').is_dir():\n",
    "        shutil.rmtree('cats_vs_dogs_small')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree('train')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree(data_dir)\n",
    "    if Path('models').is_dir():\n",
    "        shutil.rmtree('models')\n",
    "    if Path('sample_data').is_dir():\n",
    "        shutil.rmtree('sample_data')\n",
    "    if Path('/root/.kaggle').is_dir():\n",
    "        shutil.rmtree('/root/.kaggle')\n",
    "\n",
    "    # remove existing files\n",
    "    if Path('train.zip').is_file():\n",
    "        os.remove('train.zip')\n",
    "    if Path('test1.zip').is_file():\n",
    "        os.remove('test1.zip')\n",
    "    if Path('kaggle.json').is_file():\n",
    "        os.remove('kaggle.json')\n",
    "\n",
    "    \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    \n",
    "\n",
    "    original_dir = pathlib.Path(\"train\")\n",
    "    new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # Data preprocessing\n",
    "        \n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "    \n",
    "    conv_base = keras.applications.vgg16.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(180, 180, 3)\n",
    "    )    \n",
    "\n",
    "    def get_features_and_labels(dataset):\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for images, labels in dataset:\n",
    "            preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "            features = conv_base.predict(preprocessed_images)\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "        return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "        \n",
    "    train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "    val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "    test_features, test_labels =  get_features_and_labels(test_dataset)\n",
    "\n",
    "    ############################\n",
    "    \n",
    "    # Defining and training the densely connected classifier\n",
    "    \n",
    "    inputs = keras.Input(shape=(5, 5, 512))\n",
    "    x = layers.Flatten()(inputs)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "          filepath=\"feature_extraction.keras\",\n",
    "          save_best_only=True,\n",
    "          monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_features, train_labels,\n",
    "        epochs=20,\n",
    "        validation_data=(val_features, val_labels),\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    print(history.history.keys())\n",
    "    # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "\n",
    "    # test_loss, test_acc = model.evaluate(\n",
    "    #     test_dataset\n",
    "    # )\n",
    "    # print(f\"Test accuracy: {test_acc}\")\n",
    "    # print(f\"Test loss: {test_loss}\")\n",
    "    # print()\n",
    "\n",
    "    # ValueError: Input 0 is incompatible with layer model_5: expected shape=(None, 5, 5, 512), found shape=(None, 180, 180, 3)\n",
    "\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # Plotting the results\n",
    "    \n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    " \n",
    "    print(\"\\nFinished..\")\n",
    "    \n",
    "listing8_24()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and freeze the VGG16 convolutional base\n",
    "# Running the convolutional base over your dataset, recording its output \n",
    "# to a NumPy array on disk, and then using this data as input to a \n",
    "# standalone, densely-connected classifier\n",
    "\n",
    "# Note: Input(shape=(5, 5, 512))\n",
    "\n",
    "# GOOD:\n",
    "# Epoch 50/50\n",
    "# 63/63 - 11s - loss: 0.5400 - accuracy: 0.9910 - val_loss: 2.2804 - val_accuracy: 0.9760\n",
    "\n",
    "\n",
    "def listing8_27():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "    import os, shutil, pathlib\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras import applications\n",
    "    import numpy as np\n",
    "    \n",
    "        \n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        \n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "    \n",
    "\n",
    "    # make sure the project space is clean\n",
    "    # remove existing dirs\n",
    "    if Path('cats_vs_dogs_small').is_dir():\n",
    "        shutil.rmtree('cats_vs_dogs_small')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree('train')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree(data_dir)\n",
    "    if Path('models').is_dir():\n",
    "        shutil.rmtree('models')\n",
    "    if Path('sample_data').is_dir():\n",
    "        shutil.rmtree('sample_data')\n",
    "    if Path('/root/.kaggle').is_dir():\n",
    "        shutil.rmtree('/root/.kaggle')\n",
    "\n",
    "    # remove existing files\n",
    "    if Path('train.zip').is_file():\n",
    "        os.remove('train.zip')\n",
    "    if Path('test1.zip').is_file():\n",
    "        os.remove('test1.zip')\n",
    "    if Path('kaggle.json').is_file():\n",
    "        os.remove('kaggle.json')\n",
    "\n",
    "    \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    \n",
    "\n",
    "    original_dir = pathlib.Path(\"train\")\n",
    "    new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # Data preprocessing\n",
    "        \n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "\n",
    "    # Create a model that chains the conv_base with a new dense classifier, \n",
    "    # and train it end to end on the inputs.\n",
    "    # To do this, first freeze the convolutional base.\n",
    "    # Freezing a layer or set of layers means preventing their weights \n",
    "    # from being updated during training. Here, if you don’t do this, then the \n",
    "    # representations that were previously learned by the convolutional base \n",
    "    # will be modified during training. Because the Dense layers on top are \n",
    "    # randomly initialized, very large weight updates would be propagated \n",
    "    # through the network, effectively destroying the representations \n",
    "    # previously learned.\n",
    "\n",
    "    conv_base = keras.applications.vgg16.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(180, 180, 3)\n",
    "    )    \n",
    "    conv_base.trainable = False\n",
    "    print(\"This is the number of trainable weights \"\n",
    "          \"after freezing the conv base:\", len(conv_base.trainable_weights))\n",
    "    print()\n",
    "\n",
    "    ############################\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Defining and training the densely connected classifier\n",
    "    \n",
    "    # OLD\n",
    "    # inputs = keras.Input(shape=(5, 5, 512))\n",
    "\n",
    "    # NEW\n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    x = conv_base(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"rmsprop\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "          filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
    "          save_best_only=True,\n",
    "          monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=50,\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    print(history.history.keys())\n",
    "    # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "\n",
    "    test_model = keras.models.load_model(\n",
    "        \"feature_extraction_with_data_augmentation.keras\"\n",
    "    )\n",
    "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # Plotting the results\n",
    "    \n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    " \n",
    "    print(\"\\nFinished..\")\n",
    "    \n",
    "listing8_27()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning a pretrained model\n",
    "# 1. Add your custom network on top of an already-trained base network.\n",
    "# 2. Freeze the base network.\n",
    "# 3. Train the part you added.\n",
    "# 4. Unfreeze some layers in the base network. (Note that you should not unfreeze \"batch normalization\" layers, which is not relevant here since there are no such layers in VGG16. Batch normalization and its impact on fine-tuning is explained in the next chapter.)\n",
    "# 5. Jointly train both these layers and the part you added.\n",
    "\n",
    "# GOOD\n",
    "# Epoch 50/50\n",
    "# 63/63 - 12s - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.2528 - val_accuracy: 0.9820\n",
    "\n",
    "\n",
    "def listing8_31():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "    import os, shutil, pathlib\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras import applications\n",
    "    import numpy as np\n",
    "    \n",
    "        \n",
    "    def is_jupyter_lab():\n",
    "        import re\n",
    "        import psutil\n",
    "        \n",
    "        return any(re.search('jupyter-lab', x) for x in psutil.Process().parent().cmdline())\n",
    "    \n",
    "\n",
    "    # make sure the project space is clean\n",
    "    # remove existing dirs\n",
    "    if Path('cats_vs_dogs_small').is_dir():\n",
    "        shutil.rmtree('cats_vs_dogs_small')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree('train')\n",
    "    if Path('train').is_dir():\n",
    "        shutil.rmtree(data_dir)\n",
    "    if Path('models').is_dir():\n",
    "        shutil.rmtree('models')\n",
    "    if Path('sample_data').is_dir():\n",
    "        shutil.rmtree('sample_data')\n",
    "    if Path('/root/.kaggle').is_dir():\n",
    "        shutil.rmtree('/root/.kaggle')\n",
    "\n",
    "    # remove existing files\n",
    "    if Path('train.zip').is_file():\n",
    "        os.remove('train.zip')\n",
    "    if Path('test1.zip').is_file():\n",
    "        os.remove('test1.zip')\n",
    "    if Path('kaggle.json').is_file():\n",
    "        os.remove('kaggle.json')\n",
    "\n",
    "    \n",
    "    if is_jupyter_lab():\n",
    "        print(\"Using jupyter-lab. Click `Upload Files` in the file-explorer and upload `kaggle.json` manually\")\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        !unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    else:\n",
    "        # colab\n",
    "        from google.colab import files\n",
    "        files.upload()\n",
    "        !mkdir ~/.kaggle\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !ls /root/.kaggle\n",
    "        !kaggle competitions download -c dogs-vs-cats\n",
    "        #!unzip -qq dogs-vs-cats.zip\n",
    "        !unzip -qq train.zip\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    \n",
    "\n",
    "    original_dir = pathlib.Path(\"train\")\n",
    "    new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "    def make_subset(subset_name, start_index, end_index):\n",
    "        for category in (\"cat\", \"dog\"):\n",
    "            dir = new_base_dir / subset_name / category\n",
    "            os.makedirs(dir, exist_ok=True)\n",
    "            fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "            for fname in fnames:\n",
    "                shutil.copyfile(src=original_dir / fname,\n",
    "                                dst=dir / fname)\n",
    "\n",
    "    make_subset(\"train\", start_index=0, end_index=1000)\n",
    "    make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "    make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # Data preprocessing\n",
    "        \n",
    "    train_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"train\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    validation_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"validation\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    test_dataset = image_dataset_from_directory(\n",
    "        new_base_dir / \"test\",\n",
    "        image_size=(180, 180),\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    ##########\n",
    "\n",
    "    # Create a model that chains the conv_base with a new dense classifier, \n",
    "    # and train it end to end on the inputs.\n",
    "    # To do this, first freeze the convolutional base.\n",
    "    # Freezing a layer or set of layers means preventing their weights \n",
    "    # from being updated during training. Here, if you don’t do this, then the \n",
    "    # representations that were previously learned by the convolutional base \n",
    "    # will be modified during training. Because the Dense layers on top are \n",
    "    # randomly initialized, very large weight updates would be propagated \n",
    "    # through the network, effectively destroying the representations \n",
    "    # previously learned.\n",
    "\n",
    "    conv_base = keras.applications.vgg16.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        input_shape=(180, 180, 3)\n",
    "    )    \n",
    "\n",
    "    # Freezing all layers until the 4th from the last\n",
    "    conv_base.trainable = True\n",
    "\n",
    "    for layer in conv_base.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "    ############################\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Defining and training the densely connected classifier\n",
    "    \n",
    "    # OLD\n",
    "    # inputs = keras.Input(shape=(5, 5, 512))\n",
    "\n",
    "    # NEW\n",
    "    \n",
    "    inputs = keras.Input(shape=(180, 180, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    x = conv_base(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Fine-tuning the model\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "          filepath=\"fine_tuning.keras\",\n",
    "          save_best_only=True,\n",
    "          monitor=\"val_loss\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=50,\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    print(history.history.keys())\n",
    "    # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "\n",
    "\n",
    "    test_model = keras.models.load_model(\n",
    "        \"fine_tuning.keras\"\n",
    "    )\n",
    "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "    print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "\n",
    "    ##########\n",
    "\n",
    "    # Plotting the results\n",
    "    \n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    " \n",
    "    print(\"\\nFinished..\")\n",
    "    \n",
    "listing8_31()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ok-chapter08_intro-to-dl-for-computer-vision-kaggle.ipynb",
   "provenance": [
    {
     "file_id": "1_aE0O3-qUP0d8wkoOA2r-0MKRfIKshDp",
     "timestamp": 1626066905836
    },
    {
     "file_id": "1LirJiT2Dm2av_FFvlBut856mxX-erBdj",
     "timestamp": 1626011620906
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
