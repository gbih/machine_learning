{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUwFl_eaWPAI"
   },
   "source": [
    "# Chp13 Best practices for the real world\n",
    "\n",
    "* https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_f8IEafiWPAN"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgrrp-xxkW_1",
    "outputId": "28e0faa2-d479-469a-cd1b-8f97a35d124a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU mode - switch to mixed precision.\n",
      "Every layer will use a 16-bit compute dtype and float32 variable dtype by default.\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: Tesla T4, compute capability 7.5\n",
      "--------------------------------------------------------------------------------\n",
      "global policy: <Policy \"mixed_float16\">\n"
     ]
    }
   ],
   "source": [
    "def HR():\n",
    "    print('-' * 80)\n",
    "\n",
    "# This results in an error in listing 12.31!\n",
    "def set_mixed_precision():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        print(\"GPU mode - switch to mixed precision.\")\n",
    "        print(\"Every layer will use a 16-bit compute dtype and float32 variable dtype by default.\")\n",
    "        keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "    HR()\n",
    "    print(\"global policy:\", tf.keras.mixed_precision.global_policy())\n",
    "\n",
    "set_mixed_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "grDUNiDtWPAP"
   },
   "outputs": [],
   "source": [
    "# Listing 13.1 A KerasTuner model-building function, p.472\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m_5j_KrzWPAQ"
   },
   "outputs": [],
   "source": [
    "# Listing 13.2 A KerasTuner HyperModel, p.473\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        \n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        \n",
    "        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "        \n",
    "        return model\n",
    "\n",
    "hypermodel = SimpleMLP(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XOVnq9rjWPAT"
   },
   "outputs": [],
   "source": [
    "def get_best_epoch(hp, data):\n",
    "    \n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_val = data['x_val']\n",
    "    y_val = data['y_val']\n",
    "\n",
    "    model = build_model(hp)\n",
    "    \n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", \n",
    "            mode=\"min\", \n",
    "            patience=2,\n",
    "            #patience=10,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        # epochs=100,\n",
    "        epochs=2,\n",
    "        batch_size=128,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "    \n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print()\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    \n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vggGV2MPWPAT"
   },
   "outputs": [],
   "source": [
    "def get_best_trained_model(hp, data):\n",
    "\n",
    "    x_train_full = data['x_train_full']\n",
    "    y_train_full = data['y_train_full']\n",
    "\n",
    "    # GB added this line here\n",
    "    model = build_model(hp)\n",
    "\n",
    "    best_epoch = get_best_epoch(hp, data)\n",
    "\n",
    "    # HR()\n",
    "    # print(f\"best_epoch * 1.2: {int(best_epoch * 1.2)}\")\n",
    "\n",
    "    model.fit(\n",
    "        x_train_full, \n",
    "        y_train_full,\n",
    "        batch_size=128, \n",
    "        epochs=int(best_epoch * 1.2),\n",
    "        verbose=2\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JREpExXQv1Ah",
    "outputId": "8ed77014-e7b3-4394-ec8f-20273c4fe5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x_train_full', 'y_train_full', 'x_train', 'y_train', 'x_test', 'y_test', 'x_val', 'y_val'])\n"
     ]
    }
   ],
   "source": [
    "def create_data():\n",
    "\n",
    "    # Load the data\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Normalize pixel values between 0 and 1\n",
    "    x_train = x_train.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape((-1, 28 * 28)).astype(\"float32\") / 255\n",
    "\n",
    "    x_train_full = x_train[:]\n",
    "    y_train_full = y_train[:]\n",
    "\n",
    "    num_val_samples = 10_000\n",
    "    x_train, x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "    y_train, y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "\n",
    "    data = {\n",
    "        'x_train_full': x_train_full,\n",
    "        'y_train_full': y_train_full,\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_test': x_test,\n",
    "        'y_test': y_test,\n",
    "        'x_val': x_val,\n",
    "        'y_val': y_val\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "data = create_data()\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "F42pMk6lvKWV"
   },
   "outputs": [],
   "source": [
    "def tuner_model(data, tuner):\n",
    "\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_val = data['x_val']\n",
    "    y_val = data['y_val']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "\n",
    "    ################\n",
    "\n",
    "    # display an overview of the search space via search_space_summary():\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    #############\n",
    "\n",
    "    # Create a callback to stop training early after reaching a certain value for the validation loss\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Run the hyperparameter search\n",
    "    # This method has the same signature as keras.Model.fit\n",
    "    tuner.search(\n",
    "        x_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=3,\n",
    "        # epochs=100,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    ################\n",
    "\n",
    "    # Listing 13.3 Querying the best hyperparameter configurations, p.476\n",
    "    top_n = 4\n",
    "\n",
    "    # # Get the optimal hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(top_n)\n",
    "\n",
    "    ################\n",
    "\n",
    "    best_models = []\n",
    "\n",
    "    for hp in best_hps:\n",
    "        model = get_best_trained_model(hp, data)\n",
    "        model.evaluate(x_test, y_test)\n",
    "        best_models.append(model)\n",
    "        HR()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lp6yuAX08JL"
   },
   "source": [
    "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available:\n",
    "\n",
    "    BayesianOptimization\n",
    "    Hyperband\n",
    "    RandomSearch\n",
    "    Sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekg-yCuX32Ui",
    "outputId": "31a1898a-c5f0-46ec-c7d6-30464a132bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 11s]\n",
      "val_accuracy: 0.9555500149726868\n",
      "\n",
      "Best val_accuracy So Far: 0.9599000215530396\n",
      "Total elapsed time: 00h 01m 55s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4215 - accuracy: 0.8867 - val_loss: 0.2319 - val_accuracy: 0.9373\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2186 - accuracy: 0.9370 - val_loss: 0.1786 - val_accuracy: 0.9522\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3964 - accuracy: 0.8929\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2075 - accuracy: 0.9411\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.9462\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4261 - accuracy: 0.8853 - val_loss: 0.2318 - val_accuracy: 0.9366\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2178 - accuracy: 0.9380 - val_loss: 0.1845 - val_accuracy: 0.9489\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3811 - accuracy: 0.8975\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.1907 - accuracy: 0.9454\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9545\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4168 - accuracy: 0.8880 - val_loss: 0.2248 - val_accuracy: 0.9386\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2073 - accuracy: 0.9407 - val_loss: 0.1763 - val_accuracy: 0.9512\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3846 - accuracy: 0.8972\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.1948 - accuracy: 0.9446\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1664 - accuracy: 0.9525\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4541 - accuracy: 0.8772 - val_loss: 0.2323 - val_accuracy: 0.9341\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2201 - accuracy: 0.9374 - val_loss: 0.1837 - val_accuracy: 0.9497\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4249 - accuracy: 0.8828\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2076 - accuracy: 0.9415\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.9481\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import keras_tuner as kt\n",
    "\n",
    "# BayesianOptimization Tuner\n",
    "# https://keras.io/api/keras_tuner/tuners/bayesian/\n",
    "\n",
    "tuner1 = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    #max_trials=100,\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "    # hypermodel,\n",
    "    # objective,\n",
    "    # max_trials,\n",
    "    # num_initial_points=2,\n",
    "    # alpha=0.0001,\n",
    "    # beta=2.6,\n",
    "    # seed=None,\n",
    "    # hyperparameters=None,\n",
    "    # tune_new_entries=True,\n",
    "    # allow_new_entries=True,\n",
    "    # **kwargs\n",
    "\n",
    "tuner_model(data, tuner1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4tBnapb39QF",
    "outputId": "8df52ead-d61f-4437-d066-be26dbd2eed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project mnist_kt_test/intro_to_kt/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from mnist_kt_test/intro_to_kt/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4627 - accuracy: 0.8747 - val_loss: 0.2421 - val_accuracy: 0.9321\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2200 - accuracy: 0.9376 - val_loss: 0.1786 - val_accuracy: 0.9511\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4095 - accuracy: 0.8886\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2010 - accuracy: 0.9444\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.9484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4194 - accuracy: 0.8861 - val_loss: 0.2363 - val_accuracy: 0.9334\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2177 - accuracy: 0.9378 - val_loss: 0.1769 - val_accuracy: 0.9525\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3952 - accuracy: 0.8928\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2017 - accuracy: 0.9426\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.9421\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.5028 - accuracy: 0.8681 - val_loss: 0.2613 - val_accuracy: 0.9287\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2600 - accuracy: 0.9268 - val_loss: 0.2162 - val_accuracy: 0.9389\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4683 - accuracy: 0.8735\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2371 - accuracy: 0.9329\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9389\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4294 - accuracy: 0.8839 - val_loss: 0.2527 - val_accuracy: 0.9273\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2264 - accuracy: 0.9358 - val_loss: 0.1901 - val_accuracy: 0.9471\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3889 - accuracy: 0.8935\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2009 - accuracy: 0.9425\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.9488\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import keras_tuner as kt\n",
    "\n",
    "# https://keras.io/api/keras_tuner/tuners/hyperband/\n",
    "# Hyperband Tuner\n",
    "\n",
    "tuner2 = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    # max_epochs=10,\n",
    "    max_epochs=5,\n",
    "    factor=3,\n",
    "    directory='mnist_kt_test',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "    # hypermodel,\n",
    "    # objective,\n",
    "    # max_epochs,\n",
    "    # factor=3,\n",
    "    # hyperband_iterations=1,\n",
    "    # seed=None,\n",
    "    # hyperparameters=None,\n",
    "    # tune_new_entries=True,\n",
    "    # allow_new_entries=True,\n",
    "    # **kwargs\n",
    "\n",
    "tuner_model(data, tuner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2Jvhdws4Alb",
    "outputId": "fe39208a-7018-48f3-aaa9-18d8d68e9fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project mnist_kt_test/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from mnist_kt_test/untitled_project/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.5007 - accuracy: 0.8706 - val_loss: 0.2856 - val_accuracy: 0.9198\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2697 - accuracy: 0.9240 - val_loss: 0.2222 - val_accuracy: 0.9376\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4701 - accuracy: 0.8743\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2452 - accuracy: 0.9295\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9361\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4888 - accuracy: 0.8691 - val_loss: 0.2489 - val_accuracy: 0.9316\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2392 - accuracy: 0.9331 - val_loss: 0.1962 - val_accuracy: 0.9461\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4516 - accuracy: 0.8773\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2288 - accuracy: 0.9356\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9434\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4155 - accuracy: 0.8873 - val_loss: 0.2235 - val_accuracy: 0.9366\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2119 - accuracy: 0.9384 - val_loss: 0.1727 - val_accuracy: 0.9518\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3829 - accuracy: 0.8978\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.1926 - accuracy: 0.9450\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9475\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4198 - accuracy: 0.8857 - val_loss: 0.2319 - val_accuracy: 0.9349\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2171 - accuracy: 0.9376 - val_loss: 0.1763 - val_accuracy: 0.9523\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3967 - accuracy: 0.8937\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2011 - accuracy: 0.9430\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9519\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import keras_tuner as kt\n",
    "\n",
    "# https://keras.io/api/keras_tuner/tuners/random/\n",
    "# RandomSearch Tuner\n",
    "\n",
    "tuner3 = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,\n",
    "    directory='mnist_kt_test',\n",
    ")\n",
    "\n",
    "    # hypermodel,\n",
    "    # objective,\n",
    "    # max_trials,\n",
    "    # seed=None,\n",
    "    # hyperparameters=None,\n",
    "    # tune_new_entries=True,\n",
    "    # allow_new_entries=True,\n",
    "    # **kwargs\n",
    "\n",
    "tuner_model(data, tuner3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1msTk_64P_N",
    "outputId": "115ec201-93c7-4ee6-b112-3bb02f486ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project mnist_kt_test/untitled_project/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from mnist_kt_test/untitled_project/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4202 - accuracy: 0.8870 - val_loss: 0.2247 - val_accuracy: 0.9388\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2151 - accuracy: 0.9379 - val_loss: 0.1751 - val_accuracy: 0.9543\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3783 - accuracy: 0.8972\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.1919 - accuracy: 0.9453\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1637 - accuracy: 0.9532\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4348 - accuracy: 0.8843 - val_loss: 0.2495 - val_accuracy: 0.9281\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2283 - accuracy: 0.9350 - val_loss: 0.1858 - val_accuracy: 0.9499\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3875 - accuracy: 0.8943\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2053 - accuracy: 0.9411\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.9465\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4145 - accuracy: 0.8902 - val_loss: 0.2205 - val_accuracy: 0.9386\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2109 - accuracy: 0.9397 - val_loss: 0.1747 - val_accuracy: 0.9510\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.3866 - accuracy: 0.8956\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2050 - accuracy: 0.9413\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9492\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/2\n",
      "391/391 - 2s - loss: 0.4624 - accuracy: 0.8777 - val_loss: 0.2473 - val_accuracy: 0.9314\n",
      "Epoch 2/2\n",
      "391/391 - 1s - loss: 0.2296 - accuracy: 0.9345 - val_loss: 0.1897 - val_accuracy: 0.9477\n",
      "\n",
      "Best epoch: 2\n",
      "Epoch 1/2\n",
      "469/469 - 2s - loss: 0.4266 - accuracy: 0.8836\n",
      "Epoch 2/2\n",
      "469/469 - 1s - loss: 0.2077 - accuracy: 0.9420\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9511\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "import keras_tuner as kt\n",
    "\n",
    "# https://keras.io/api/keras_tuner/tuners/base_tuner/\n",
    "# The base Tuner class\n",
    "\n",
    "tuner0 = kt.Tuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('score', 'max'),\n",
    "        max_trials=10\n",
    "    ),\n",
    "    hypermodel=build_model, #hypermodel,\n",
    "    max_model_size=None,\n",
    "    optimizer=None,\n",
    "    loss=None,\n",
    "    metrics=None,\n",
    "    distribution_strategy=None,\n",
    "    directory=\"mnist_kt_test\",\n",
    "    project_name=None,\n",
    "    logger=None,\n",
    "    tuner_id=None,\n",
    "    overwrite=False,\n",
    ")\n",
    "\n",
    "    # oracle,\n",
    "    # hypermodel,\n",
    "    # max_model_size=None,\n",
    "    # optimizer=None,\n",
    "    # loss=None,\n",
    "    # metrics=None,\n",
    "    # distribution_strategy=None,\n",
    "    # directory=None,\n",
    "    # project_name=None,\n",
    "    # logger=None,\n",
    "    # tuner_id=None,\n",
    "    # overwrite=False,\n",
    "\n",
    "tuner_model(data, tuner0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "Tu7ypftR4DPw"
   },
   "outputs": [],
   "source": [
    "# #import sklearn.model_selection\n",
    "# import keras_tuner as kt\n",
    "# from sklearn import model_selection\n",
    "# from sklearn import metrics\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# # Tuning Scikit-learn Models\n",
    "\n",
    "\n",
    "# # https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html\n",
    "# # Despite its name, Keras Tuner can be used to tune a wide variety of \n",
    "# # machine learning models. In addition to built-in Tuners for Keras models, \n",
    "# # Keras Tuner provides a built-in Tuner that works with Scikit-learn models. \n",
    " \n",
    "\n",
    "# # https://keras.io/api/keras_tuner/tuners/sklearn/\n",
    "# # Sklearn Tuner\n",
    "\n",
    "# tuner4 = kt.tuners.SklearnTuner(\n",
    "#     oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "#         objective=kt.Objective('score', 'loss'),\n",
    "#         max_trials=10\n",
    "#     ),\n",
    "#     hypermodel=build_model,\n",
    "#     # scoring=None, \n",
    "#     # metrics=None, \n",
    "#     scoring=metrics.make_scorer(metrics.accuracy_score),\n",
    "#     cv=model_selection.StratifiedKFold(5),\n",
    "#     directory='mnist_kt_test',\n",
    "#     project_name='my_project',\n",
    "# )\n",
    "\n",
    "# X_train = data['x_train']\n",
    "# y_train = data['y_train']\n",
    "\n",
    "# tuner4.search(X_train, y_train)\n",
    "\n",
    "# best_model = tuner4.get_best_models(num_models=1)[0]\n",
    "\n",
    "#     # hypermodel,\n",
    "#     # objective,\n",
    "#     # max_epochs,\n",
    "#     # factor=3,\n",
    "#     # hyperband_iterations=1,\n",
    "#     # seed=None,\n",
    "#     # hyperparameters=None,\n",
    "#     # tune_new_entries=True,\n",
    "#     # allow_new_entries=True,\n",
    "#     # **kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1KlmiBW-4H6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chp13_best_practices_for_the_real_world.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
