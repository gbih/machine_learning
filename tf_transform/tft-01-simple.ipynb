{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8071a56b-a0dd-4ccb-acd2-2f7e83b7487d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Preprocessing data with TensorFlow Transform (Intro)\n",
    "\n",
    "[Source](https://www.tensorflow.org/tfx/tutorials/transform/simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a10707-c6a5-4f7b-a86c-c308585c9b97",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/gbih/ml-notes/blob/main/tf_transform/tft-01-simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a568cb1-6f0a-4cc0-b6b5-697920125f48",
   "metadata": {},
   "source": [
    "1. [Setup](#1.0)\n",
    "2. [Introduction](#2.0)\n",
    "3. [Data: Create some dummy data](#3.0)\n",
    "4. [Transform: Create a preprocessing function](#4.0)\n",
    "5. [Syntax](#5.0)\n",
    "6. [Putting it all together](#6.0)\n",
    "7. [Is this right answer?](#7.0)\n",
    "8. [Use the resulting transform_fn](#8.0)\n",
    "9. [Export](#9.0)\n",
    "    * [9.1 An example training model](#9.1)\n",
    "    * [9.2 An example export wrapper](#9.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a0d04-ab8e-4cb1-8cf7-8bf1bfa48fec",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='setup'></a><a name='setup'>\n",
    "# 1. Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3bb02-7e3c-4514-8be6-877e1b00ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print(\"Running on Colab. Installing TFT.\")\n",
    "    !pip install tfx &> /dev/null\n",
    "    !apt-get install tree &> /dev/null\n",
    "    !pip install protobuf==3.19.0\n",
    "else:\n",
    "    print(\"Running locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561211af-72a9-4d35-84df-3fdfdbc9a53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "# Module level imports for tensorflow_transform.beam.\n",
    "# https://github.com/tensorflow/transform/blob/master/tensorflow_transform/beam/__init__.py\n",
    "# https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "# In-memory representation of all metadata associated with a dataset.\n",
    "# https://www.tensorflow.org/tfx/transform/api_docs/python/tft/DatasetMetadata\n",
    "# https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/dataset_metadata.py\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "\n",
    "# Utilities for using the tf.Metadata Schema within TensorFlow\n",
    "# https://github.com/tensorflow/transform/blob/master/tensorflow_transform/tf_metadata/schema_utils.py\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# global seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.get_logger().propagate = False\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR') # DEBUG, INFO, WARN, ERROR, or FATAL\n",
    "\n",
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "def dir_ex(obj):\n",
    "    result = [x for x in dir(obj) if not x.startswith('_')]\n",
    "    print(type(obj))\n",
    "    print()\n",
    "    for x in result:\n",
    "        print(f'{x:<40}', end=\"\")\n",
    "        \n",
    "print(\"Loaded libraries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2cf8e0-58f4-4fde-95f5-08ffc03dafe1",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='2.0'></a><a name='2.0'></a>\n",
    "# 2. Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "**The Feature Engineering Component of TensorFlow Extended (TFX)**\n",
    "\n",
    "This example notebook provides a very simple example of how TensorFlow Transform (`tf.Transform`) can be used to preprocess data using exactly the same code for both training a model and serving inferences in production.\n",
    "\n",
    "TensorFlow Transform is a library for preprocessing input data for TensorFlow, including creating features that require a full pass over the training dataset. For example, using `tr.Transform` you could:\n",
    "\n",
    "* Normalize an input value by using the mean and standard deviation (`tft.scale_to_0_1()`)\n",
    "\n",
    "* Convert strings to integers by generating a vocabulary over all of the input values (`tft.compute_and_apply_vocabulary()`)\n",
    "\n",
    "* Convert floats to integers by assigning them to buckets, based on the observed data distribution (`tft.bucketize`)\n",
    "\n",
    "TensorFlow has built-in support for manipulations on a single example or batch of example **(GB: Show examples of this)**. `tf.Transform` extends these capabilities to support full passes over the entire training dataset.\n",
    "\n",
    "The output of `tf.Transform` is exported as a TensorFlow graph which you can use for both training and serving. Using the same graph for both training and serving can prevent skew, since the same transformations are applied in both stages.\n",
    "\n",
    "## Transform library for TFX and non-TFX users \n",
    "\n",
    "The `tft` module documentation is the only module that is relevant to TFX users. The `tft_beam` module is relevant only when using Transform as a standalone library. Typically, a TFX user constructs a `preprocessing_fn`, and the rest of the Transform library calls are made by the [TFX Transform component](https://www.tensorflow.org/tfx/guide/transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcfee9-70d9-4e60-afeb-63ee3a8c21ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<sub>\n",
    "\n",
    "\n",
    "[Quick cheatsheet for TensorFlow Transform](https://www.tensorflow.org/tfx/transform/api_docs/python/tft)\n",
    "\n",
    "    \n",
    "### Classes:\n",
    "    \n",
    "    \n",
    "```\n",
    "tft.DatasetMetadata:  Metadata about a dataset used for the \"instance dict\" format.\n",
    "tft.TFTransformOutput:  A wrapper around the output of the tf.Transform.\n",
    "tft.TransformFeaturesLayer:  A Keras layer for applying a tf.Transform output to input layers.\n",
    "```\n",
    "\n",
    "### Transform Functions:\n",
    "\n",
    "\n",
    "```\n",
    "tft.apply_buckets():  Returns a bucketized column, with a bucket index assigned to each input.\n",
    "tft.apply_buckets_with_interpolation():  Interpolates within the provided buckets and then normalizes to 0 to 1.\n",
    "tft.apply_pyfunc():  Applies a python function to some Tensors.\n",
    "tft.apply_vocabulary():  Maps x to a vocabulary specified by the deferred tensor.\n",
    "tft.bag_of_words():  Computes a bag of \"words\" based on the specified ngram configuration.\n",
    "tft.bucketize():  Returns a bucketized column, with a bucket index assigned to each input.\n",
    "tft.bucketize_per_key():  Returns a bucketized column, with a bucket index assigned to each input.\n",
    "tft.compute_and_apply_vocabulary():  Generates a vocabulary for x and maps it to an integer with this vocab.\n",
    "tft.count_per_key():  Computes the count of each element of a Tensor.\n",
    "tft.covariance():  Computes the covariance matrix over the whole dataset.\n",
    "tft.deduplicate_tensor_per_row():  Deduplicates each row (0-th dimension) of the provided tensor.\n",
    "tft.estimated_probability_density():  Computes an approximate probability density at each x, given the bins.\n",
    "tft.get_analyze_input_columns():  Return columns that are required inputs of AnalyzeDataset.\n",
    "tft.get_num_buckets_for_transformed_feature():  Provides the number of buckets for a transformed feature if annotated.\n",
    "tft.get_transform_input_columns():  Return columns that are required inputs of TransformDataset.\n",
    "tft.hash_strings():  Hash strings into buckets.\n",
    "tft.histogram():  Computes a histogram over x, given the bin boundaries or bin count.\n",
    "tft.make_and_track_object():  Keeps track of the object created by invoking trackable_factory_callable.\n",
    "tft.max():  Computes the maximum of the values of a Tensor over the whole dataset.\n",
    "tft.mean():  Computes the mean of the values of a Tensor over the whole dataset.\n",
    "tft.min():  Computes the minimum of the values of a Tensor over the whole dataset.\n",
    "tft.ngrams():  Create a SparseTensor of n-grams.\n",
    "tft.pca():  Computes PCA on the dataset using biased covariance.\n",
    "tft.quantiles():  Computes the quantile boundaries of a Tensor over the whole dataset.\n",
    "tft.scale_by_min_max():  Scale a numerical column into the range [output_min, output_max].\n",
    "tft.scale_by_min_max_per_key():  Scale a numerical column into a predefined range on a per-key basis.\n",
    "tft.scale_to_0_1():  Returns a column which is the input column scaled to have range [0,1].\n",
    "tft.scale_to_0_1_per_key():  Returns a column which is the input column scaled to have range [0,1].\n",
    "tft.scale_to_gaussian():  Returns an (approximately) normal column with mean to 0 and variance 1.\n",
    "tft.scale_to_z_score():  Returns a standardized column with mean 0 and variance 1.\n",
    "tft.scale_to_z_score_per_key():  Returns a standardized column with mean 0 and variance 1, grouped per key.\n",
    "tft.segment_indices():  Returns a Tensor of indices within each segment.\n",
    "tft.size():  Computes the total size of instances in a Tensor over the whole dataset.\n",
    "tft.sparse_tensor_left_align():  Re-arranges a tf.SparseTensor and returns a left-aligned version of it.\n",
    "tft.sparse_tensor_to_dense_with_shape():  Converts a SparseTensor into a dense tensor and sets its shape.\n",
    "tft.sum():  Computes the sum of the values of a Tensor over the whole dataset.\n",
    "tft.tfidf():  Maps the terms in x to their term frequency * inverse document frequency.\n",
    "tft.tukey_h_params():  Computes the h parameters of the values of a Tensor over the dataset.\n",
    "tft.tukey_location():  Computes the location of the values of a Tensor over the whole dataset.\n",
    "tft.tukey_scale():  Computes the scale of the values of a Tensor over the whole dataset.\n",
    "tft.var():  Computes the variance of the values of a Tensor over the whole dataset.\n",
    "tft.vocabulary():  Computes the unique values of a Tensor over the whole dataset.\n",
    "tft.word_count():  Find the token count of each document/row.\n",
    "```\n",
    "    \n",
    "</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec81701-103f-4327-bd11-5c61327e41ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "914fa3c7-31eb-48cb-9235-2639be968a4d",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='3.0'></a><a name='3.0'></a>\n",
    "# 3. Data: Create some dummy data\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Create some simple dummy data for our simple exercise:\n",
    "\n",
    "* `raw_data` is the initial raw data that we're going to preprocess\n",
    "* `raw_data_metadata` contains the schema that tells us the types of each of the columns in `raw_data`. It is very simple in this example.\n",
    "\n",
    "---\n",
    "\n",
    "**NOTES:**\n",
    "\n",
    "https://www.tensorflow.org/tfx/transform/get_started\n",
    "\n",
    "TFT Beam implementation accepts two different input data formats. The \"instance dict\" format (as seen here) is an intuitive format and is suitable for small datasets while the TFXIO (Apache Arrow) format provides improved performance and is suitable for large datasets.\n",
    "\n",
    "The \"instance dict\" format:\n",
    "\n",
    "The previous code examples used this format. The **metadata** contains the schema that defines the layout of the data and how it is read from and written to various formats. This in-memory format is not self-describing and requires a schema in order to be interpreted as tensors.\n",
    "\n",
    "The Schema proto contains the information needed to parse the data, from on-disk or in-memory format, into tensors. It is typically constructed by calling `tft.tf_metadata.schema_utils.schema_from_feature_spec` with a dict mapping feature keys to `tf.io.FixedLenFeature`, `tf.io.VarLenFeature`, and `tf.io.SparseFeature` values (see documentation for `tf.parse_example` for more details).\n",
    "\n",
    "Above, we use `tf.io.FixedLenFeature` to indicate that each feature contains a fixed number of values (in this case a single scalar value). Because `tensorflow_transform` batches instances, the actual Tensor representing the feature will have shape `(None,)` where the unknown dimension is the batch dimension.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### tft.DatasetMetadata\n",
    "\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "\n",
    "    tft.DatasetMetadata(\n",
    "        schema: schema_pb2.Schema\n",
    "    )\n",
    "\n",
    "* This is an in-memory representation that may be serialized and deserialized to and from a variety of disk representations.\n",
    "* Caution: The \"instance dict\" format used with DatasetMetadata is much less efficient than TFXIO. For any serious workloads you should use TFXIO with a tfxio.TensorAdapterConfig instance as the metadata\n",
    "\n",
    "https://www.tensorflow.org/tfx/transform/api_docs/python/tft/DatasetMetadata\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4e56c0d-88ce-4c0a-bef1-1849bd3b4ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_schema': feature {\n",
      "  name: \"s\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"x\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"y\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "raw_data = [\n",
    "    {'x': 1, 'y': 1, 's': 'hello'},\n",
    "    {'x': 2, 'y': 2, 's': 'world'},\n",
    "    {'x': 3, 'y': 3, 's': 'hello'},\n",
    "]\n",
    "\n",
    "# Simple \"instance dict\" format for TFT Beam input data formats\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "        's': tf.io.FixedLenFeature([], tf.string)\n",
    "    })\n",
    ")\n",
    "\n",
    "print(raw_data_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b378e-5bef-48eb-beb8-2fe31dd801e8",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='4.0'></a><a name='4.0'></a>\n",
    "# 4. Transform: Create a preprocessing function\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "The *preprocessing function* is the most important concept of tf.Transform. A preprocessing function is where the transformation of the dataset happens. It accepts and return a dictionary of tensors, where a tensor is defined as a `Tensor` or `SparseTensor`. There are two main groups of API calls that typically form the heart of a preprocessing function:\n",
    "\n",
    "1. **TensorFlowOps**: Any function that accepts and returns tensors, which usually means TensorFlow ops. These add TensorFlow operations to the graph that transforms raw data into transformed data, one feature at a time. These will run for every example, during both training and serving.\n",
    "\n",
    "2. **Tensorflow Transform Analyzers/Mappers**: Any of the analyzers/mappers provided by `tf.Transform`. These accept and return tensors, and typically contain a combination of Tensorflow ops and Beam computation, but unlike TensorFlow ops, they only run in the Beam pipeline during analysis requiring a full pass over the entire training dataset. The Beam computation runs only once (prior to training, during analysis), and typically makes a full pass over the entire training dataset. They create `tf.constant` tensors, which are added to your graph. For example, `tft.min` computes the minimum of a tensor over the training dataset.\n",
    "\n",
    "Caution: When you apply your preprocessing function to serving inferences, the constants that were created by analyzers during training do not change. If your data has trend or seasonality components, plan accordingly.\n",
    "\n",
    "Note: `preprocessing_fn` is not directly callable. Instead, it must be passed to the Transform Beam API, as shown in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daa7220e-436f-4f19-9afc-b5696ca72100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs) -> dict:\n",
    "    \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "    Preprocess input columns into transformed columns.\n",
    "\n",
    "    Args:\n",
    "    inputs: map from feature keys to raw not-yet-transformed features.\n",
    "\n",
    "    Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Return a frame object from the call stack.\n",
    "    print(f\"---> preprocessing_fn CALLED FROM: {sys._getframe().f_back.f_code.co_name}\")\n",
    "        \n",
    "    x = inputs['x']\n",
    "    y = inputs['y']\n",
    "    s = inputs['s']\n",
    "    \n",
    "    x_centered = x - tft.mean(x)\n",
    "    y_normalized = tft.scale_to_0_1(y)\n",
    "    s_integerized = tft.compute_and_apply_vocabulary(s)\n",
    "    x_centered_times_y_normalized = (x_centered * y_normalized)\n",
    "    \n",
    "    return {\n",
    "        'x_centered': x_centered,\n",
    "        'y_normalized': y_normalized,\n",
    "        's_integerized': s_integerized,\n",
    "        'x_centered_times_y_normalized': x_centered_times_y_normalized\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3ee22-4d08-497f-8e3f-9279c7885c8f",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='5.0'></a><a name='5.0'></a>\n",
    "# 5. Syntax\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We are ready to put everything together and use Apache Beam to run it.\n",
    "\n",
    "Apache Beam uses a special syntax to define and invoke transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77657884-2bf0-4bc7-a451-568ec0662016",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<a id='6.0'></a><a name='6.0'></a>\n",
    "# 6. Putting it all together\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We are ready to transform our data. We will use Apache Beam with a direct runner, and supply three inputs:\n",
    "\n",
    "1. `raw_data`: The raw input data that we created above.\n",
    "2. `raw_data_metadata`: The schema for the raw data.\n",
    "3. `preprocessing_fn`: The function that we created to do our transformation.\n",
    "\n",
    "---\n",
    "\n",
    "We use three `tft_beam` classes here:\n",
    "\n",
    "* [tft_beam.Context](https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam/Context): Context manager for tensorflow-transform. All the attributes in this context are kept on a thread local state. \n",
    "\n",
    "* [tft_beam.AnalyzeAndTransformDataset](https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam/AnalyzeAndTransformDataset): Combination of AnalyzeDataset and TransformDataset. This may be more efficient since it avoids multiple passes over the data.\n",
    "\n",
    "* [tft_beam.WriteTransformFn](https://www.tensorflow.org/tfx/transform/api_docs/python/tft_beam/WriteTransformFn): Writes a TransformFn to disk. The internal structure is a directory containing two subdirectories. The first is 'transformed_metadata' and contains metadata of the transformed data. The second is 'transform_fn' and contains a SavedModel representing the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f9d841a-679f-4de7-a381-30a34f59d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(output_dir, DEBUG=False):\n",
    "    \n",
    "    # Context manager for tensorflow-transform.\n",
    "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "        \n",
    "        # resulting dataset and function is returned as transformed_dataset, transform_fn\n",
    "        transformed_dataset, transform_fn = (\n",
    "            (raw_data, raw_data_metadata) \n",
    "            # Combination of AnalyzeDataset and TransformDataset, equivalent to:\n",
    "            # transform_fn = AnalyzeDataset(preprocessing_fn).expand(dataset)\n",
    "            # transformed = TransformDataset().expand((dataset, transform_fn))\n",
    "            | tft_beam.AnalyzeAndTransformDataset(\n",
    "                # A function that accepts and returns a dict from strings to `Tensor` or `SparseTensor`s.\n",
    "                preprocessing_fn\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        # for higher performance, could use tfxio\n",
    "        \"\"\"\n",
    "        csv_tfxio = tfxio.BeamRecordCsvTFXIO(                                                                                                                                                                                                                                                                                                                                    \n",
    "            physical_format='text',                                                                                                                                                                                                                                                                                                                                              \n",
    "            column_names=CSV_COLUMNS,                                                                                                                                                                                                                                                                                                                                            \n",
    "            schema=_SCHEMA\n",
    "        )                                                                                                                                                                                                                                                                                                                                                      \n",
    "        raw_data = (                                                                                                                                                                                                                                                                                                                                                             \n",
    "            pipeline                                                                                                                                                                                                                                                                                                                                                             \n",
    "            | 'ReadTrainData' >> beam.io.ReadFromText(file_pattern=train_file_path, coder=beam.coders.BytesCoder(), skip_header_lines=1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
    "            | 'DecodeTrainData' >> csv_tfxio.BeamSource()                                                                                                                                                                                                       \n",
    "        )                                                                                                                                                                                                                                                                                                                                                                    \n",
    "        raw_dataset = (raw_data, csv_tfxio.TensorAdapterConfig())                                                                                                                                                                                                                                                                                                                \n",
    "\n",
    "        transformed_dataset, transform_fn = (                                                                                                                                                                                                                                                                                                                                    \n",
    "            raw_dataset | tft_beam.AnalyzeAndTransformDataset(                                                                                                                                                                                                                                                                                                                   \n",
    "                preprocessing_fn, output_record_batches=True))                                                                                                                                                                                                                                                                                                                   \n",
    "        \"\"\"\n",
    "    \n",
    "\n",
    "    if DEBUG:\n",
    "        HR()\n",
    "        print(f\"******* transformed_dataset:\\n\\n{transformed_dataset}\")\n",
    "        HR()\n",
    "        HR()\n",
    "        print(f\"======= transform_fn:\\n\\n{transform_fn}\")\n",
    "        HR()\n",
    "    \n",
    "    transformed_data, transformed_metadata = transformed_dataset\n",
    "    \n",
    "    # Save the transform_fn to the output_dir\n",
    "    _ = (\n",
    "        transform_fn | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir)\n",
    "    )\n",
    "    \n",
    "    # list, tensorflow_transform.beam.tft_beam_io.beam_metadata_io.BeamDatasetMetadata\n",
    "    # We don't return transform_fn, since we instead save it to disk above....?\n",
    "    return transformed_data, transformed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b106fe68-d82b-407c-b9c4-4a47c5728fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Start of calling function main()\n",
      "---> preprocessing_fn CALLED FROM: transform_fn\n",
      "---> preprocessing_fn CALLED FROM: metadata_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/Users/gb/Desktop/python-3.8.12/env/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/Users/gb/Library/Jupyter/runtime/kernel-e11aa401-ad8b-469b-af8e-4a89a89fa439.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> preprocessing_fn CALLED FROM: transform_fn\n",
      "---> preprocessing_fn CALLED FROM: transform_fn\n",
      "---> preprocessing_fn CALLED FROM: metadata_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/Users/gb/Desktop/python-3.8.12/env/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/Users/gb/Library/Jupyter/runtime/kernel-e11aa401-ad8b-469b-af8e-4a89a89fa439.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "** Exited function main()\n",
      "TYPE: transformed_data <class 'list'>\n",
      "TYPE: transformed_metadata: <class 'tensorflow_transform.beam.tft_beam_io.beam_metadata_io.BeamDatasetMetadata'>\n",
      "----------------------------------------\n",
      "Raw data:\n",
      "[ {'s': 'hello', 'x': 1, 'y': 1},\n",
      "  {'s': 'world', 'x': 2, 'y': 2},\n",
      "  {'s': 'hello', 'x': 3, 'y': 3}]\n",
      "----------------------------------------\n",
      "Transformed data:\n",
      "[ { 's_integerized': 0,\n",
      "    'x_centered': -1.0,\n",
      "    'x_centered_times_y_normalized': -0.0,\n",
      "    'y_normalized': 0.0},\n",
      "  { 's_integerized': 1,\n",
      "    'x_centered': 0.0,\n",
      "    'x_centered_times_y_normalized': 0.0,\n",
      "    'y_normalized': 0.5},\n",
      "  { 's_integerized': 0,\n",
      "    'x_centered': 1.0,\n",
      "    'x_centered_times_y_normalized': 1.0,\n",
      "    'y_normalized': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ts = datetime.timestamp(datetime.now())\n",
    "output_dir = pathlib.Path(f\"tft_01_simple/output_{int(ts)}\")\n",
    "print(\"** Start of calling function main()\")\n",
    "transformed_data, transformed_metadata = main(str(output_dir), DEBUG=False)\n",
    "\n",
    "HR() \n",
    "print(\"** Exited function main()\")\n",
    "print(f\"TYPE: transformed_data {type(transformed_data)}\") # list\n",
    "print(f\"TYPE: transformed_metadata: {type(transformed_metadata)}\") # tensorflow_transform.beam.tft_beam_io.beam_metadata_io.BeamDatasetMetadata\n",
    "\n",
    "HR()\n",
    "\n",
    "print(f\"Raw data:\\n{pp.pformat(raw_data)}\")\n",
    "HR()\n",
    "print(f\"Transformed data:\\n{pp.pformat(transformed_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c81736b-1132-4f85-b103-768b7be1570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n",
      "\n",
      "asset_map                               count                                   dataset_metadata                        deferred_metadata                       index                                   schema                                  "
     ]
    }
   ],
   "source": [
    "dir_ex(tft.beam.tft_beam_io.beam_metadata_io.BeamDatasetMetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "863e03ad-dd55-410e-9377-d41e4c8ff0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mtft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtft_beam_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_metadata_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeamDatasetMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdataset_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdeferred_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0masset_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A class like DatasetMetadata also holding `PCollection`s and an asset_map.\n",
       "\n",
       "`deferred_metadata` is a PCollection containing a single DatasetMetadata.\n",
       "`asset_map` is a Dictionary mapping asset keys to filenames.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Desktop/python-3.8.12/env/lib/python3.8/site-packages/tensorflow_transform/beam/tft_beam_io/beam_metadata_io.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tft.beam.tft_beam_io.beam_metadata_io.BeamDatasetMetadata?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3549b2-8d06-483a-9cc6-7d79195d61fd",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='7.0'></a><a name='7.0'></a>\n",
    "# 7. Is this the right answer?\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c741b94-c58b-4637-afd6-397b4e2af83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_test = ['x_centered', 's_integerized', 'x_centered_times_y_normalized', 'y_normalized']\n",
    "\n",
    "results = {\n",
    "    'x_centered' :[-1.0, 0.0, 1.0],\n",
    "    's_integerized':[0, 1, 0],\n",
    "    'x_centered_times_y_normalized':[-0.0, 0.0, 1.0],\n",
    "    'y_normalized':[0.0, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for x in keys_test:\n",
    "    value = list(map(lambda key: key[x], transformed_data))\n",
    "    #print(f\"{x}: transformed: {value}, should be:{results[x]}\")\n",
    "    assert value == results[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9bf57eb-3bcc-431b-92d3-98f5e814a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative style of extracting data and running assert\n",
    "assert [x['x_centered'] for x in transformed_data] == results['x_centered']\n",
    "assert [x['s_integerized'] for x in transformed_data] == results['s_integerized']\n",
    "assert [x['x_centered_times_y_normalized'] for x in transformed_data] == results['x_centered_times_y_normalized']\n",
    "assert [x['y_normalized'] for x in transformed_data] == results['y_normalized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec28b2-acfc-4694-92b9-dd46b9b30af6",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='8.0'></a><a name='8.0'></a>\n",
    "# 8. Use the resulting transform_fn\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "359a2031-4565-4243-a709-d8a9b063788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0K\ttft_01_simple/output_1658933910/transform_fn/variables\n",
      "4.0K\ttft_01_simple/output_1658933910/transform_fn/assets\n",
      " 40K\ttft_01_simple/output_1658933910/transform_fn\n",
      "8.0K\ttft_01_simple/output_1658933910/transformed_metadata\n"
     ]
    }
   ],
   "source": [
    "!du -h {output_dir}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bb18c-5a79-497b-81f8-c1c57156f7dd",
   "metadata": {},
   "source": [
    "---\n",
    "The `transform_fn/` directory contains a `tf.saved_model` implementing all the constants that tensorflow analysis builds into the graph.\n",
    "\n",
    "It is possible to load this directly with `tf.saved_model.load` but this is awkward to use.\n",
    "\n",
    "---\n",
    "https://www.tensorflow.org/api_docs/python/tf/saved_model/load\n",
    "\n",
    "Keras models are trackable, so they can be saved to SavedModel. \n",
    "\n",
    "However, the object returned by `tf.saved_model.load` is not a Keras object (i.e. doesn't have .fit, .predict, etc. methods). A few attributes and functions are still available: .variables, .trainable_variables and .__call__.\n",
    "\n",
    "At the minimum, `tf.saved_model.load` returns a trackable object with a signatures attribute mapping from signature keys to functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b5b8cba-ab60-46a7-8686-d3903aa29519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>\n",
      "\n",
      "assets                                  created_variables                       graph_debug_info                        initializers                            resources                               signatures                              tensorflow_git_version                  tensorflow_version                      trackable_objects                       transform_fn                            "
     ]
    }
   ],
   "source": [
    "# Create a `trackable` object.\n",
    "# This is a trackable object with a signatures attribute mapping from signature keys to functions\n",
    "loaded = tf.saved_model.load(str(output_dir/'transform_fn'))\n",
    "\n",
    "dir_ex(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0092d36-7abf-49c5-8e55-284386396b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, inputs_1, inputs, inputs_2) at 0x159C34640>})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the signature map. We use the signature key 'serving_default'\n",
    "loaded.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dee5aa26-cc91-422f-940f-e4604fdb79f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.saved_model.load._WrapperFunction'>\n",
      "\n",
      "add_gradient_functions_to_graph         add_to_graph                            captured_inputs                         function_def                            graph                                   inputs                                  name                                    output_dtypes                           output_shapes                           outputs                                 pretty_printed_signature                replace_capture_with_deferred_capture   set_external_captures                   structured_input_signature              structured_outputs                      trainable_variables                     variables                               "
     ]
    }
   ],
   "source": [
    "# Create a wrapped concrete function\n",
    "wrapped_concrete_fn = loaded.signatures['serving_default']\n",
    "dir_ex(wrapped_concrete_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d2e571c-78a9-4132-ae53-c85a3ee0b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** wrapped_concrete_fn.inputs:\n",
      "[ <tf.Tensor 'inputs:0' shape=(None,) dtype=string>,\n",
      "  <tf.Tensor 'inputs_1:0' shape=(None,) dtype=float32>,\n",
      "  <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float32>,\n",
      "  <tf.Tensor 'unknown:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'unknown_0:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'unknown_1:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'unknown_2:0' shape=() dtype=float32>,\n",
      "  <tf.Tensor 'unknown_3:0' shape=() dtype=int64>,\n",
      "  <tf.Tensor 'unknown_4:0' shape=() dtype=int64>,\n",
      "  <tf.Tensor 'unknown_5:0' shape=() dtype=resource>,\n",
      "  <tf.Tensor 'unknown_6:0' shape=() dtype=int64>,\n",
      "  <tf.Tensor 'unknown_7:0' shape=() dtype=int64>]\n",
      "----------------------------------------\n",
      "***** wrapped_concrete_fn.outputs:\n",
      "[ <tf.Tensor 'Identity:0' shape=<unknown> dtype=int64>,\n",
      "  <tf.Tensor 'Identity_1:0' shape=(None,) dtype=float32>,\n",
      "  <tf.Tensor 'Identity_2:0' shape=(None,) dtype=float32>,\n",
      "  <tf.Tensor 'Identity_3:0' shape=(None,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.constant(\"This is string\")\n",
    "inputs_1 = tf.constant([1.1, 2.2, 3.3], dtype=tf.float32)\n",
    "inputs_2 = tf.constant(1.3, dtype=tf.float32)\n",
    "\n",
    "wrapped_concrete_fn(inputs=inputs, inputs_1=inputs_1, inputs_2=inputs_2)\n",
    "\n",
    "# Returns tensors in `self.graph` corresponding to returned tensors.\n",
    "print(\"***** wrapped_concrete_fn.inputs:\")\n",
    "pp.pprint(wrapped_concrete_fn.inputs)\n",
    "HR()\n",
    "\n",
    "print(\"***** wrapped_concrete_fn.outputs:\")\n",
    "pp.pprint(wrapped_concrete_fn.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73de3360-616e-4793-8b55-b70abb01985a",
   "metadata": {},
   "source": [
    "---\n",
    "A better approach is to load transform_fn using `tft.TRTransformOutput`. \n",
    "\n",
    "The `TFTransformOutput.transform_features_layer` method returns a `tft.TransformFeaturesLayer` object that can be used to apply the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62788443-5d68-46ba-90b8-8d310decb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature: tft.TFTransformOutput.transform_features_layer(self) -> keras.engine.training.Model\n",
    "# Creates a `TransformFeaturesLayer` from this transform output.\n",
    "\n",
    "tft_layer: tft.output_wrapper.TransformFeaturesLayer = tft.TFTransformOutput(output_dir).transform_features_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c08aff5-ce4d-4a11-8112-59c0d7d2f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow_transform.output_wrapper.TransformFeaturesLayer'>\n",
      "\n",
      "activity_regularizer                    add_loss                                add_metric                              add_update                              add_variable                            add_weight                              apply                                   build                                   built                                   call                                    compile                                 compiled_loss                           compiled_metrics                        compute_dtype                           compute_loss                            compute_mask                            compute_metrics                         compute_output_shape                    compute_output_signature                count_params                            distribute_strategy                     dtype                                   dtype_policy                            dynamic                                 evaluate                                evaluate_generator                      finalize_state                          fit                                     fit_generator                           from_config                             get_config                              get_input_at                            get_input_mask_at                       get_input_shape_at                      get_layer                               get_losses_for                          get_output_at                           get_output_mask_at                      get_output_shape_at                     get_updates_for                         get_weights                             history                                 inbound_nodes                           input                                   input_mask                              input_names                             input_shape                             input_spec                              inputs                                  layers                                  load_weights                            losses                                  make_predict_function                   make_test_function                      make_train_function                     metrics                                 metrics_names                           name                                    name_scope                              non_trainable_variables                 non_trainable_weights                   optimizer                               outbound_nodes                          output                                  output_mask                             output_names                            output_shape                            outputs                                 predict                                 predict_function                        predict_generator                       predict_on_batch                        predict_step                            reset_metrics                           reset_states                            run_eagerly                             save                                    save_spec                               save_weights                            set_weights                             state_updates                           stateful                                stop_training                           submodules                              summary                                 supports_masking                        test_function                           test_on_batch                           test_step                               to_json                                 to_yaml                                 train_function                          train_on_batch                          train_step                              train_tf_function                       trainable                               trainable_variables                     trainable_weights                       updates                                 variable_dtype                          variables                               weights                                 with_name_scope                         "
     ]
    }
   ],
   "source": [
    "dir_ex(tft_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d11ed41-ed91-4cac-a68a-4a50bfecde7d",
   "metadata": {},
   "source": [
    "---\n",
    "This `tft.TransformFeaturesLayer` expects a dictionary of batched features. \n",
    "\n",
    "Accordingly, we create a `Dict[str, tf.Tensor]` from the `List[Dict[str, Any]]` in `raw_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6bd1abe4-b95f-480d-9a86-8c8047d2664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 1, 'y': 1, 's': 'hello'},\n",
       " {'x': 2, 'y': 2, 's': 'world'},\n",
       " {'x': 3, 'y': 3, 's': 'hello'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what raw_data contains\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b5a3d04-7c25-4a8a-9874-c5228c6c033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'hello', b'world', b'hello'], dtype=object)>,\n",
       " 'x': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n",
       " 'y': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract individual columns via list-comprehension\n",
    "raw_data_batch = {\n",
    "    's': tf.constant([ex['s'] for ex in raw_data]),\n",
    "    'x': tf.constant([ex['x'] for ex in raw_data], dtype=tf.float32),\n",
    "    'y': tf.constant([ex['y'] for ex in raw_data], dtype=tf.float32),\n",
    "}\n",
    "\n",
    "raw_data_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e5968-d8f2-4d64-a5e4-db24277fbf67",
   "metadata": {},
   "source": [
    "---\n",
    "You can use `tft.TransformFeaturesLayer` on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b5c7556-a075-4dd2-9fbe-711136bd2eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_centered': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-1.,  0.,  1.], dtype=float32)>,\n",
       " 'y_normalized': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0. , 0.5, 1. ], dtype=float32)>,\n",
       " 's_integerized': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 0])>,\n",
       " 'x_centered_times_y_normalized': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.,  0.,  1.], dtype=float32)>}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_batch = tft_layer(raw_data_batch)\n",
    "\n",
    "# Examine the structure of transformed_batch\n",
    "transformed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "590dd95c-745e-4b6f-bc59-46b03c8b332a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_centered': array([-1.,  0.,  1.], dtype=float32),\n",
       " 'y_normalized': array([0. , 0.5, 1. ], dtype=float32),\n",
       " 's_integerized': array([0, 1, 0]),\n",
       " 'x_centered_times_y_normalized': array([-0.,  0.,  1.], dtype=float32)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since transformed_batch is a dict, use .items() to iterate over it\n",
    "{key: value.numpy() for key, value in transformed_batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe54f3c-9b01-424c-a61f-ac1071ab2e81",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='9.0'></a><a name='9.0'></a>\n",
    "# 9. Export\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "A more typical use case would use `tf.Transform` to apply the transformation to the training and evaluation datasets (see the [**Census tutorial**](https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/transform/census.ipynb) for an example). \n",
    "\n",
    "After training, before exporting the model, attach the `tft.TransformFeaturesLayer` as the first layer so that you can export it as part of your `tf.saved_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0277662-f3c9-4286-975c-2301ee8b42fb",
   "metadata": {},
   "source": [
    "<a id='9.1'></a><a name='9.1'></a>\n",
    "## 9.1 An example training model\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Below is a model that:\n",
    "\n",
    "1. Takes the transformed batch\n",
    "2. Stacks the batch together in a simple `(batch, features)` matrix.\n",
    "3. Runs them through a few dense layers\n",
    "4. Produces 10 linear outputs\n",
    "\n",
    "In a real use case, you would apply a one-hot encoding to the `s_integerized` feature.\n",
    "\n",
    "You could train this model on a dataset transformed by `tf.Transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f55300b-458c-4f42-ab7e-2f62e763a3f1",
   "metadata": {},
   "source": [
    "# GB: Try to redo this using only functions (eg create a model_builder function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1680b8-b17d-4d89-8e8c-fddc6a2bebf4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Notes on tf.keras.layers.Layer \n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer\n",
    "\n",
    "A layer is a callable object that takes as input one or more tensors and that outputs one or more tensors. It involves computation, defined in the call() method, and a state (weight variables). State can be created in various places, at the convenience of the subclass implementer:\n",
    "\n",
    "* in `__init__()`\n",
    "\n",
    "* in the optional `build()` method, which is invoked by the first `__call__()` to the layer, and supplies the shape(s) of the input(s), which may not have been known at initialization time\n",
    "\n",
    "* in the first invocation of `call()`, with some caveats\n",
    "\n",
    "Users will just instantiate a layer and then treat it as a callable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27a82bfb-bce9-4118-9f04-94b225913821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  -1.  -0.   0. ]\n",
      " [ 1.   0.   0.   0.5]\n",
      " [ 0.   1.   1.   1. ]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# child class StackDict inherits from tf.keras.layers.Layer\n",
    "# tf.keras.layers.Layer is the class from which all layers inherit.\n",
    "# Since we don't call __init__, we inherit all of the methods and attributes\n",
    "# of parent tf.keras.layers.Layer as-is.\n",
    "\n",
    "# We use the .call method here to create a callable object, so we\n",
    "# can treat it more like a function. We are not interested in creating \n",
    "# any new attributes or customizing inherited ones, hence the lack of __init__ method here.\n",
    "\n",
    "# Remember, we call the parent class __init__() method to get access to \n",
    "# all the attributes defined in the parent class __init__ method, if they exist.\n",
    "\n",
    "class StackDict(tf.keras.layers.Layer):\n",
    "    \n",
    "    # This is where the layer's logic lives.\n",
    "    # The call() method may not create state (except in its first invocation, \n",
    "    # wrapping the creation of variables or other resources in tf.init_scope()). \n",
    "    # It is recommended to create state in __init__(), or the build() method that \n",
    "    # is called automatically before call() executes the first time.\n",
    "    # Returns a tensor or list/tuple of tensors. \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call\n",
    "    # https://github.com/keras-team/keras/blob/v2.9.0/keras/engine/base_layer.py#L485-L528\n",
    "    def call(self, inputs):\n",
    "        values = [\n",
    "            tf.cast(v, tf.float32)\n",
    "            for k,v in sorted(inputs.items(), key=lambda kv: kv[0])\n",
    "        ]\n",
    "        return tf.stack(values, axis=1)\n",
    "    \n",
    "    \n",
    "# Test\n",
    "stack_dict_method = StackDict()\n",
    "print(stack_dict_method(transformed_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "578e0bac-956d-4f2d-9c0e-025e16ca1fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.StackDict'>\n",
      "\n",
      "activity_regularizer                    add_loss                                add_metric                              add_update                              add_variable                            add_weight                              apply                                   build                                   built                                   call                                    compute_dtype                           compute_mask                            compute_output_shape                    compute_output_signature                count_params                            dtype                                   dtype_policy                            dynamic                                 finalize_state                          from_config                             get_config                              get_input_at                            get_input_mask_at                       get_input_shape_at                      get_losses_for                          get_output_at                           get_output_mask_at                      get_output_shape_at                     get_updates_for                         get_weights                             inbound_nodes                           input                                   input_mask                              input_shape                             input_spec                              losses                                  metrics                                 name                                    name_scope                              non_trainable_variables                 non_trainable_weights                   outbound_nodes                          output                                  output_mask                             output_shape                            set_weights                             stateful                                submodules                              supports_masking                        trainable                               trainable_variables                     trainable_weights                       updates                                 variable_dtype                          variables                               weights                                 with_name_scope                         None\n"
     ]
    }
   ],
   "source": [
    "print(dir_ex(stack_dict_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9c2d9-fb02-4b3d-a5bc-74227a9f167b",
   "metadata": {},
   "source": [
    "## Notes (tf.keras.Model):\n",
    "\n",
    "There are two ways to instantiate a `tf.keras.Model`:\n",
    "\n",
    "1. With the \"Functional API\". This is not used here.\n",
    "\n",
    "2. By subclassing the `Model` class (used here). In this case, you should define your\n",
    "layers in `__init__()` and you should implement the model's forward pass\n",
    "in `call()`.\n",
    "\n",
    "This method should not be called directly. It is only meant to be\n",
    "overridden when subclassing `tf.keras.Model`.\n",
    "To call a model on an input, always use the `__call__()` method,\n",
    "i.e. `model(inputs)`, which relies on the underlying `call()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "004d7516-41a3-429c-8143-b78508e38bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainedModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # By using the __init__() function with super(), this child class \n",
    "        # will inherit all the methods and properties from its parent tf.keras.Model)\n",
    "        super().__init__(self)\n",
    "        self.concat = StackDict()\n",
    "        self.body = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ])\n",
    "    \n",
    "    # GB: This is NOT the Python __call__ mechanism.\n",
    "    def call(self, inputs, training=None):\n",
    "    #def __call__(self, inputs, training=None):\n",
    "        x = self.concat(inputs)\n",
    "        print(\"===== class TrainedModel, function call() =====\\n\")\n",
    "        print(\"THIS IS input x:\\n\", x)\n",
    "        print(\"THIS IS input training:\\n\", training)\n",
    "        HR()\n",
    "        return self.body(x, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3def49c7-8fe9-4bfb-8bc6-9b8f6b0bb308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.TrainedModel'>\n",
      "\n",
      "activity_regularizer                    add_loss                                add_metric                              add_update                              add_variable                            add_weight                              apply                                   body                                    build                                   built                                   call                                    compile                                 compiled_loss                           compiled_metrics                        compute_dtype                           compute_loss                            compute_mask                            compute_metrics                         compute_output_shape                    compute_output_signature                concat                                  count_params                            distribute_strategy                     dtype                                   dtype_policy                            dynamic                                 evaluate                                evaluate_generator                      finalize_state                          fit                                     fit_generator                           from_config                             get_config                              get_input_at                            get_input_mask_at                       get_input_shape_at                      get_layer                               get_losses_for                          get_output_at                           get_output_mask_at                      get_output_shape_at                     get_updates_for                         get_weights                             history                                 inbound_nodes                           input                                   input_mask                              input_names                             input_shape                             input_spec                              inputs                                  layers                                  load_weights                            losses                                  make_predict_function                   make_test_function                      make_train_function                     metrics                                 metrics_names                           name                                    name_scope                              non_trainable_variables                 non_trainable_weights                   optimizer                               outbound_nodes                          output                                  output_mask                             output_names                            output_shape                            outputs                                 predict                                 predict_function                        predict_generator                       predict_on_batch                        predict_step                            reset_metrics                           reset_states                            run_eagerly                             save                                    save_spec                               save_weights                            set_weights                             state_updates                           stateful                                stop_training                           submodules                              summary                                 supports_masking                        test_function                           test_on_batch                           test_step                               to_json                                 to_yaml                                 train_function                          train_on_batch                          train_step                              train_tf_function                       trainable                               trainable_variables                     trainable_weights                       updates                                 variable_dtype                          variables                               weights                                 with_name_scope                         "
     ]
    }
   ],
   "source": [
    "# This only calls __init__ of TrainedModel, not call().\n",
    "# We access call() by first creating an instance, then using call() on that instance.\n",
    "trained_model = TrainedModel()\n",
    "\n",
    "dir_ex(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "529c515a-cf5f-4750-a573-a9e9ea49f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n"
     ]
    }
   ],
   "source": [
    "# Need to call the model on a batch of data first:\n",
    "try:\n",
    "    trained_model.summary()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d9f62-8922-4913-a289-1b6423b01f58",
   "metadata": {},
   "source": [
    "---\n",
    "Imagine we trained the model:\n",
    "\n",
    "```\n",
    "trained_model.compile(loss=..., optimizer='adam')\n",
    "trained_model.fit(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfbea0-091d-4d89-b0ac-b665723e873f",
   "metadata": {},
   "source": [
    "---\n",
    "This model runs on the transformed inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c8baaba-4b6e-4e33-8d0f-02667ab8fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " tf.Tensor(\n",
      "[[ 0.  -1.  -0.   0. ]\n",
      " [ 1.   0.   0.   0.5]\n",
      " [ 0.   1.   1.   1. ]], shape=(3, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " None\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use trained_model() like a callable, via its .call() wrapper method.\n",
    "trained_model_output = trained_model(transformed_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d957418-6d41-41f8-b680-6e14e6d09f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2731171e-2267-4002-999e-8a51f839299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"trained_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " stack_dict_4 (StackDict)    multiple                  0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (3, 10)                   5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model was called on a batch of data, so we can now run model.summary()\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08b17e-aec1-491c-b1de-b84dd9d65d36",
   "metadata": {},
   "source": [
    "<a id='9.2'></a><a name='9.2'></a>\n",
    "## 9.2 An example export wrapper\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Image you've trained the above model and want to export it.\n",
    "\n",
    "You'll want to include the transform function in the exported model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ca99102-5cfa-4787-9586-bbce491dd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExportModel inherits from the parent tf.Module\n",
    "class ExportModel(tf.Module):\n",
    "    # Override creation of attributes here\n",
    "    def __init__(self, trained_model, input_transform):\n",
    "        self.trained_model = trained_model\n",
    "        self.input_transform = input_transform\n",
    "        print(\"INSIDE __init__\")\n",
    "        print(f\"self.trained_model: {self.trained_model}\")\n",
    "        print(f\"self.input_transform: {self.input_transform}\")\n",
    "        HR()\n",
    "        \n",
    "    @tf.function\n",
    "    # Create callable-type mechanism via __call__, so we can use as pseudo-function call.\n",
    "    def __call__(self, inputs, training=None):\n",
    "        x = self.input_transform(inputs)\n",
    "        print(f\"*** ExportModel call(),  inputs:\\n\")\n",
    "        pp.pprint(inputs)\n",
    "        HR()\n",
    "        return self.trained_model(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e05c914f-b399-4981-9db4-5b56f330b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSIDE __init__\n",
      "self.trained_model: <__main__.TrainedModel object at 0x159bbac10>\n",
      "self.input_transform: <tensorflow_transform.output_wrapper.TransformFeaturesLayer object at 0x158871c40>\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Call __init__ method of ExportModel here (not the __call__ method)\n",
    "export_model = ExportModel(\n",
    "    trained_model = trained_model,\n",
    "    input_transform = tft_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c228a4f6-c926-46fd-8943-b567018a55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.ExportModel'>\n",
      "\n",
      "input_transform                         name                                    name_scope                              non_trainable_variables                 submodules                              trainable_variables                     trained_model                           variables                               with_name_scope                         "
     ]
    }
   ],
   "source": [
    "dir_ex(export_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859286f1-8f44-4685-b925-dfb93cb48c6a",
   "metadata": {},
   "source": [
    "---\n",
    "This combined model works on the raw data, and produces exactly the same results as calling the trained model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d06f5fa-73a7-42ab-bbbb-5a3d08ef3551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ExportModel call(),  inputs:\n",
      "\n",
      "{ 's': <tf.Tensor 'inputs:0' shape=(3,) dtype=string>,\n",
      "  'x': <tf.Tensor 'inputs_1:0' shape=(3,) dtype=float32>,\n",
      "  'y': <tf.Tensor 'inputs_2:0' shape=(3,) dtype=float32>}\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"trained_model_1/stack_dict_4/stack:0\", shape=(3, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " None\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
       "array([[ 0.023,  0.099, -0.094,  0.124, -0.126,  0.105, -0.083, -0.26 ,\n",
       "        -0.058, -0.018],\n",
       "       [ 0.085, -0.051, -0.146,  0.19 , -0.227,  0.071, -0.071, -0.191,\n",
       "        -0.108, -0.178],\n",
       "       [ 0.15 ,  0.011, -0.01 ,  0.059, -0.272, -0.092, -0.172, -0.096,\n",
       "        -0.073, -0.298]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acess ExportModel's __call__ as a callable.\n",
    "export_model_output = export_model(raw_data_batch)\n",
    "export_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "562cf4b8-de3f-407c-842f-0f967e210f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d96a2cac-a50e-44ca-af81-514412cb6489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(abs(export_model_output - trained_model_output)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693c5fc-7195-4059-b28f-74b3ffb40028",
   "metadata": {},
   "source": [
    "---\n",
    "This `export_model` includes the `tft.TransformFeaturesLayer` and is entirely self-contained. You can save it and restore it in another environment and still get exactly the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9034bc44-7759-450e-9126-d836b0cc1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ExportModel call(),  inputs:\n",
      "\n",
      "{ 's': <tf.Tensor 'inputs/s:0' shape=(3,) dtype=string>,\n",
      "  'x': <tf.Tensor 'inputs/x:0' shape=(3,) dtype=float32>,\n",
      "  'y': <tf.Tensor 'inputs/y:0' shape=(3,) dtype=float32>}\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"trained_model_1/stack_dict_4/stack:0\", shape=(3, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " None\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"trained_model_1/stack_dict_4/stack:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " False\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/PartitionedCall:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " False\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/PartitionedCall:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " True\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/PartitionedCall:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " False\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/PartitionedCall:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " True\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/stack:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " False\n",
      "----------------------------------------\n",
      "===== class TrainedModel, function call() =====\n",
      "\n",
      "THIS IS input x:\n",
      " Tensor(\"stack_dict_4/stack:0\", shape=(None, 4), dtype=float32)\n",
      "THIS IS input training:\n",
      " True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ts = datetime.timestamp(datetime.now())\n",
    "model_dir = str(pathlib.Path(f\"tft_01_model/output_{int(ts)}\"))\n",
    "\n",
    "tf.saved_model.save(export_model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55d9f951-c3e1-4f98-8163-a9140f9b4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x1599e7610>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded = tf.saved_model.load(model_dir)\n",
    "reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "784bb20d-9cc8-4aaf-b764-152ff413a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
       "array([[ 0.023,  0.099, -0.094,  0.124, -0.126,  0.105, -0.083, -0.26 ,\n",
       "        -0.058, -0.018],\n",
       "       [ 0.085, -0.051, -0.146,  0.19 , -0.227,  0.071, -0.071, -0.191,\n",
       "        -0.108, -0.178],\n",
       "       [ 0.15 ,  0.011, -0.01 ,  0.059, -0.272, -0.092, -0.172, -0.096,\n",
       "        -0.073, -0.298]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model_output = reloaded(raw_data_batch)\n",
    "reloaded_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ca1ec6b-39ef-4086-bcb2-8c574f2bb391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91eebd28-e065-4891-bc99-b6a547c7a73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(abs(export_model_output - reloaded_model_output)).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
