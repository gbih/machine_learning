{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103ba989-19d7-4ffa-8c04-268e69056a0d",
   "metadata": {
    "id": "103ba989-19d7-4ffa-8c04-268e69056a0d"
   },
   "source": [
    "<a id='top'></a>\n",
    "<a name=\"top\"></a><!--Need for Colab-->\n",
    "# Extra: KerasTuner (deep learning models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5243db4-e2b5-4745-9037-2e0642d7ce77",
   "metadata": {
    "id": "d5243db4-e2b5-4745-9037-2e0642d7ce77"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/gbih/ml-notes/blob/main/book_hands_on/20_01_kerastuner_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de02c8-71f6-48a0-af27-1dd3ec7d2177",
   "metadata": {
    "id": "41de02c8-71f6-48a0-af27-1dd3ec7d2177"
   },
   "source": [
    "1. [Setup](#setup)\n",
    "2. [Overview](#2.0)\n",
    "2. [Examples](#3.0)\n",
    "    * 3.1 [Keras Tuner with Hyperband](#3.1)\n",
    "    * 3.2 [Keras Tuner with BayesianOptimization](#3.2)\n",
    "    * 3.3 [neptune.ai article](#3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdfbf6-ee8d-429e-b523-8d4fd3210aae",
   "metadata": {
    "id": "89cdfbf6-ee8d-429e-b523-8d4fd3210aae"
   },
   "source": [
    "---\n",
    "<a name=\"setup\"></a>\n",
    "# 1. Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168f0980-94d2-49ad-885b-098e9b122307",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168f0980-94d2-49ad-885b-098e9b122307",
    "outputId": "957ff32d-cb56-4413-c0de-b9c3e61ee5b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Keras Tuner\n",
      "\u001b[K     |████████████████████████████████| 135 kB 32.9 MB/s \n",
      "\u001b[?25hLoaded libraries..\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "# global seed\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "# Need to install keras_tuner on colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    print(\"Installing Keras Tuner\")\n",
    "    !pip install -q -U keras-tuner \n",
    "\n",
    "import keras_tuner as kt\n",
    "    \n",
    "def HR():\n",
    "    print(\"-\"*40)    \n",
    "\n",
    "print(\"Loaded libraries..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c55d93d-5d77-4f48-bd02-bf66eaf56e2c",
   "metadata": {
    "id": "7c55d93d-5d77-4f48-bd02-bf66eaf56e2c"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = 'data_chp20_kt'\n",
    "data_dir = Path() / DATA_ROOT\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bd966-b656-4e87-987b-25065afce3a2",
   "metadata": {
    "id": "ae3bd966-b656-4e87-987b-25065afce3a2"
   },
   "source": [
    "---\n",
    "<a name=\"2.0\"></a>\n",
    "# 2. Overview\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called hyperparameter tuning or hypertuning.\n",
    "\n",
    "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
    "\n",
    "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
    "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier\n",
    "\n",
    "In this tutorial, you will use the Keras Tuner to perform hypertuning for an image classification application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681cbb42-c0f3-413a-a5f7-015037b9c1b2",
   "metadata": {
    "id": "681cbb42-c0f3-413a-a5f7-015037b9c1b2"
   },
   "source": [
    "---\n",
    "<a name=\"3.0\"></a>\n",
    "# 3. Examples\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Simple framework for setting up data, passing tuner, model fitting and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "HKY4PMGwlSvL",
   "metadata": {
    "id": "HKY4PMGwlSvL"
   },
   "outputs": [],
   "source": [
    "# Define the hypermodel for standard MLP model\n",
    "\n",
    "# Part 1:\n",
    "\n",
    "def model_builder(hp):\n",
    "    print(\"== Calling model_builder.\")\n",
    "    print(\"hp.values:\")\n",
    "    pp.pprint(hp.values)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(keras.layers.Dropout(rate=0.25))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    model.compile(\n",
    "        # Tune the learning rate for the optimizer\n",
    "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [0.01, 0.001, 0.0001])),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(\"== Exiting model_builder.\")\n",
    "    HR()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def kt_framework(tuner):\n",
    "    \n",
    "    # Download and prepare the dataset\n",
    "    (img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "        \n",
    "    # Check if int or float. \n",
    "    # If int, model loss is 'SparseCategoricalCrossentropy'\n",
    "    label_choices = len(np.unique(label_train))\n",
    "\n",
    "    # Normalize pixel values between 0 and 1\n",
    "    img_train = img_train.astype('float32') / 255.0\n",
    "    img_test = img_test.astype('float32') / 255.0\n",
    "\n",
    "    # Tuner passed as parameter\n",
    "\n",
    "    HR()\n",
    "\n",
    "    # Callback to stop training after reaching a certain value for the validation\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5\n",
    "    )\n",
    "    \n",
    "    # Run the hyperparameter search\n",
    "    # Same API to model.fit()\n",
    "    print(\"Run the hyperparameter search.\")\n",
    "    tuner.search(\n",
    "        img_train, \n",
    "        label_train,\n",
    "        epochs=50,\n",
    "        #epochs=20,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[stop_early],\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    ####################################\n",
    "\n",
    "    # Part 2:\n",
    "    \n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"===== The hyperparameter search is complete =====\")\n",
    "    pp.pprint(best_hps.values)\n",
    "        \n",
    "    # Train the model\n",
    "    # Find the optimal number of epochs to train the model with the \n",
    "    # hyperparameters obtained from the search.\n",
    "    \n",
    "    # Build the model with the optimal hyperparameters and train it on the data for 50 epochs.\n",
    "    print(\"Build the model with the optimal hyperparameters and train it on the data for n-epochs.\")\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "    \n",
    "    history = model.fit(\n",
    "        img_train,\n",
    "        label_train,\n",
    "        epochs=50,\n",
    "        #epochs=2,\n",
    "        validation_split=0.2,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    val_acc_per_epoch = history.history['val_accuracy']\n",
    "    best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    HR()\n",
    "    \n",
    "    \n",
    "    # Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
    "    print(\"Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\")\n",
    "    hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    # Retrain the model\n",
    "    print(\"Retrain the model:\\n\")\n",
    "    hypermodel.fit(\n",
    "        img_train, \n",
    "        label_train, \n",
    "        epochs=best_epoch, \n",
    "        validation_split=0.2,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "\n",
    "    print(hypermodel.summary())\n",
    "    HR() \n",
    "\n",
    "    # Evaluate the hypermodel on the test data.\n",
    "    print(\"Evaluate the hypermodel on the test data.\")\n",
    "    eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "    print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "YA478mnGbUUH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA478mnGbUUH",
    "outputId": "22778f2b-e6ff-4850-f847-d54fa2fb99a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "# Quickly test if the model builds successfully.\n",
    "# keras_tuner.HyperParameters()\n",
    "# Container for both a hyperparameter space, and current values.\n",
    "# A HyperParameters instance can be pass to HyperModel.build(hp) as an argument to build a model.\n",
    "\n",
    "result = model_builder(kt.HyperParameters())\n",
    "print(type(result)) # keras.engine.sequential.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "njjr6_P8oykY",
   "metadata": {
    "id": "njjr6_P8oykY"
   },
   "source": [
    "<a name=\"3.1\"></a>\n",
    "## 3.1 Keras Tuner with HyperBand\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nwpkb3FjnZvX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwpkb3FjnZvX",
    "outputId": "2b64bac0-f1b4-484c-e2c2-e2265154e074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 38s]\n",
      "val_loss: 0.444957971572876\n",
      "\n",
      "Best val_loss So Far: 0.3163602948188782\n",
      "Total elapsed time: 00h 10m 08s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "----------------------------------------\n",
      "===== The hyperparameter search is complete =====\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.001,\n",
      "    'num_layers': 4,\n",
      "    'tuner/bracket': 0,\n",
      "    'tuner/epochs': 10,\n",
      "    'tuner/initial_epoch': 0,\n",
      "    'tuner/round': 0,\n",
      "    'units_0': 352,\n",
      "    'units_1': 384,\n",
      "    'units_2': 128,\n",
      "    'units_3': 96,\n",
      "    'units_4': 64}\n",
      "Build the model with the optimal hyperparameters and train it on the data for n-epochs.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.001,\n",
      "    'num_layers': 4,\n",
      "    'tuner/bracket': 0,\n",
      "    'tuner/epochs': 10,\n",
      "    'tuner/initial_epoch': 0,\n",
      "    'tuner/round': 0,\n",
      "    'units_0': 352,\n",
      "    'units_1': 384,\n",
      "    'units_2': 128,\n",
      "    'units_3': 96,\n",
      "    'units_4': 64}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.5421 - accuracy: 0.8065 - val_loss: 0.4048 - val_accuracy: 0.8552 - 4s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "1500/1500 - 4s - loss: 0.3941 - accuracy: 0.8577 - val_loss: 0.3994 - val_accuracy: 0.8567 - 4s/epoch - 3ms/step\n",
      "Epoch 3/50\n",
      "1500/1500 - 4s - loss: 0.3524 - accuracy: 0.8730 - val_loss: 0.3443 - val_accuracy: 0.8775 - 4s/epoch - 3ms/step\n",
      "Epoch 4/50\n",
      "1500/1500 - 4s - loss: 0.3265 - accuracy: 0.8790 - val_loss: 0.3328 - val_accuracy: 0.8795 - 4s/epoch - 3ms/step\n",
      "Epoch 5/50\n",
      "1500/1500 - 4s - loss: 0.3103 - accuracy: 0.8871 - val_loss: 0.3316 - val_accuracy: 0.8804 - 4s/epoch - 3ms/step\n",
      "Epoch 6/50\n",
      "1500/1500 - 4s - loss: 0.2939 - accuracy: 0.8920 - val_loss: 0.3338 - val_accuracy: 0.8788 - 4s/epoch - 3ms/step\n",
      "Epoch 7/50\n",
      "1500/1500 - 4s - loss: 0.2818 - accuracy: 0.8964 - val_loss: 0.3160 - val_accuracy: 0.8862 - 4s/epoch - 3ms/step\n",
      "Epoch 8/50\n",
      "1500/1500 - 4s - loss: 0.2705 - accuracy: 0.9006 - val_loss: 0.3175 - val_accuracy: 0.8888 - 4s/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "1500/1500 - 4s - loss: 0.2621 - accuracy: 0.9030 - val_loss: 0.3196 - val_accuracy: 0.8864 - 4s/epoch - 3ms/step\n",
      "Epoch 10/50\n",
      "1500/1500 - 4s - loss: 0.2495 - accuracy: 0.9067 - val_loss: 0.3612 - val_accuracy: 0.8827 - 4s/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "1500/1500 - 4s - loss: 0.2442 - accuracy: 0.9087 - val_loss: 0.3396 - val_accuracy: 0.8891 - 4s/epoch - 3ms/step\n",
      "Epoch 12/50\n",
      "1500/1500 - 4s - loss: 0.2324 - accuracy: 0.9147 - val_loss: 0.3460 - val_accuracy: 0.8868 - 4s/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "1500/1500 - 4s - loss: 0.2277 - accuracy: 0.9153 - val_loss: 0.3572 - val_accuracy: 0.8866 - 4s/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "1500/1500 - 4s - loss: 0.2204 - accuracy: 0.9166 - val_loss: 0.3284 - val_accuracy: 0.8930 - 4s/epoch - 3ms/step\n",
      "Epoch 15/50\n",
      "1500/1500 - 4s - loss: 0.2111 - accuracy: 0.9186 - val_loss: 0.3480 - val_accuracy: 0.8903 - 4s/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "1500/1500 - 4s - loss: 0.2077 - accuracy: 0.9209 - val_loss: 0.3528 - val_accuracy: 0.8911 - 4s/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "1500/1500 - 4s - loss: 0.2018 - accuracy: 0.9234 - val_loss: 0.3439 - val_accuracy: 0.8959 - 4s/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "1500/1500 - 4s - loss: 0.1993 - accuracy: 0.9251 - val_loss: 0.3671 - val_accuracy: 0.8932 - 4s/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "1500/1500 - 4s - loss: 0.1929 - accuracy: 0.9267 - val_loss: 0.3357 - val_accuracy: 0.8941 - 4s/epoch - 3ms/step\n",
      "Epoch 20/50\n",
      "1500/1500 - 5s - loss: 0.1838 - accuracy: 0.9303 - val_loss: 0.3606 - val_accuracy: 0.8914 - 5s/epoch - 3ms/step\n",
      "Epoch 21/50\n",
      "1500/1500 - 4s - loss: 0.1799 - accuracy: 0.9317 - val_loss: 0.4072 - val_accuracy: 0.8900 - 4s/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "1500/1500 - 4s - loss: 0.1789 - accuracy: 0.9327 - val_loss: 0.3995 - val_accuracy: 0.8891 - 4s/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "1500/1500 - 4s - loss: 0.1721 - accuracy: 0.9341 - val_loss: 0.4229 - val_accuracy: 0.8912 - 4s/epoch - 3ms/step\n",
      "Epoch 24/50\n",
      "1500/1500 - 4s - loss: 0.1700 - accuracy: 0.9357 - val_loss: 0.4480 - val_accuracy: 0.8988 - 4s/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "1500/1500 - 4s - loss: 0.1661 - accuracy: 0.9365 - val_loss: 0.4059 - val_accuracy: 0.8944 - 4s/epoch - 3ms/step\n",
      "Epoch 26/50\n",
      "1500/1500 - 4s - loss: 0.1603 - accuracy: 0.9398 - val_loss: 0.4204 - val_accuracy: 0.8942 - 4s/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "1500/1500 - 4s - loss: 0.1631 - accuracy: 0.9391 - val_loss: 0.4473 - val_accuracy: 0.8978 - 4s/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "1500/1500 - 4s - loss: 0.1524 - accuracy: 0.9414 - val_loss: 0.4336 - val_accuracy: 0.8915 - 4s/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "1500/1500 - 4s - loss: 0.1560 - accuracy: 0.9404 - val_loss: 0.4274 - val_accuracy: 0.8963 - 4s/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "1500/1500 - 4s - loss: 0.1524 - accuracy: 0.9419 - val_loss: 0.4518 - val_accuracy: 0.8947 - 4s/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "1500/1500 - 4s - loss: 0.1493 - accuracy: 0.9440 - val_loss: 0.4495 - val_accuracy: 0.8972 - 4s/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "1500/1500 - 4s - loss: 0.1445 - accuracy: 0.9453 - val_loss: 0.4208 - val_accuracy: 0.8982 - 4s/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "1500/1500 - 4s - loss: 0.1406 - accuracy: 0.9465 - val_loss: 0.5277 - val_accuracy: 0.8948 - 4s/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "1500/1500 - 4s - loss: 0.1408 - accuracy: 0.9474 - val_loss: 0.5440 - val_accuracy: 0.9013 - 4s/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "1500/1500 - 4s - loss: 0.1397 - accuracy: 0.9477 - val_loss: 0.5297 - val_accuracy: 0.8958 - 4s/epoch - 3ms/step\n",
      "Epoch 36/50\n",
      "1500/1500 - 4s - loss: 0.1322 - accuracy: 0.9487 - val_loss: 0.4830 - val_accuracy: 0.8945 - 4s/epoch - 3ms/step\n",
      "Epoch 37/50\n",
      "1500/1500 - 4s - loss: 0.1345 - accuracy: 0.9507 - val_loss: 0.5967 - val_accuracy: 0.8939 - 4s/epoch - 3ms/step\n",
      "Epoch 38/50\n",
      "1500/1500 - 4s - loss: 0.1316 - accuracy: 0.9501 - val_loss: 0.4677 - val_accuracy: 0.8941 - 4s/epoch - 3ms/step\n",
      "Epoch 39/50\n",
      "1500/1500 - 4s - loss: 0.1210 - accuracy: 0.9539 - val_loss: 0.5005 - val_accuracy: 0.9007 - 4s/epoch - 3ms/step\n",
      "Epoch 40/50\n",
      "1500/1500 - 4s - loss: 0.1273 - accuracy: 0.9535 - val_loss: 0.5473 - val_accuracy: 0.8979 - 4s/epoch - 3ms/step\n",
      "Epoch 41/50\n",
      "1500/1500 - 4s - loss: 0.1266 - accuracy: 0.9529 - val_loss: 0.4972 - val_accuracy: 0.8977 - 4s/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "1500/1500 - 4s - loss: 0.1209 - accuracy: 0.9547 - val_loss: 0.5009 - val_accuracy: 0.8992 - 4s/epoch - 3ms/step\n",
      "Epoch 43/50\n",
      "1500/1500 - 4s - loss: 0.1182 - accuracy: 0.9559 - val_loss: 0.5186 - val_accuracy: 0.8954 - 4s/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "1500/1500 - 4s - loss: 0.1175 - accuracy: 0.9558 - val_loss: 0.5776 - val_accuracy: 0.8917 - 4s/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "1500/1500 - 4s - loss: 0.1208 - accuracy: 0.9557 - val_loss: 0.6166 - val_accuracy: 0.8925 - 4s/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "1500/1500 - 4s - loss: 0.1178 - accuracy: 0.9564 - val_loss: 0.5078 - val_accuracy: 0.8910 - 4s/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "1500/1500 - 4s - loss: 0.1116 - accuracy: 0.9583 - val_loss: 0.6299 - val_accuracy: 0.8953 - 4s/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "1500/1500 - 4s - loss: 0.1290 - accuracy: 0.9570 - val_loss: 0.5533 - val_accuracy: 0.8934 - 4s/epoch - 3ms/step\n",
      "Epoch 49/50\n",
      "1500/1500 - 4s - loss: 0.1042 - accuracy: 0.9601 - val_loss: 0.5926 - val_accuracy: 0.8940 - 4s/epoch - 3ms/step\n",
      "Epoch 50/50\n",
      "1500/1500 - 4s - loss: 0.1101 - accuracy: 0.9599 - val_loss: 0.7750 - val_accuracy: 0.8914 - 4s/epoch - 2ms/step\n",
      "Best epoch: 34\n",
      "----------------------------------------\n",
      "Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.001,\n",
      "    'num_layers': 4,\n",
      "    'tuner/bracket': 0,\n",
      "    'tuner/epochs': 10,\n",
      "    'tuner/initial_epoch': 0,\n",
      "    'tuner/round': 0,\n",
      "    'units_0': 352,\n",
      "    'units_1': 384,\n",
      "    'units_2': 128,\n",
      "    'units_3': 96,\n",
      "    'units_4': 64}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Retrain the model:\n",
      "\n",
      "Epoch 1/34\n",
      "1500/1500 - 4s - loss: 0.5439 - accuracy: 0.8056 - val_loss: 0.4074 - val_accuracy: 0.8528 - 4s/epoch - 3ms/step\n",
      "Epoch 2/34\n",
      "1500/1500 - 4s - loss: 0.3979 - accuracy: 0.8572 - val_loss: 0.3840 - val_accuracy: 0.8606 - 4s/epoch - 3ms/step\n",
      "Epoch 3/34\n",
      "1500/1500 - 4s - loss: 0.3581 - accuracy: 0.8692 - val_loss: 0.3549 - val_accuracy: 0.8752 - 4s/epoch - 3ms/step\n",
      "Epoch 4/34\n",
      "1500/1500 - 4s - loss: 0.3302 - accuracy: 0.8790 - val_loss: 0.3435 - val_accuracy: 0.8759 - 4s/epoch - 3ms/step\n",
      "Epoch 5/34\n",
      "1500/1500 - 4s - loss: 0.3133 - accuracy: 0.8851 - val_loss: 0.3338 - val_accuracy: 0.8812 - 4s/epoch - 3ms/step\n",
      "Epoch 6/34\n",
      "1500/1500 - 4s - loss: 0.2970 - accuracy: 0.8903 - val_loss: 0.3536 - val_accuracy: 0.8728 - 4s/epoch - 3ms/step\n",
      "Epoch 7/34\n",
      "1500/1500 - 4s - loss: 0.2799 - accuracy: 0.8965 - val_loss: 0.3525 - val_accuracy: 0.8842 - 4s/epoch - 3ms/step\n",
      "Epoch 8/34\n",
      "1500/1500 - 4s - loss: 0.2716 - accuracy: 0.8999 - val_loss: 0.3256 - val_accuracy: 0.8880 - 4s/epoch - 3ms/step\n",
      "Epoch 9/34\n",
      "1500/1500 - 4s - loss: 0.2621 - accuracy: 0.9030 - val_loss: 0.3325 - val_accuracy: 0.8824 - 4s/epoch - 3ms/step\n",
      "Epoch 10/34\n",
      "1500/1500 - 4s - loss: 0.2507 - accuracy: 0.9054 - val_loss: 0.3550 - val_accuracy: 0.8812 - 4s/epoch - 3ms/step\n",
      "Epoch 11/34\n",
      "1500/1500 - 4s - loss: 0.2432 - accuracy: 0.9094 - val_loss: 0.3328 - val_accuracy: 0.8898 - 4s/epoch - 3ms/step\n",
      "Epoch 12/34\n",
      "1500/1500 - 4s - loss: 0.2340 - accuracy: 0.9126 - val_loss: 0.3380 - val_accuracy: 0.8881 - 4s/epoch - 3ms/step\n",
      "Epoch 13/34\n",
      "1500/1500 - 4s - loss: 0.2233 - accuracy: 0.9154 - val_loss: 0.3556 - val_accuracy: 0.8844 - 4s/epoch - 3ms/step\n",
      "Epoch 14/34\n",
      "1500/1500 - 4s - loss: 0.2186 - accuracy: 0.9168 - val_loss: 0.3549 - val_accuracy: 0.8905 - 4s/epoch - 3ms/step\n",
      "Epoch 15/34\n",
      "1500/1500 - 4s - loss: 0.2133 - accuracy: 0.9192 - val_loss: 0.3664 - val_accuracy: 0.8831 - 4s/epoch - 3ms/step\n",
      "Epoch 16/34\n",
      "1500/1500 - 4s - loss: 0.2117 - accuracy: 0.9221 - val_loss: 0.3628 - val_accuracy: 0.8864 - 4s/epoch - 3ms/step\n",
      "Epoch 17/34\n",
      "1500/1500 - 4s - loss: 0.2022 - accuracy: 0.9247 - val_loss: 0.3896 - val_accuracy: 0.8835 - 4s/epoch - 3ms/step\n",
      "Epoch 18/34\n",
      "1500/1500 - 4s - loss: 0.2009 - accuracy: 0.9239 - val_loss: 0.3425 - val_accuracy: 0.8941 - 4s/epoch - 3ms/step\n",
      "Epoch 19/34\n",
      "1500/1500 - 4s - loss: 0.1903 - accuracy: 0.9267 - val_loss: 0.3465 - val_accuracy: 0.8909 - 4s/epoch - 3ms/step\n",
      "Epoch 20/34\n",
      "1500/1500 - 4s - loss: 0.1845 - accuracy: 0.9299 - val_loss: 0.3756 - val_accuracy: 0.8909 - 4s/epoch - 3ms/step\n",
      "Epoch 21/34\n",
      "1500/1500 - 4s - loss: 0.1800 - accuracy: 0.9318 - val_loss: 0.3653 - val_accuracy: 0.8944 - 4s/epoch - 3ms/step\n",
      "Epoch 22/34\n",
      "1500/1500 - 4s - loss: 0.1778 - accuracy: 0.9331 - val_loss: 0.4072 - val_accuracy: 0.8922 - 4s/epoch - 3ms/step\n",
      "Epoch 23/34\n",
      "1500/1500 - 4s - loss: 0.1743 - accuracy: 0.9349 - val_loss: 0.4178 - val_accuracy: 0.8871 - 4s/epoch - 3ms/step\n",
      "Epoch 24/34\n",
      "1500/1500 - 4s - loss: 0.1687 - accuracy: 0.9367 - val_loss: 0.4120 - val_accuracy: 0.8903 - 4s/epoch - 3ms/step\n",
      "Epoch 25/34\n",
      "1500/1500 - 4s - loss: 0.1684 - accuracy: 0.9358 - val_loss: 0.3856 - val_accuracy: 0.8935 - 4s/epoch - 3ms/step\n",
      "Epoch 26/34\n",
      "1500/1500 - 4s - loss: 0.1584 - accuracy: 0.9394 - val_loss: 0.4492 - val_accuracy: 0.8833 - 4s/epoch - 3ms/step\n",
      "Epoch 27/34\n",
      "1500/1500 - 4s - loss: 0.1587 - accuracy: 0.9399 - val_loss: 0.4570 - val_accuracy: 0.8905 - 4s/epoch - 3ms/step\n",
      "Epoch 28/34\n",
      "1500/1500 - 4s - loss: 0.1611 - accuracy: 0.9392 - val_loss: 0.4189 - val_accuracy: 0.8860 - 4s/epoch - 3ms/step\n",
      "Epoch 29/34\n",
      "1500/1500 - 4s - loss: 0.1486 - accuracy: 0.9428 - val_loss: 0.4264 - val_accuracy: 0.8968 - 4s/epoch - 3ms/step\n",
      "Epoch 30/34\n",
      "1500/1500 - 4s - loss: 0.1490 - accuracy: 0.9432 - val_loss: 0.4918 - val_accuracy: 0.8867 - 4s/epoch - 3ms/step\n",
      "Epoch 31/34\n",
      "1500/1500 - 4s - loss: 0.1519 - accuracy: 0.9417 - val_loss: 0.5030 - val_accuracy: 0.8938 - 4s/epoch - 3ms/step\n",
      "Epoch 32/34\n",
      "1500/1500 - 4s - loss: 0.1474 - accuracy: 0.9455 - val_loss: 0.4565 - val_accuracy: 0.8969 - 4s/epoch - 3ms/step\n",
      "Epoch 33/34\n",
      "1500/1500 - 4s - loss: 0.1413 - accuracy: 0.9466 - val_loss: 0.4437 - val_accuracy: 0.8882 - 4s/epoch - 3ms/step\n",
      "Epoch 34/34\n",
      "1500/1500 - 4s - loss: 0.1427 - accuracy: 0.9467 - val_loss: 0.4834 - val_accuracy: 0.8905 - 4s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 352)               276320    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 384)               135552    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               49280     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 96)                12384     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                970       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 474,506\n",
      "Trainable params: 474,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------\n",
      "Evaluate the hypermodel on the test data.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5462 - accuracy: 0.8852\n",
      "[test loss, test accuracy]: [0.5462405681610107, 0.885200023651123]\n"
     ]
    }
   ],
   "source": [
    "tuner_hyperband = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory=f\"{data_dir}/ky_hyperband\",\n",
    "    project_name='kt_hyperband_project',\n",
    ")\n",
    "\n",
    "kt_framework(tuner_hyperband)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-EMtL4ino3tB",
   "metadata": {
    "id": "-EMtL4ino3tB"
   },
   "source": [
    "<a name=\"3.2\"></a>\n",
    "## 3.2 Keras Tuner with BayesianOptimization\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inE39VFrnI-r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inE39VFrnI-r",
    "outputId": "99bebfd4-a709-489c-c507-76828bfc6590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 52s]\n",
      "val_loss: 0.2962571084499359\n",
      "\n",
      "Best val_loss So Far: 0.2794955372810364\n",
      "Total elapsed time: 00h 23m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "----------------------------------------\n",
      "===== The hyperparameter search is complete =====\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 1,\n",
      "    'units_0': 512,\n",
      "    'units_1': 32,\n",
      "    'units_2': 32,\n",
      "    'units_3': 32,\n",
      "    'units_4': 32}\n",
      "Build the model with the optimal hyperparameters and train it on the data for n-epochs.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 1,\n",
      "    'units_0': 512,\n",
      "    'units_1': 32,\n",
      "    'units_2': 32,\n",
      "    'units_3': 32,\n",
      "    'units_4': 32}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.6764 - accuracy: 0.7740 - val_loss: 0.4817 - val_accuracy: 0.8397 - 4s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "1500/1500 - 3s - loss: 0.4670 - accuracy: 0.8407 - val_loss: 0.4256 - val_accuracy: 0.8514 - 3s/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "1500/1500 - 3s - loss: 0.4195 - accuracy: 0.8538 - val_loss: 0.3983 - val_accuracy: 0.8615 - 3s/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "1500/1500 - 3s - loss: 0.3914 - accuracy: 0.8624 - val_loss: 0.3811 - val_accuracy: 0.8620 - 3s/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.3691 - accuracy: 0.8704 - val_loss: 0.3791 - val_accuracy: 0.8660 - 3s/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.3509 - accuracy: 0.8766 - val_loss: 0.3542 - val_accuracy: 0.8740 - 3s/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.3367 - accuracy: 0.8800 - val_loss: 0.3436 - val_accuracy: 0.8785 - 3s/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.3252 - accuracy: 0.8851 - val_loss: 0.3437 - val_accuracy: 0.8773 - 3s/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.3155 - accuracy: 0.8881 - val_loss: 0.3315 - val_accuracy: 0.8823 - 3s/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.3061 - accuracy: 0.8896 - val_loss: 0.3308 - val_accuracy: 0.8827 - 3s/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.2963 - accuracy: 0.8948 - val_loss: 0.3187 - val_accuracy: 0.8864 - 3s/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.2886 - accuracy: 0.8960 - val_loss: 0.3160 - val_accuracy: 0.8871 - 3s/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.2817 - accuracy: 0.8993 - val_loss: 0.3214 - val_accuracy: 0.8843 - 3s/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.2750 - accuracy: 0.8996 - val_loss: 0.3173 - val_accuracy: 0.8853 - 3s/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.2689 - accuracy: 0.9032 - val_loss: 0.3086 - val_accuracy: 0.8878 - 3s/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.2616 - accuracy: 0.9056 - val_loss: 0.3033 - val_accuracy: 0.8903 - 3s/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.2574 - accuracy: 0.9081 - val_loss: 0.3018 - val_accuracy: 0.8892 - 3s/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.2506 - accuracy: 0.9093 - val_loss: 0.3014 - val_accuracy: 0.8925 - 3s/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.2476 - accuracy: 0.9096 - val_loss: 0.3004 - val_accuracy: 0.8918 - 3s/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.2406 - accuracy: 0.9135 - val_loss: 0.2981 - val_accuracy: 0.8926 - 3s/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "1500/1500 - 3s - loss: 0.2360 - accuracy: 0.9155 - val_loss: 0.2977 - val_accuracy: 0.8914 - 3s/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "1500/1500 - 3s - loss: 0.2308 - accuracy: 0.9166 - val_loss: 0.2962 - val_accuracy: 0.8932 - 3s/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "1500/1500 - 3s - loss: 0.2289 - accuracy: 0.9170 - val_loss: 0.2947 - val_accuracy: 0.8931 - 3s/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "1500/1500 - 3s - loss: 0.2243 - accuracy: 0.9201 - val_loss: 0.2906 - val_accuracy: 0.8957 - 3s/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "1500/1500 - 3s - loss: 0.2203 - accuracy: 0.9207 - val_loss: 0.2924 - val_accuracy: 0.8931 - 3s/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.2153 - accuracy: 0.9233 - val_loss: 0.2903 - val_accuracy: 0.8960 - 3s/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "1500/1500 - 3s - loss: 0.2113 - accuracy: 0.9237 - val_loss: 0.2881 - val_accuracy: 0.8980 - 3s/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.2079 - accuracy: 0.9249 - val_loss: 0.2872 - val_accuracy: 0.8970 - 3s/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "1500/1500 - 3s - loss: 0.2056 - accuracy: 0.9264 - val_loss: 0.2823 - val_accuracy: 0.8972 - 3s/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.2012 - accuracy: 0.9270 - val_loss: 0.2907 - val_accuracy: 0.8970 - 3s/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.1962 - accuracy: 0.9300 - val_loss: 0.2871 - val_accuracy: 0.8991 - 3s/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.1936 - accuracy: 0.9310 - val_loss: 0.2892 - val_accuracy: 0.8975 - 3s/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.1919 - accuracy: 0.9316 - val_loss: 0.2825 - val_accuracy: 0.8975 - 3s/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.1882 - accuracy: 0.9333 - val_loss: 0.2880 - val_accuracy: 0.8978 - 3s/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.1852 - accuracy: 0.9334 - val_loss: 0.2858 - val_accuracy: 0.8977 - 3s/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "1500/1500 - 3s - loss: 0.1815 - accuracy: 0.9350 - val_loss: 0.2892 - val_accuracy: 0.8978 - 3s/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "1500/1500 - 3s - loss: 0.1778 - accuracy: 0.9365 - val_loss: 0.2866 - val_accuracy: 0.8991 - 3s/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "1500/1500 - 3s - loss: 0.1765 - accuracy: 0.9374 - val_loss: 0.2806 - val_accuracy: 0.9023 - 3s/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "1500/1500 - 4s - loss: 0.1718 - accuracy: 0.9388 - val_loss: 0.2839 - val_accuracy: 0.9012 - 4s/epoch - 3ms/step\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.1696 - accuracy: 0.9397 - val_loss: 0.2825 - val_accuracy: 0.9008 - 3s/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "1500/1500 - 3s - loss: 0.1696 - accuracy: 0.9403 - val_loss: 0.2896 - val_accuracy: 0.8977 - 3s/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.1656 - accuracy: 0.9405 - val_loss: 0.2867 - val_accuracy: 0.8996 - 3s/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.1630 - accuracy: 0.9417 - val_loss: 0.2890 - val_accuracy: 0.8997 - 3s/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.1602 - accuracy: 0.9436 - val_loss: 0.2825 - val_accuracy: 0.9023 - 3s/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.1571 - accuracy: 0.9448 - val_loss: 0.2964 - val_accuracy: 0.8988 - 3s/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.1543 - accuracy: 0.9454 - val_loss: 0.2885 - val_accuracy: 0.9009 - 3s/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.1521 - accuracy: 0.9462 - val_loss: 0.2841 - val_accuracy: 0.9008 - 3s/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.1518 - accuracy: 0.9459 - val_loss: 0.2872 - val_accuracy: 0.9032 - 3s/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.1495 - accuracy: 0.9466 - val_loss: 0.2861 - val_accuracy: 0.9001 - 3s/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.1461 - accuracy: 0.9476 - val_loss: 0.2858 - val_accuracy: 0.9037 - 3s/epoch - 2ms/step\n",
      "Best epoch: 50\n",
      "----------------------------------------\n",
      "Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 1,\n",
      "    'units_0': 512,\n",
      "    'units_1': 32,\n",
      "    'units_2': 32,\n",
      "    'units_3': 32,\n",
      "    'units_4': 32}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Retrain the model:\n",
      "\n",
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.6694 - accuracy: 0.7777 - val_loss: 0.4811 - val_accuracy: 0.8397 - 4s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "1500/1500 - 3s - loss: 0.4692 - accuracy: 0.8405 - val_loss: 0.4257 - val_accuracy: 0.8525 - 3s/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "1500/1500 - 3s - loss: 0.4184 - accuracy: 0.8541 - val_loss: 0.3988 - val_accuracy: 0.8614 - 3s/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "1500/1500 - 3s - loss: 0.3885 - accuracy: 0.8646 - val_loss: 0.3791 - val_accuracy: 0.8662 - 3s/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "1500/1500 - 3s - loss: 0.3669 - accuracy: 0.8702 - val_loss: 0.3753 - val_accuracy: 0.8687 - 3s/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "1500/1500 - 3s - loss: 0.3491 - accuracy: 0.8768 - val_loss: 0.3548 - val_accuracy: 0.8741 - 3s/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "1500/1500 - 3s - loss: 0.3358 - accuracy: 0.8814 - val_loss: 0.3439 - val_accuracy: 0.8780 - 3s/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "1500/1500 - 3s - loss: 0.3234 - accuracy: 0.8855 - val_loss: 0.3411 - val_accuracy: 0.8795 - 3s/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "1500/1500 - 3s - loss: 0.3137 - accuracy: 0.8885 - val_loss: 0.3313 - val_accuracy: 0.8814 - 3s/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "1500/1500 - 3s - loss: 0.3045 - accuracy: 0.8903 - val_loss: 0.3342 - val_accuracy: 0.8830 - 3s/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "1500/1500 - 3s - loss: 0.2968 - accuracy: 0.8928 - val_loss: 0.3194 - val_accuracy: 0.8863 - 3s/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "1500/1500 - 3s - loss: 0.2874 - accuracy: 0.8967 - val_loss: 0.3181 - val_accuracy: 0.8851 - 3s/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "1500/1500 - 3s - loss: 0.2810 - accuracy: 0.8997 - val_loss: 0.3215 - val_accuracy: 0.8846 - 3s/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "1500/1500 - 3s - loss: 0.2743 - accuracy: 0.9012 - val_loss: 0.3143 - val_accuracy: 0.8873 - 3s/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "1500/1500 - 3s - loss: 0.2681 - accuracy: 0.9042 - val_loss: 0.3071 - val_accuracy: 0.8903 - 3s/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "1500/1500 - 3s - loss: 0.2617 - accuracy: 0.9063 - val_loss: 0.3028 - val_accuracy: 0.8921 - 3s/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "1500/1500 - 3s - loss: 0.2556 - accuracy: 0.9093 - val_loss: 0.3028 - val_accuracy: 0.8886 - 3s/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "1500/1500 - 3s - loss: 0.2527 - accuracy: 0.9078 - val_loss: 0.2991 - val_accuracy: 0.8932 - 3s/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "1500/1500 - 3s - loss: 0.2457 - accuracy: 0.9110 - val_loss: 0.2972 - val_accuracy: 0.8932 - 3s/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "1500/1500 - 3s - loss: 0.2419 - accuracy: 0.9130 - val_loss: 0.3038 - val_accuracy: 0.8903 - 3s/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "1500/1500 - 4s - loss: 0.2369 - accuracy: 0.9142 - val_loss: 0.2942 - val_accuracy: 0.8942 - 4s/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "1500/1500 - 3s - loss: 0.2323 - accuracy: 0.9163 - val_loss: 0.2933 - val_accuracy: 0.8952 - 3s/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "1500/1500 - 3s - loss: 0.2280 - accuracy: 0.9175 - val_loss: 0.2918 - val_accuracy: 0.8957 - 3s/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "1500/1500 - 3s - loss: 0.2241 - accuracy: 0.9199 - val_loss: 0.2902 - val_accuracy: 0.8928 - 3s/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "1500/1500 - 3s - loss: 0.2195 - accuracy: 0.9213 - val_loss: 0.2893 - val_accuracy: 0.8942 - 3s/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "1500/1500 - 3s - loss: 0.2141 - accuracy: 0.9231 - val_loss: 0.2907 - val_accuracy: 0.8953 - 3s/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "1500/1500 - 3s - loss: 0.2120 - accuracy: 0.9243 - val_loss: 0.2933 - val_accuracy: 0.8950 - 3s/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "1500/1500 - 3s - loss: 0.2088 - accuracy: 0.9260 - val_loss: 0.2880 - val_accuracy: 0.8961 - 3s/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "1500/1500 - 3s - loss: 0.2030 - accuracy: 0.9270 - val_loss: 0.2845 - val_accuracy: 0.8963 - 3s/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "1500/1500 - 3s - loss: 0.2004 - accuracy: 0.9281 - val_loss: 0.2922 - val_accuracy: 0.8948 - 3s/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "1500/1500 - 3s - loss: 0.1969 - accuracy: 0.9290 - val_loss: 0.2879 - val_accuracy: 0.8971 - 3s/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "1500/1500 - 3s - loss: 0.1938 - accuracy: 0.9309 - val_loss: 0.2863 - val_accuracy: 0.8954 - 3s/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "1500/1500 - 3s - loss: 0.1914 - accuracy: 0.9304 - val_loss: 0.2835 - val_accuracy: 0.8973 - 3s/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "1500/1500 - 3s - loss: 0.1866 - accuracy: 0.9334 - val_loss: 0.2868 - val_accuracy: 0.8981 - 3s/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "1500/1500 - 3s - loss: 0.1858 - accuracy: 0.9336 - val_loss: 0.2892 - val_accuracy: 0.8957 - 3s/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "1500/1500 - 3s - loss: 0.1815 - accuracy: 0.9358 - val_loss: 0.2884 - val_accuracy: 0.8961 - 3s/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "1500/1500 - 3s - loss: 0.1782 - accuracy: 0.9360 - val_loss: 0.2817 - val_accuracy: 0.8997 - 3s/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "1500/1500 - 3s - loss: 0.1748 - accuracy: 0.9376 - val_loss: 0.2818 - val_accuracy: 0.9010 - 3s/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "1500/1500 - 3s - loss: 0.1739 - accuracy: 0.9392 - val_loss: 0.2854 - val_accuracy: 0.8987 - 3s/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "1500/1500 - 3s - loss: 0.1713 - accuracy: 0.9377 - val_loss: 0.2843 - val_accuracy: 0.9001 - 3s/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "1500/1500 - 3s - loss: 0.1671 - accuracy: 0.9409 - val_loss: 0.2837 - val_accuracy: 0.9008 - 3s/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "1500/1500 - 3s - loss: 0.1654 - accuracy: 0.9410 - val_loss: 0.2832 - val_accuracy: 0.8996 - 3s/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "1500/1500 - 3s - loss: 0.1624 - accuracy: 0.9423 - val_loss: 0.2853 - val_accuracy: 0.8996 - 3s/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "1500/1500 - 3s - loss: 0.1593 - accuracy: 0.9434 - val_loss: 0.2811 - val_accuracy: 0.9008 - 3s/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "1500/1500 - 3s - loss: 0.1572 - accuracy: 0.9435 - val_loss: 0.2964 - val_accuracy: 0.8981 - 3s/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "1500/1500 - 3s - loss: 0.1551 - accuracy: 0.9449 - val_loss: 0.2856 - val_accuracy: 0.9015 - 3s/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "1500/1500 - 3s - loss: 0.1534 - accuracy: 0.9464 - val_loss: 0.2849 - val_accuracy: 0.9015 - 3s/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "1500/1500 - 3s - loss: 0.1503 - accuracy: 0.9464 - val_loss: 0.2827 - val_accuracy: 0.9008 - 3s/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "1500/1500 - 3s - loss: 0.1487 - accuracy: 0.9480 - val_loss: 0.2861 - val_accuracy: 0.9015 - 3s/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "1500/1500 - 3s - loss: 0.1462 - accuracy: 0.9485 - val_loss: 0.2870 - val_accuracy: 0.9018 - 3s/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------\n",
      "Evaluate the hypermodel on the test data.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.8952\n",
      "[test loss, test accuracy]: [0.314955472946167, 0.8952000141143799]\n"
     ]
    }
   ],
   "source": [
    "tuner_bayes_optimization = kt.BayesianOptimization(\n",
    "    model_builder,\n",
    "    #objective='val_accuracy',\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    seed=42,\n",
    "    directory=f'{data_dir}/kt_bayes_optimization',\n",
    "    project_name='kt_bayes_optimization_project',\n",
    "    #overwrite=True\n",
    ")\n",
    "\n",
    "kt_framework(tuner_bayes_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "am3DrouQqECE",
   "metadata": {
    "id": "am3DrouQqECE"
   },
   "source": [
    "<a name=\"3.3\"></a>\n",
    "## 3.3 Keras Tuner with RandomSearch\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Y4RNrnTCqR6j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4RNrnTCqR6j",
    "outputId": "4f89316b-2614-4f67-c7e5-f17772ba43d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 41s]\n",
      "val_loss: 0.31762030720710754\n",
      "\n",
      "Best val_loss So Far: 0.2984068691730499\n",
      "Total elapsed time: 00h 14m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "----------------------------------------\n",
      "===== The hyperparameter search is complete =====\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 3,\n",
      "    'units_0': 480,\n",
      "    'units_1': 64,\n",
      "    'units_2': 320,\n",
      "    'units_3': 128,\n",
      "    'units_4': 192}\n",
      "Build the model with the optimal hyperparameters and train it on the data for n-epochs.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 3,\n",
      "    'units_0': 480,\n",
      "    'units_1': 64,\n",
      "    'units_2': 320,\n",
      "    'units_3': 128,\n",
      "    'units_4': 192}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Epoch 1/50\n",
      "1500/1500 - 4s - loss: 0.6731 - accuracy: 0.7699 - val_loss: 0.4469 - val_accuracy: 0.8450 - 4s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "1500/1500 - 4s - loss: 0.4291 - accuracy: 0.8490 - val_loss: 0.3937 - val_accuracy: 0.8601 - 4s/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "1500/1500 - 4s - loss: 0.3803 - accuracy: 0.8636 - val_loss: 0.3640 - val_accuracy: 0.8685 - 4s/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "1500/1500 - 4s - loss: 0.3505 - accuracy: 0.8736 - val_loss: 0.3486 - val_accuracy: 0.8731 - 4s/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "1500/1500 - 4s - loss: 0.3290 - accuracy: 0.8815 - val_loss: 0.3369 - val_accuracy: 0.8789 - 4s/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "1500/1500 - 4s - loss: 0.3088 - accuracy: 0.8879 - val_loss: 0.3283 - val_accuracy: 0.8799 - 4s/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "1500/1500 - 4s - loss: 0.2945 - accuracy: 0.8930 - val_loss: 0.3268 - val_accuracy: 0.8837 - 4s/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "1500/1500 - 4s - loss: 0.2804 - accuracy: 0.8975 - val_loss: 0.3189 - val_accuracy: 0.8852 - 4s/epoch - 3ms/step\n",
      "Epoch 9/50\n",
      "1500/1500 - 4s - loss: 0.2689 - accuracy: 0.9026 - val_loss: 0.3108 - val_accuracy: 0.8871 - 4s/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "1500/1500 - 4s - loss: 0.2580 - accuracy: 0.9039 - val_loss: 0.3133 - val_accuracy: 0.8888 - 4s/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "1500/1500 - 4s - loss: 0.2473 - accuracy: 0.9094 - val_loss: 0.3094 - val_accuracy: 0.8899 - 4s/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "1500/1500 - 4s - loss: 0.2373 - accuracy: 0.9119 - val_loss: 0.3003 - val_accuracy: 0.8905 - 4s/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "1500/1500 - 4s - loss: 0.2267 - accuracy: 0.9165 - val_loss: 0.3207 - val_accuracy: 0.8861 - 4s/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "1500/1500 - 4s - loss: 0.2205 - accuracy: 0.9179 - val_loss: 0.3128 - val_accuracy: 0.8900 - 4s/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "1500/1500 - 4s - loss: 0.2106 - accuracy: 0.9216 - val_loss: 0.3113 - val_accuracy: 0.8899 - 4s/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "1500/1500 - 4s - loss: 0.2028 - accuracy: 0.9261 - val_loss: 0.3254 - val_accuracy: 0.8888 - 4s/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "1500/1500 - 4s - loss: 0.1953 - accuracy: 0.9270 - val_loss: 0.3080 - val_accuracy: 0.8917 - 4s/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "1500/1500 - 4s - loss: 0.1890 - accuracy: 0.9303 - val_loss: 0.3059 - val_accuracy: 0.8942 - 4s/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "1500/1500 - 4s - loss: 0.1814 - accuracy: 0.9321 - val_loss: 0.3163 - val_accuracy: 0.8942 - 4s/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "1500/1500 - 4s - loss: 0.1751 - accuracy: 0.9348 - val_loss: 0.3119 - val_accuracy: 0.8943 - 4s/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "1500/1500 - 4s - loss: 0.1685 - accuracy: 0.9379 - val_loss: 0.3253 - val_accuracy: 0.8932 - 4s/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "1500/1500 - 4s - loss: 0.1606 - accuracy: 0.9412 - val_loss: 0.3159 - val_accuracy: 0.8968 - 4s/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "1500/1500 - 4s - loss: 0.1554 - accuracy: 0.9421 - val_loss: 0.3323 - val_accuracy: 0.8949 - 4s/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "1500/1500 - 4s - loss: 0.1491 - accuracy: 0.9459 - val_loss: 0.3302 - val_accuracy: 0.8961 - 4s/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "1500/1500 - 4s - loss: 0.1426 - accuracy: 0.9471 - val_loss: 0.3246 - val_accuracy: 0.8972 - 4s/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "1500/1500 - 4s - loss: 0.1384 - accuracy: 0.9490 - val_loss: 0.3633 - val_accuracy: 0.8892 - 4s/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "1500/1500 - 4s - loss: 0.1337 - accuracy: 0.9514 - val_loss: 0.3429 - val_accuracy: 0.8970 - 4s/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "1500/1500 - 4s - loss: 0.1285 - accuracy: 0.9532 - val_loss: 0.3371 - val_accuracy: 0.8977 - 4s/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "1500/1500 - 4s - loss: 0.1237 - accuracy: 0.9539 - val_loss: 0.3366 - val_accuracy: 0.8969 - 4s/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "1500/1500 - 4s - loss: 0.1201 - accuracy: 0.9559 - val_loss: 0.3590 - val_accuracy: 0.8934 - 4s/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "1500/1500 - 4s - loss: 0.1151 - accuracy: 0.9578 - val_loss: 0.3627 - val_accuracy: 0.8979 - 4s/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "1500/1500 - 4s - loss: 0.1112 - accuracy: 0.9587 - val_loss: 0.3615 - val_accuracy: 0.8978 - 4s/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "1500/1500 - 4s - loss: 0.1069 - accuracy: 0.9613 - val_loss: 0.3712 - val_accuracy: 0.8967 - 4s/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "1500/1500 - 4s - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.3800 - val_accuracy: 0.8938 - 4s/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "1500/1500 - 4s - loss: 0.1005 - accuracy: 0.9633 - val_loss: 0.3966 - val_accuracy: 0.8919 - 4s/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "1500/1500 - 4s - loss: 0.0960 - accuracy: 0.9640 - val_loss: 0.3886 - val_accuracy: 0.8950 - 4s/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "1500/1500 - 4s - loss: 0.0928 - accuracy: 0.9658 - val_loss: 0.3916 - val_accuracy: 0.8942 - 4s/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "1500/1500 - 4s - loss: 0.0870 - accuracy: 0.9680 - val_loss: 0.4045 - val_accuracy: 0.8985 - 4s/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "1500/1500 - 4s - loss: 0.0858 - accuracy: 0.9689 - val_loss: 0.4012 - val_accuracy: 0.8980 - 4s/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "1500/1500 - 4s - loss: 0.0814 - accuracy: 0.9702 - val_loss: 0.3924 - val_accuracy: 0.8990 - 4s/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "1500/1500 - 4s - loss: 0.0804 - accuracy: 0.9707 - val_loss: 0.4152 - val_accuracy: 0.8963 - 4s/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "1500/1500 - 4s - loss: 0.0803 - accuracy: 0.9709 - val_loss: 0.4105 - val_accuracy: 0.8944 - 4s/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "1500/1500 - 4s - loss: 0.0761 - accuracy: 0.9725 - val_loss: 0.4475 - val_accuracy: 0.8901 - 4s/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "1500/1500 - 4s - loss: 0.0732 - accuracy: 0.9731 - val_loss: 0.4789 - val_accuracy: 0.8917 - 4s/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "1500/1500 - 4s - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.4417 - val_accuracy: 0.8945 - 4s/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "1500/1500 - 4s - loss: 0.0686 - accuracy: 0.9750 - val_loss: 0.4403 - val_accuracy: 0.8982 - 4s/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "1500/1500 - 4s - loss: 0.0670 - accuracy: 0.9756 - val_loss: 0.4372 - val_accuracy: 0.8961 - 4s/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "1500/1500 - 4s - loss: 0.0635 - accuracy: 0.9774 - val_loss: 0.4501 - val_accuracy: 0.8984 - 4s/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "1500/1500 - 4s - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.4723 - val_accuracy: 0.8957 - 4s/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "1500/1500 - 4s - loss: 0.0623 - accuracy: 0.9775 - val_loss: 0.4722 - val_accuracy: 0.8980 - 4s/epoch - 2ms/step\n",
      "Best epoch: 40\n",
      "----------------------------------------\n",
      "Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
      "== Calling model_builder.\n",
      "hp.values:\n",
      "{   'dropout': True,\n",
      "    'learning_rate': 0.0001,\n",
      "    'num_layers': 3,\n",
      "    'units_0': 480,\n",
      "    'units_1': 64,\n",
      "    'units_2': 320,\n",
      "    'units_3': 128,\n",
      "    'units_4': 192}\n",
      "== Exiting model_builder.\n",
      "----------------------------------------\n",
      "Retrain the model:\n",
      "\n",
      "Epoch 1/40\n",
      "1500/1500 - 4s - loss: 0.6798 - accuracy: 0.7694 - val_loss: 0.4436 - val_accuracy: 0.8465 - 4s/epoch - 3ms/step\n",
      "Epoch 2/40\n",
      "1500/1500 - 4s - loss: 0.4308 - accuracy: 0.8476 - val_loss: 0.3935 - val_accuracy: 0.8574 - 4s/epoch - 2ms/step\n",
      "Epoch 3/40\n",
      "1500/1500 - 4s - loss: 0.3810 - accuracy: 0.8633 - val_loss: 0.3617 - val_accuracy: 0.8703 - 4s/epoch - 2ms/step\n",
      "Epoch 4/40\n",
      "1500/1500 - 4s - loss: 0.3510 - accuracy: 0.8745 - val_loss: 0.3486 - val_accuracy: 0.8711 - 4s/epoch - 2ms/step\n",
      "Epoch 5/40\n",
      "1500/1500 - 4s - loss: 0.3293 - accuracy: 0.8802 - val_loss: 0.3358 - val_accuracy: 0.8787 - 4s/epoch - 2ms/step\n",
      "Epoch 6/40\n",
      "1500/1500 - 4s - loss: 0.3096 - accuracy: 0.8863 - val_loss: 0.3307 - val_accuracy: 0.8812 - 4s/epoch - 2ms/step\n",
      "Epoch 7/40\n",
      "1500/1500 - 4s - loss: 0.2965 - accuracy: 0.8914 - val_loss: 0.3174 - val_accuracy: 0.8832 - 4s/epoch - 2ms/step\n",
      "Epoch 8/40\n",
      "1500/1500 - 4s - loss: 0.2816 - accuracy: 0.8959 - val_loss: 0.3143 - val_accuracy: 0.8854 - 4s/epoch - 2ms/step\n",
      "Epoch 9/40\n",
      "1500/1500 - 4s - loss: 0.2712 - accuracy: 0.9011 - val_loss: 0.3081 - val_accuracy: 0.8838 - 4s/epoch - 2ms/step\n",
      "Epoch 10/40\n",
      "1500/1500 - 4s - loss: 0.2603 - accuracy: 0.9034 - val_loss: 0.3084 - val_accuracy: 0.8869 - 4s/epoch - 2ms/step\n",
      "Epoch 11/40\n",
      "1500/1500 - 4s - loss: 0.2501 - accuracy: 0.9081 - val_loss: 0.3085 - val_accuracy: 0.8888 - 4s/epoch - 2ms/step\n",
      "Epoch 12/40\n",
      "1500/1500 - 4s - loss: 0.2398 - accuracy: 0.9106 - val_loss: 0.3011 - val_accuracy: 0.8903 - 4s/epoch - 2ms/step\n",
      "Epoch 13/40\n",
      "1500/1500 - 4s - loss: 0.2321 - accuracy: 0.9146 - val_loss: 0.3167 - val_accuracy: 0.8868 - 4s/epoch - 2ms/step\n",
      "Epoch 14/40\n",
      "1500/1500 - 4s - loss: 0.2238 - accuracy: 0.9174 - val_loss: 0.3141 - val_accuracy: 0.8898 - 4s/epoch - 2ms/step\n",
      "Epoch 15/40\n",
      "1500/1500 - 4s - loss: 0.2156 - accuracy: 0.9204 - val_loss: 0.3098 - val_accuracy: 0.8876 - 4s/epoch - 2ms/step\n",
      "Epoch 16/40\n",
      "1500/1500 - 4s - loss: 0.2076 - accuracy: 0.9229 - val_loss: 0.3084 - val_accuracy: 0.8920 - 4s/epoch - 2ms/step\n",
      "Epoch 17/40\n",
      "1500/1500 - 4s - loss: 0.1999 - accuracy: 0.9261 - val_loss: 0.3136 - val_accuracy: 0.8907 - 4s/epoch - 2ms/step\n",
      "Epoch 18/40\n",
      "1500/1500 - 4s - loss: 0.1929 - accuracy: 0.9280 - val_loss: 0.3009 - val_accuracy: 0.8939 - 4s/epoch - 2ms/step\n",
      "Epoch 19/40\n",
      "1500/1500 - 4s - loss: 0.1867 - accuracy: 0.9311 - val_loss: 0.3048 - val_accuracy: 0.8935 - 4s/epoch - 2ms/step\n",
      "Epoch 20/40\n",
      "1500/1500 - 4s - loss: 0.1803 - accuracy: 0.9338 - val_loss: 0.3075 - val_accuracy: 0.8913 - 4s/epoch - 2ms/step\n",
      "Epoch 21/40\n",
      "1500/1500 - 4s - loss: 0.1741 - accuracy: 0.9354 - val_loss: 0.3228 - val_accuracy: 0.8923 - 4s/epoch - 2ms/step\n",
      "Epoch 22/40\n",
      "1500/1500 - 4s - loss: 0.1670 - accuracy: 0.9388 - val_loss: 0.3082 - val_accuracy: 0.8938 - 4s/epoch - 2ms/step\n",
      "Epoch 23/40\n",
      "1500/1500 - 4s - loss: 0.1624 - accuracy: 0.9400 - val_loss: 0.3246 - val_accuracy: 0.8903 - 4s/epoch - 2ms/step\n",
      "Epoch 24/40\n",
      "1500/1500 - 4s - loss: 0.1542 - accuracy: 0.9428 - val_loss: 0.3175 - val_accuracy: 0.8969 - 4s/epoch - 2ms/step\n",
      "Epoch 25/40\n",
      "1500/1500 - 4s - loss: 0.1482 - accuracy: 0.9457 - val_loss: 0.3145 - val_accuracy: 0.8964 - 4s/epoch - 2ms/step\n",
      "Epoch 26/40\n",
      "1500/1500 - 4s - loss: 0.1421 - accuracy: 0.9474 - val_loss: 0.3420 - val_accuracy: 0.8893 - 4s/epoch - 2ms/step\n",
      "Epoch 27/40\n",
      "1500/1500 - 4s - loss: 0.1392 - accuracy: 0.9478 - val_loss: 0.3326 - val_accuracy: 0.8957 - 4s/epoch - 2ms/step\n",
      "Epoch 28/40\n",
      "1500/1500 - 4s - loss: 0.1327 - accuracy: 0.9509 - val_loss: 0.3377 - val_accuracy: 0.8942 - 4s/epoch - 2ms/step\n",
      "Epoch 29/40\n",
      "1500/1500 - 4s - loss: 0.1262 - accuracy: 0.9535 - val_loss: 0.3259 - val_accuracy: 0.8968 - 4s/epoch - 2ms/step\n",
      "Epoch 30/40\n",
      "1500/1500 - 4s - loss: 0.1250 - accuracy: 0.9530 - val_loss: 0.3333 - val_accuracy: 0.8977 - 4s/epoch - 2ms/step\n",
      "Epoch 31/40\n",
      "1500/1500 - 4s - loss: 0.1188 - accuracy: 0.9555 - val_loss: 0.3528 - val_accuracy: 0.8963 - 4s/epoch - 3ms/step\n",
      "Epoch 32/40\n",
      "1500/1500 - 4s - loss: 0.1135 - accuracy: 0.9582 - val_loss: 0.3595 - val_accuracy: 0.8928 - 4s/epoch - 2ms/step\n",
      "Epoch 33/40\n",
      "1500/1500 - 4s - loss: 0.1101 - accuracy: 0.9598 - val_loss: 0.3555 - val_accuracy: 0.8946 - 4s/epoch - 2ms/step\n",
      "Epoch 34/40\n",
      "1500/1500 - 4s - loss: 0.1064 - accuracy: 0.9613 - val_loss: 0.3617 - val_accuracy: 0.8944 - 4s/epoch - 2ms/step\n",
      "Epoch 35/40\n",
      "1500/1500 - 4s - loss: 0.1025 - accuracy: 0.9624 - val_loss: 0.3825 - val_accuracy: 0.8940 - 4s/epoch - 2ms/step\n",
      "Epoch 36/40\n",
      "1500/1500 - 4s - loss: 0.0992 - accuracy: 0.9631 - val_loss: 0.3569 - val_accuracy: 0.8981 - 4s/epoch - 2ms/step\n",
      "Epoch 37/40\n",
      "1500/1500 - 4s - loss: 0.0951 - accuracy: 0.9649 - val_loss: 0.3822 - val_accuracy: 0.8931 - 4s/epoch - 2ms/step\n",
      "Epoch 38/40\n",
      "1500/1500 - 4s - loss: 0.0932 - accuracy: 0.9659 - val_loss: 0.4100 - val_accuracy: 0.8926 - 4s/epoch - 2ms/step\n",
      "Epoch 39/40\n",
      "1500/1500 - 4s - loss: 0.0893 - accuracy: 0.9672 - val_loss: 0.3805 - val_accuracy: 0.8973 - 4s/epoch - 2ms/step\n",
      "Epoch 40/40\n",
      "1500/1500 - 4s - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.3919 - val_accuracy: 0.8965 - 4s/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 480)               376800    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                30784     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 320)               20800     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                3210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,594\n",
      "Trainable params: 431,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------\n",
      "Evaluate the hypermodel on the test data.\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4415 - accuracy: 0.8922\n",
      "[test loss, test accuracy]: [0.44149863719940186, 0.8921999931335449]\n"
     ]
    }
   ],
   "source": [
    "tuner_random_search = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    #objective='val_accuracy',\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    seed=42,\n",
    "    directory=f'{data_dir}/kt_random_search',\n",
    "    project_name='kt_random_search_project',\n",
    ")\n",
    "\n",
    "kt_framework(tuner_random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ff853-6c05-4f4a-9021-e0e7f5e4dd3b",
   "metadata": {
    "id": "d83ff853-6c05-4f4a-9021-e0e7f5e4dd3b"
   },
   "source": [
    "<a name=\"3.3\"></a>\n",
    "## 3.3 neptune.ai article\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://neptune.ai/blog/keras-tuner-tuning-hyperparameters-deep-learning-model\n",
    "\n",
    "High-level overview of available tuners\n",
    "\n",
    "How can we get the most out of our model using Keras Tuner? First of all, it’s important to say that there are multiple tuners in Keras. They use different algorithms for hyperparameter search. Here are the algorithms, with corresponding tuners in Keras:\n",
    "\n",
    "1. `kerastuner.tuners.hyperband.Hyperband` for the HyperBand-based algorithm;\n",
    "2. `kerastuner.tuners.bayesian.BayesianOptimization` for the Gaussian process-based algorithm;\n",
    "3. `kerastuner.tuners.randomsearch.RandomSearch` for the random search tuner.\n",
    "\n",
    "To give you an initial intuition of these methods, I can say that RandomSearch is the least efficient approach. It doesn’t learn from previously tested parameter combinations, and simply samples parameter combinations from a search space randomly.\n",
    "\n",
    "**BayesianOptimization** is similar to RandomSearch in a way that they both sample a subset of hyperparameter combinations. The key difference is that BayesianOptimization doesn’t sample hyperparameter combinations randomly, it follows a probabilistic approach under the hood. This approach takes into account already tested combinations and uses this information to sample the next combination for a test. \n",
    "\n",
    "Hyperband is an optimized version of RandomSearch in terms of search time and, therefore, resources allocation. \n",
    "\n",
    "If you’re a curious person and want to learn more about Random Search, Bayesian Optimization and HyperBand, I definitely recommend this article: https://neptune.ai/blog/hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "20_01_kerastuner_deep_learning.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
