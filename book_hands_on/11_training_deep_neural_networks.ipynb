{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2ldwh5N8IrT"
      },
      "source": [
        "<a name='top'></a><a id='top'></a>\n",
        "# Chapter 11 – Training Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIdTEOq08IrV"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svSIaMG-8IrX"
      },
      "source": [
        "1. [Setup](#setup)\n",
        "2. [Vanishing/Exploding Gradients Problem](#2.0)\n",
        "    - [2.1 Glorot and He Initialization](#2.1)\n",
        "        * [2.1.1 Glorot Initialization (Xavier Glorot & Yoshua Bengio)](#2.1.1)\n",
        "        * [2.1.2 He Initialization](#2.1.2)\n",
        "    - [2.2 Initializer comparison (extra material)](#2.2)\n",
        "    - [2.3 Nonsaturating Activation Functions](#2.3)\n",
        "        * [2.3.1 Leaky ReLU](#2.4.1)\n",
        "        * [2.3.2 PReLU](#2.4.2)\n",
        "        * [2.3.3 ELU](#2.4.3)\n",
        "        * [2.3.4 SELU](#2.4.4)\n",
        "        * [2.3.5 RELU](#2.4.5)\n",
        "        * [2.3.6 Overall Test of Activation Functions](#2.4.6)\n",
        "    - [2.4 Batch Normalization](#2.4)\n",
        "    - [2.5 Gradient Clipping](#2.5)\n",
        "        * [2.5.1 Gradient Clipping: Clip tensor values to a specified min and max](#2.5.1)\n",
        "        * [2.5.2 Gradient Clipping: Clip tensor values to a maximum L2-norm](#2.5.2)\n",
        "3. [Reusing Pretrained Layers](#3.0)\n",
        "    - [3.1  Transfer Learning with Keras](#3.1)\n",
        "    - [3.2  Unsupervised Pretraining](#3.2)\n",
        "    - [3.3  Pretraining on an Auxiliary Task](#3.3)\n",
        "4. [Faster Optimizers](#4.0)\n",
        "    - [4.1 Momentum optimization](#4.1)\n",
        "    - [4.2 Nesterov Accelerated Gradient / NAG](#4.2)\n",
        "    - [4.3 AdaGrad](#4.3)\n",
        "    - [4.4 RMSProp](#4.4)\n",
        "    - [4.5 Adam Optimization](#4.5)\n",
        "        * [4.5.1 Adamax Optimization](#4.5.1)\n",
        "        * [4.5.2 Nadam Optimization](#4.5.2)\n",
        "    - [4.6 Learning Rate Scheduling](#4.6)\n",
        "        * [4.6.1 Power Scheduling](#4.6.1)\n",
        "        * [4.6.2 Exponential Scheduling](#4.6.2)\n",
        "            - [4.6.2.1 Exponential Scheduling - Standard](#4.6.2.1)\n",
        "            - [4.6.2.2 Exponential Scheduling - Using current LR](#4.6.2.2)\n",
        "            - [4.6.2.3 Exponential Scheduling - Update LR at each iteration](#4.6.2.3)\n",
        "        * [4.6.3 Piecewise Constant Scheduling](#4.6.3)\n",
        "        * [4.6.4 Performance Scheduling](#4.6.4)\n",
        "        * [4.6.5 tf.keras Schedulers](#4.6.5)\n",
        "            - [4.6.5.1 tf.keras scheduler using ExponentialDecay](#4.6.5.1)\n",
        "            - [4.6.5.2 tf.keras scheduler using PiecewiseConstantDecay](#4.6.5.2)\n",
        "        * [4.6.6 1Cycle scheduling](#4.6.6)\n",
        "5. [Avoiding Overfitting Through Regularization](#5.0)\n",
        "    - [5.1 ℓ1 and ℓ2 regularization](#5.1)\n",
        "         * [5.1.1 ℓ1 and ℓ2 regularization using functools.partial()](#5.1.1)\n",
        "    - [5.2 Dropout](#5.2)\n",
        "        * [5.1.1 $\\ell_1$ and $\\ell_2$ regularization using functools.partial()](#5.1.1)\n",
        "    - [5.3 Alpha Dropout](#5.3)\n",
        "    - [5.4 Monte Carlo (MC) Dropout](#5.4)\n",
        "        * [5.4.1 MC Dropout, Model with standard layers](#5.4.1)\n",
        "        * [5.4.2 MC Dropout, Model with customized layers](#5.4.2)\n",
        "    - [5.5 Max-Norm Regularization](#5.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpmA7AvQ8Ira"
      },
      "source": [
        "    11章 深層ニューラルネットワークの訓練\n",
        "        11.1　勾配消失／爆発問題\n",
        "            11.1.1　Glorotと Heの初期値\n",
        "            11.1.2　飽和しない活性化関数\n",
        "            11.1.3　バッチ正規化\n",
        "            11.1.4　勾配クリッピング\n",
        "\n",
        "        11.2　事前学習済みの層の再利用\n",
        "            11.2.1　Kerasによる転移学習\n",
        "            11.2.2　教師なし事前学習\n",
        "            11.2.3　関連タスクの事前学習\n",
        "\n",
        "        11.3　オプティマイザの高速化\n",
        "            11.3.1　モーメンタム最適化\n",
        "            11.3.2　NAG\n",
        "            11.3.3　AdaGrad\n",
        "            11.3.4　RMSProp\n",
        "            11.3.5　Adam、Nadam最適化\n",
        "            11.3.6　学習率のスケジューリング\n",
        "\n",
        "        11.4　正則化による過学習の防止\n",
        "            11.4.1　ℓ1、ℓ2 正則化\n",
        "            11.4.2　ドロップアウト\n",
        "            11.4.3　モンテカルロ（MC）ドロップアウト\n",
        "            11.4.4　重み上限正則化\n",
        "        11.5　まとめと実践的なガイドライン\n",
        "        11.6　演習問題\n",
        "        \n",
        "* [AI・機械学習の用語辞典](https://atmarkit.itmedia.co.jp/ait/subtop/features/di/mlglossary_index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mJFeoYQ8Irf"
      },
      "source": [
        "---\n",
        "<a name='setup'></a><a id=\"setup\"></a>\n",
        "# 1. Setup\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrrliT_p8Irg",
        "outputId": "b95f249a-8d55-4c91-eb85-b83e3cbe31e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished imports\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# for stable output across runs\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "def HR():\n",
        "    print(\"-\"*40)\n",
        "\n",
        "print(\"Finished imports\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = 'data_chp11'"
      ],
      "metadata": {
        "id": "H4l7CqaD942i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ZFo0BB8Irh"
      },
      "source": [
        "---\n",
        "<a id='2.0'></a><a name='2.0'></a>\n",
        "# 2. Vanishing/Exploding Gradients Problem / 勾配消失／爆発問題\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "1slPonEY8Iri",
        "outputId": "0790722c-86c2-4dbf-ccd4-d2ffa1bbea1c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2():\n",
        "    import traceback\n",
        "    \n",
        "    def logit(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    z = np.linspace(-5, 5, 200)\n",
        "\n",
        "    plt.plot([-5, 5], [0, 0], 'k-')\n",
        "    plt.plot([-5, 5], [1, 1], 'k--')\n",
        "    plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
        "    plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
        "    plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
        "\n",
        "    props = dict(facecolor='black', shrink=0.1)\n",
        "\n",
        "    plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "    plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "    plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "    plt.grid(True)\n",
        "    plt.title(\"Sigmoid activation function\")\n",
        "    plt.axis([-5, 5, -0.2, 1.2])\n",
        "    plt.suptitle(\"Logistic activation function saturation\")\n",
        "    plt.show()\n",
        "\n",
        "listing2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06a5v_Kz8Iri"
      },
      "source": [
        "<a id='2.1'></a><a name='2.1'></a>\n",
        "## 2.1 Glorot and He Initialization\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3oYhudc8Irk"
      },
      "source": [
        "<a id='2.1.1'></a><a name='2.1_1'></a>\n",
        "### 2.1.1 Glorot Initialization (Xavier Glorot & Yoshua Bengio)\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Activation functions for Glorot initialization: None, tanh, logistics, softmax\n",
        "\n",
        "https://keras.io/api/layers/initializers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtKeDAFN8Irk",
        "outputId": "5ce78d5a-ce5b-47a4-c45f-c500be4fb29c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'activation': 'linear',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
            "                              'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n",
            "----------------------------------------\n",
            "{   'activation': 'tanh',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
            "                              'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_1',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n",
            "----------------------------------------\n",
            "{   'activation': 'sigmoid',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
            "                              'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_2',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n",
            "----------------------------------------\n",
            "{   'activation': 'softmax',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
            "                              'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_3',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n"
          ]
        }
      ],
      "source": [
        "# Keras default glorot_uniform initialization\n",
        "def listing2_1_1():\n",
        "    \n",
        "    layer_none = keras.layers.Dense(10, activation=None, kernel_initializer=\"glorot_uniform\")\n",
        "    pp.pprint(layer_none.get_config())\n",
        "    HR()\n",
        "    \n",
        "    layer_tanh = keras.layers.Dense(10, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")\n",
        "    pp.pprint(layer_tanh.get_config())\n",
        "    HR()\n",
        "\n",
        "    # Assume `logistic` refers to the `sigmoid` function\n",
        "    layer_logistic = keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")\n",
        "    pp.pprint(layer_logistic.get_config())\n",
        "    HR()    \n",
        "\n",
        "    layer_softmax = keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"glorot_uniform\")\n",
        "    pp.pprint(layer_softmax.get_config())\n",
        "    \n",
        "listing2_1_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNJ9kWc8Irl"
      },
      "source": [
        "<a id='2.1.2'></a><a name='2.1_2'></a>\n",
        "### 2.1.2 He Initialization\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Activation functions for He initialization: ReLU and variants\n",
        "\n",
        "https://keras.io/api/layers/initializers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug3mytuE8Irm",
        "outputId": "c05b2e85-200e-4493-ca7e-dffe2a0128f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'activation': 'relu',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {'class_name': 'HeUniform', 'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_4',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n",
            "----------------------------------------\n",
            "{   'activation': 'relu',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_5',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n",
            "----------------------------------------\n",
            "{   'activation': 'relu',\n",
            "    'activity_regularizer': None,\n",
            "    'bias_constraint': None,\n",
            "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
            "    'bias_regularizer': None,\n",
            "    'dtype': 'float32',\n",
            "    'kernel_constraint': None,\n",
            "    'kernel_initializer': {   'class_name': 'VarianceScaling',\n",
            "                              'config': {   'distribution': 'uniform',\n",
            "                                            'mode': 'fan_avg',\n",
            "                                            'scale': 2.0,\n",
            "                                            'seed': None}},\n",
            "    'kernel_regularizer': None,\n",
            "    'name': 'dense_6',\n",
            "    'trainable': True,\n",
            "    'units': 10,\n",
            "    'use_bias': True}\n"
          ]
        }
      ],
      "source": [
        "# Use He initialization\n",
        "def listing2_1_2():\n",
        "    \n",
        "    layer_he_uniform = keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "    pp.pprint(layer_he_uniform.get_config())\n",
        "    HR()\n",
        "    \n",
        "    layer_he_normal = keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "    pp.pprint(layer_he_normal.get_config())    \n",
        "    HR()\n",
        "\n",
        "    # He initialization with uniform distribution based on fan_avg\n",
        "    init = keras.initializers.VarianceScaling(\n",
        "        scale=2., \n",
        "        mode='fan_avg',\n",
        "        distribution='uniform'\n",
        "    )\n",
        "    layer_fan_avg = keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)\n",
        "    pp.pprint(layer_fan_avg.get_config())\n",
        "    \n",
        "listing2_1_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8VjsB_C8Irm"
      },
      "source": [
        "<a id='2.2'></a><a name='2.2'></a>\n",
        "## 2.2 Initializer comparison (extra material)\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "**To-do**:\n",
        "\n",
        "Fix this code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "8cfmrZQr8Irm",
        "outputId": "cddc3df9-e82d-4634-f782-4c99cbb4167f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x1296 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2_2():\n",
        "    import pandas as pd\n",
        "    import traceback\n",
        "    \n",
        "    data_list = [name for name in dir(tf.keras.initializers) if not name.startswith(\"_\")]\n",
        "    data_length = len(data_list)\n",
        "    #print(data_length)\n",
        "    \n",
        "    columns = 4\n",
        "    \n",
        "    # Keep column width constant, need to calculate row-length\n",
        "    rows = int(data_length / columns)+1        \n",
        "    plt_row_size = (rows*2)\n",
        "    \n",
        "    # width, height\n",
        "    fig = plt.figure(figsize=(12,plt_row_size))\n",
        "    i = 1\n",
        "    \n",
        "    for x in data_list:\n",
        "        \n",
        "        try:\n",
        "            init_func = f\"tf.keras.initializers.{x}()\"\n",
        "            initializer = eval(init_func)\n",
        "            values = initializer(shape=(200, 1))\n",
        "            df = pd.DataFrame(values)\n",
        "            ax = fig.add_subplot(rows, columns,i) # i must not be 0, else cause matplotlib error\n",
        "            df.plot(ax=ax, kind=\"hist\", title=x, legend=False, grid=True)\n",
        "            i+=1\n",
        "                        \n",
        "        except Exception as e:\n",
        "            pass\n",
        "    \n",
        "    plt.suptitle(\"tf.keras.initializers: Keras initializer serialization / deserialization\", fontsize=18)\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.94) # Call after tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "listing2_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icFlekP48Irn"
      },
      "source": [
        "<a id='2.3'></a><a name='2.3'></a>\n",
        "## 2.3 Nonsaturating Activation Functions / 飽和しない活性化関数\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkvzD_LK8Iro"
      },
      "source": [
        "<a id='2.3.1'></a><a name='2.3.1'></a>\n",
        "### 2.3.1 Leaky ReLU\n",
        "\n",
        "用語「Leaky ReLU（Leaky Rectified Linear Unit）／LReLU」について説明。「0」を基点として、入力値が0より下なら「入力値とα倍した値」（α倍は基本的に0.01倍）、0以上なら「入力値と同じ値」を返す、ニューラルネットワークの活性化関数を指す。ReLUの拡張版。\n",
        "* https://atmarkit.itmedia.co.jp/ait/articles/2005/13/news009.html\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "p41xNaoB8Iro",
        "outputId": "1d639845-0889-493c-9345-775ab0684451"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2_3_1():\n",
        "    \n",
        "    # Hyperparameter α defines how much the function “leaks”\n",
        "    def leaky_relu(z, alpha=0.01):\n",
        "        return np.maximum(alpha*z, z)\n",
        "        \n",
        "    z = np.linspace(-5, 5, 200)\n",
        "    \n",
        "    plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
        "    plt.plot([-5, 5], [0, 0], 'k-')\n",
        "    plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
        "    plt.grid(True)\n",
        "    props = dict(facecolor='black', shrink=0.1)\n",
        "    \n",
        "    plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "    plt.title(\"Leaky ReLU activation function, (alpha=0.01)\", fontsize=14)\n",
        "    plt.axis([-5, 5, -0.5, 4.2])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "listing2_3_1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9QNAzw58Irp",
        "outputId": "ddf50c0e-1e87-4398-93d4-7e3a1228ddc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   'deserialize',\n",
            "    'elu',\n",
            "    'exponential',\n",
            "    'gelu',\n",
            "    'get',\n",
            "    'hard_sigmoid',\n",
            "    'linear',\n",
            "    'relu',\n",
            "    'selu',\n",
            "    'serialize',\n",
            "    'sigmoid',\n",
            "    'softmax',\n",
            "    'softplus',\n",
            "    'softsign',\n",
            "    'swish',\n",
            "    'tanh']\n",
            "----------------------------------------\n",
            "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def listing2_3_1_extra():\n",
        "\n",
        "    data = [m for m in dir(keras.activations) if not m.startswith(\"_\")]\n",
        "    pp.pprint(data)\n",
        "    HR()\n",
        "    \n",
        "    data2 = [m for m in dir(keras.layers) if \"relu\" in m.lower()]\n",
        "    pp.pprint(data2)\n",
        "    HR()\n",
        "    \n",
        "listing2_3_1_extra()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2gnGl7k8Irp",
        "outputId": "6ca006e9-570d-45fc-babf-f36c5d9929db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 7s - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160 - 7s/epoch - 4ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 7s - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7658 - 7s/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 7s - loss: 0.6816 - accuracy: 0.7720 - val_loss: 0.6427 - val_accuracy: 0.7898 - 7s/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 5s - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8064 - 5s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 4s - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8202 - 4s/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.5582 - accuracy: 0.8202 - 469ms/epoch - 3ms/step\n",
            "[test loss, test accuracy]: [0.5581830739974976, 0.8202000260353088]\n",
            "----------------------------------------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 300)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with keras.layers.LeakyReLU\n",
        "\n",
        "def listing2_3_1_model():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.LeakyReLU(),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "listing2_3_1_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "OgGbwQKe8Irq",
        "outputId": "280a0a0b-73c1-4a70-a854-ba34ffb49d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: 0: mean: 0.39, std deviation: 0.59\n",
            "Layer: 2: mean: 0.19, std deviation: 0.20\n",
            "Layer: 4: mean: 0.08, std deviation: 0.08\n",
            "Layer: 6: mean: 0.04, std deviation: 0.03\n",
            "Layer: 8: mean: 0.02, std deviation: 0.01\n",
            "Layer: 10: mean: 0.01, std deviation: 0.01\n",
            "Layer: 12: mean: 0.00, std deviation: 0.00\n",
            "Layer: 14: mean: 0.00, std deviation: 0.00\n",
            "Layer: 16: mean: 0.00, std deviation: 0.00\n",
            "Layer: 18: mean: 0.00, std deviation: 0.00\n",
            "Layer: 20: mean: 0.00, std deviation: 0.00\n",
            "Layer: 22: mean: 0.00, std deviation: 0.00\n",
            "Layer: 24: mean: 0.00, std deviation: 0.00\n",
            "Layer: 26: mean: 0.00, std deviation: 0.00\n",
            "Layer: 28: mean: 0.00, std deviation: 0.00\n",
            "Layer: 30: mean: 0.00, std deviation: 0.00\n",
            "Layer: 32: mean: 0.00, std deviation: 0.00\n",
            "Layer: 34: mean: 0.00, std deviation: 0.00\n",
            "Layer: 36: mean: 0.00, std deviation: 0.00\n",
            "Layer: 38: mean: 0.00, std deviation: 0.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Test of leaky_relu\n",
        "def listing2_2_5_test():\n",
        "    from scipy.special import erfc\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # alpha and scale to self normalize with mean 0 and standard deviation 1 (see equation 14 in the paper):\n",
        "    alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "    scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
        "        \n",
        "    # Built-in relu functions: NOT WORKING\n",
        "    # def leaky_relu(z):\n",
        "    #     return tf.nn.leaky_relu(z)\n",
        "\n",
        "    def leaky_relu(z, alpha=0.01):\n",
        "        return np.maximum(alpha*z, z)\n",
        "\n",
        "    data_means = []\n",
        "    Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "    for layer in range(40):\n",
        "        W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "        Z = leaky_relu(np.dot(Z, W))\n",
        "        means = np.mean(Z, axis=0).mean()\n",
        "        stds = np.std(Z, axis=0).mean()\n",
        "        if layer % 2 == 0:\n",
        "            print(f\"Layer: {layer}: mean: {means:.2f}, std deviation: {stds:.2f}\")\n",
        "        data_means.append(means)\n",
        " \n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(data_means)\n",
        "    df.plot(grid=True, legend=False)\n",
        "    plt.show()\n",
        "    \n",
        "listing2_2_5_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46SAzSs98Irq"
      },
      "source": [
        "<a id='2.3.2'></a><a name='2.3.2'></a>\n",
        "### 2.3.2 PReLU\n",
        "\n",
        "用語「PReLU（Parametric ReLU）」について説明。「0」を基点として、入力値が0より下なら「入力値をα倍した値」（αはパラメーターであり学習により決まる）、0以上なら「入力値と同じ値」を返す、ニューラルネットワークの活性化関数を指す。ReLUやLeaky ReLUの拡張版\n",
        "\n",
        "* https://atmarkit.itmedia.co.jp/ait/articles/2005/20/news010.html\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBTZM9xj8Irq",
        "outputId": "44dc4d3d-113c-42bc-8fc8-10aa82f02859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 7s - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7186 - 7s/epoch - 4ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 5s - loss: 0.8197 - accuracy: 0.7355 - val_loss: 0.7305 - val_accuracy: 0.7630 - 5s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 4s - loss: 0.6966 - accuracy: 0.7694 - val_loss: 0.6565 - val_accuracy: 0.7878 - 4s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 6s - loss: 0.6331 - accuracy: 0.7909 - val_loss: 0.6003 - val_accuracy: 0.8046 - 6s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 4s - loss: 0.5917 - accuracy: 0.8056 - val_loss: 0.5657 - val_accuracy: 0.8178 - 4s/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.5657 - accuracy: 0.8178 - 304ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.5656538605690002, 0.817799985408783]\n",
            "----------------------------------------\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " p_re_lu (PReLU)             (None, 300)               300       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " p_re_lu_1 (PReLU)           (None, 100)               100       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267,010\n",
            "Trainable params: 267,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with keras.layers.PReLU\n",
        "\n",
        "def listing2_3_2():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    # Get dataset\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.PReLU(),\n",
        "        keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.PReLU(),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "listing2_3_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A99DNK28Irr"
      },
      "source": [
        "<a id='2.3.3'></a><a name='2.3.3'></a>\n",
        "### 2.3.3 ELU\n",
        "\n",
        "用語「ELU（Exponential Linear Unit）」について説明。「0」を基点として、入力値が0以下なら「0」～「-α」（αは基本的に1.0）の間の値を、0より上なら「入力値と同じ値」を返す、ニューラルネットワークの活性化関数を指す。ReLUの拡張版。\n",
        "\n",
        "* https://atmarkit.itmedia.co.jp/ait/articles/2005/27/news015.html\n",
        "* https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#elu\n",
        "\n",
        "A 2015 paper by Djork-Arné Clevert et al.6 proposed a new activation function called the exponential linear unit (ELU) that outperformed all the ReLU variants in the authors’ experiments: training time was reduced, and the neural network performed better on the test set.\n",
        "\n",
        "The ELU activation function looks a lot like the ReLU function, with a few major differences:\n",
        "\n",
        "* It takes on negative values when z < 0, which allows the unit to have an average output closer to 0 and helps alleviate the vanishing gradients problem. The hyperparameter α defines the value that the ELU function approaches when z is a large negative number. It is usually set to 1, but you can tweak it like any other hyperparameter.\n",
        "* It has a nonzero gradient for z < 0, which avoids the dead neurons problem.\n",
        "* If α is equal to 1 then the function is smooth everywhere, including around z = 0, which helps speed up Gradient Descent since it does not bounce as much to the left and right of z = 0.\n",
        "\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Lg0kBCZf8Irs",
        "outputId": "38532bda-725e-48b9-97c9-23e6e8bedb09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2_3_3_graph():\n",
        "    \n",
        "    def elu(z, alpha=1):\n",
        "        return tf.nn.elu(z)\n",
        "    \n",
        "    z = np.linspace(-5, 5, 200)\n",
        "\n",
        "    plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
        "    plt.plot([-5, 5], [0, 0], 'k-')\n",
        "    plt.plot([-5, 5], [-1, -1], 'k--') # dark horizonal line\n",
        "    plt.plot([0, 0], [-2.2, 3.2], 'k-') # dark vert line\n",
        "    plt.grid(True)\n",
        "    plt.title(r\"ELU activation function (alpha=1)\")\n",
        "    plt.axis([-5, 5, -2.2, 3.2])\n",
        "    plt.show()\n",
        "    \n",
        "listing2_3_3_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "DmuF8hwl8Irs",
        "outputId": "69a525ca-0b20-4fb7-b6b1-07d192ead838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: 0: mean: 0.16, std deviation: 0.79\n",
            "Layer: 1: mean: 0.12, std deviation: 0.63\n",
            "Layer: 2: mean: 0.07, std deviation: 0.52\n",
            "Layer: 3: mean: 0.06, std deviation: 0.44\n",
            "Layer: 4: mean: 0.04, std deviation: 0.39\n",
            "Layer: 5: mean: 0.04, std deviation: 0.34\n",
            "Layer: 6: mean: 0.02, std deviation: 0.30\n",
            "Layer: 7: mean: 0.03, std deviation: 0.28\n",
            "Layer: 8: mean: 0.01, std deviation: 0.25\n",
            "Layer: 9: mean: 0.02, std deviation: 0.23\n",
            "Layer: 10: mean: 0.01, std deviation: 0.20\n",
            "Layer: 11: mean: 0.01, std deviation: 0.19\n",
            "Layer: 12: mean: 0.01, std deviation: 0.18\n",
            "Layer: 13: mean: 0.00, std deviation: 0.17\n",
            "Layer: 14: mean: 0.01, std deviation: 0.16\n",
            "Layer: 15: mean: 0.01, std deviation: 0.14\n",
            "Layer: 16: mean: 0.01, std deviation: 0.13\n",
            "Layer: 17: mean: 0.01, std deviation: 0.13\n",
            "Layer: 18: mean: 0.01, std deviation: 0.12\n",
            "Layer: 19: mean: -0.00, std deviation: 0.11\n",
            "Layer: 20: mean: -0.00, std deviation: 0.11\n",
            "Layer: 21: mean: 0.01, std deviation: 0.10\n",
            "Layer: 22: mean: 0.01, std deviation: 0.09\n",
            "Layer: 23: mean: 0.00, std deviation: 0.09\n",
            "Layer: 24: mean: 0.01, std deviation: 0.09\n",
            "Layer: 25: mean: 0.00, std deviation: 0.09\n",
            "Layer: 26: mean: 0.01, std deviation: 0.08\n",
            "Layer: 27: mean: 0.00, std deviation: 0.08\n",
            "Layer: 28: mean: -0.00, std deviation: 0.08\n",
            "Layer: 29: mean: -0.00, std deviation: 0.08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2_3_3_test():\n",
        "    from scipy.special import erfc\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # alpha and scale to self normalize with mean 0 and standard deviation 1\n",
        "    # (see equation 14 in the paper):\n",
        "    alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "    scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
        "    \n",
        "    def elu(z, alpha=1):\n",
        "        return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
        "    \n",
        "    # def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "    #     return scale * elu(z, alpha)\n",
        "\n",
        "    # THESE ARE NOT WORKING\n",
        "    # Built-in selu and elu functions\n",
        "#     def selu(z, alpha=1):\n",
        "#         return tf.nn.selu(z)\n",
        "    \n",
        "#     def elu(z, alpha=1):\n",
        "#         return tf.nn.elu(z)\n",
        "    \n",
        "    data_means = []\n",
        "    Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "    for layer in range(30):\n",
        "        W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "        Z = elu(np.dot(Z, W))\n",
        "        means = np.mean(Z, axis=0).mean()\n",
        "        stds = np.std(Z, axis=0).mean()\n",
        "        #if layer % 100 == 0:\n",
        "        print(f\"Layer: {layer}: mean: {means:.2f}, std deviation: {stds:.2f}\")\n",
        "        data_means.append(means)\n",
        " \n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(data_means)\n",
        "    df.plot(grid=True, legend=False)\n",
        "    plt.show()\n",
        "    \n",
        "listing2_3_3_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeKLUTMZ8Irt",
        "outputId": "809eb372-da91-48c7-f8d6-6aa3d9dad66f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 5s - loss: 1.3465 - accuracy: 0.6208 - val_loss: 0.9257 - val_accuracy: 0.7190 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 5s - loss: 0.8198 - accuracy: 0.7356 - val_loss: 0.7306 - val_accuracy: 0.7628 - 5s/epoch - 3ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 5s - loss: 0.6966 - accuracy: 0.7694 - val_loss: 0.6565 - val_accuracy: 0.7876 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 6s - loss: 0.6331 - accuracy: 0.7910 - val_loss: 0.6003 - val_accuracy: 0.8046 - 6s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 4s - loss: 0.5917 - accuracy: 0.8057 - val_loss: 0.5656 - val_accuracy: 0.8182 - 4s/epoch - 3ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.5656 - accuracy: 0.8182 - 344ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.5655964016914368, 0.8181999921798706]\n",
            "----------------------------------------\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " p_re_lu_2 (PReLU)           (None, 300)               300       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " p_re_lu_3 (PReLU)           (None, 100)               100       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 267,010\n",
            "Trainable params: 267,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with keras.layers.PReLU, elu-activation\n",
        "\n",
        "def listing2_3_3():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, kernel_initializer=\"he_normal\", activation=\"elu\"),\n",
        "        keras.layers.PReLU(),\n",
        "        keras.layers.Dense(100, kernel_initializer=\"he_normal\", activation=\"elu\"),\n",
        "        keras.layers.PReLU(),\n",
        "        keras.layers.Dense(10, activation=\"softmax\") # elu or softmax?\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "listing2_3_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q91owra8Iru"
      },
      "source": [
        "<a id='2.3.4'></a><a name='2.3.4'></a>\n",
        "### 2.3.4 SELU\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "用語「SELU（Scaled Exponential Linear Unit）」について説明。「0」を基点として、入力値が0以下なら「0」～「-λα」（λは基本的に約1.0507、αは基本的に約1.6733）の間の値を、0より上なら「入力値をλ倍した値」を返す、ニューラルネットワークの活性化関数を指す。ReLUおよびELUの拡張版。\n",
        "\n",
        "* https://atmarkit.itmedia.co.jp/ait/articles/2006/03/news019.html\n",
        "\n",
        "---\n",
        "\n",
        "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions.\n",
        "\n",
        "---\n",
        "\n",
        "SELU is is a scaled variant of the ELU activation function.\n",
        "\n",
        "A 2017 paper by Günter Klambauer et al. introduced the Scaled ELU (SELU) activation function: as its name suggests, it is a scaled variant of the ELU activation function. The authors showed that if you build a neural network composed exclusively of a stack of dense layers, and if all hidden layers use the SELU activation function, then the network will self-normalize: the output of each layer will tend to preserve a mean of 0 and standard deviation of 1 during training, which solves the vanishing/exploding gradients problem. As a result, the SELU activation function often significantly outperforms other activation functions for such neural nets (especially deep ones). There are, however, a few conditions for self-normalization to happen (see the paper for the mathematical justification):\n",
        "\n",
        "* The input features must be standardized (mean 0 and standard deviation 1).\n",
        "* Every hidden layer’s weights must be initialized with LeCun normal initialization. In Keras, this means setting `kernel_initializer=\"lecun_normal`.\n",
        "* The network’s architecture must be sequential. Unfortunately, if you try to use SELU in nonsequential architectures, such as recurrent networks (see Chapter 15) or networks with skip connections (i.e., connections that skip layers, such as in Wide & Deep nets), self-normalization will not be guaranteed, so SELU will not necessarily outperform other activation functions.\n",
        "* The paper only guarantees self-normalization if all layers are dense, but some researchers have noted that the SELU activation function can improve performance in convolutional neural nets as well (see Chapter 14).\n",
        "\n",
        "---\n",
        "\n",
        "So, which activation function should you use for the hidden layers of your deep neural networks? Although your mileage will vary, in general:\n",
        "\n",
        "    SELU > ELU > leaky ReLU (and its variants) > ReLU > tanh > logistic. \n",
        "\n",
        "If the network’s architecture prevents it from self-normalizing, then ELU may perform better than SELU (since SELU is not smooth at z = 0). \n",
        "\n",
        "If you care a lot about runtime latency, then you may prefer leaky ReLU. \n",
        "\n",
        "If you don’t want to tweak yet another hyperparameter, you may use the default α values used by Keras (e.g., 0.3 for leaky ReLU). \n",
        "\n",
        "If you have spare time and computing power, you can use cross-validation to evaluate other activation functions, such as RReLU if your network is overfitting or PReLU if you have a huge training set. \n",
        "\n",
        "That said, because ReLU is the most used activation function (by far), many libraries and hardware accelerators provide ReLU-specific optimizations; therefore, if speed is your priority, ReLU might still be the best choice.\n",
        "\n",
        "---\n",
        "\n",
        "By default, the SELU hyperparameters (scale and alpha) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GcpL04Cw8Iru",
        "outputId": "3cc55e4c-27d6-4dea-b229-4f06af699c46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing2_3_4_graph():\n",
        "    \n",
        "    from scipy.special import erfc\n",
        "\n",
        "    # alpha and scale to self normalize with mean 0 and standard deviation 1\n",
        "    # (see equation 14 in the paper):\n",
        "    alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "    scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
        "    \n",
        "    def elu(z, alpha=1):\n",
        "        return tf.nn.elu(z)\n",
        "    \n",
        "    z = np.linspace(-5, 5, 200)\n",
        "    \n",
        "    def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "        return scale * elu(z, alpha)\n",
        "    \n",
        "    plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
        "    plt.plot([-5, 5], [0, 0], 'k-')\n",
        "    plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
        "    plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "    plt.grid(True)\n",
        "    plt.title(\"SELU activation function\", fontsize=14)\n",
        "    plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "listing2_3_4_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3x7pwaK8Irv"
      },
      "source": [
        "By default, the SELU hyperparameters (scale and alpha) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). \n",
        "\n",
        "Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veiSzlmP8Irv",
        "outputId": "7d3ab031-658e-49e2-dd73-bc3a8dac9bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 26s - loss: 1.2933 - accuracy: 0.5122 - val_loss: 1.1249 - val_accuracy: 0.5768 - 26s/epoch - 15ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 18s - loss: 0.8387 - accuracy: 0.6819 - val_loss: 0.7307 - val_accuracy: 0.7362 - 18s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 17s - loss: 0.7145 - accuracy: 0.7345 - val_loss: 0.8415 - val_accuracy: 0.6598 - 17s/epoch - 10ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 18s - loss: 0.6880 - accuracy: 0.7506 - val_loss: 0.6032 - val_accuracy: 0.7754 - 18s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 17s - loss: 0.7500 - accuracy: 0.7309 - val_loss: 0.7105 - val_accuracy: 0.7652 - 17s/epoch - 10ms/step\n",
            "----------------------------------------\n",
            "157/157 - 1s - loss: 1.5405 - accuracy: 0.4932 - 1s/epoch - 7ms/step\n",
            "[test loss, test accuracy]: [1.5404752492904663, 0.49320000410079956]\n",
            "----------------------------------------\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,256,410\n",
            "Trainable params: 1,256,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with 100 hidden layers, SELU activation function\n",
        "\n",
        "def listing2_3_4():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    # Scale the inputs to mean 0 and standard deviation 1.\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "    model.add(keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "\n",
        "    for layer in range(99):\n",
        "        model.add(keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\")\n",
        "    )\n",
        "\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "        \n",
        "    history = model.fit(\n",
        "        X_train_scaled, y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=2\n",
        "    )  \n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)    \n",
        "\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "listing2_3_4()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNA-gOU58Irw"
      },
      "source": [
        "<a id='2.3.5'></a><a name='2.3.5'></a>\n",
        "### 2.3.5 RELU\n",
        "\n",
        "用語「ReLU（Rectified Linear Unit）／ランプ関数」について説明。「0」を基点として、0以下なら「0」、0より上なら「入力値と同じ値」を返す、ニューラルネットワークの活性化関数を指す。\n",
        "\n",
        "* https://atmarkit.itmedia.co.jp/ait/articles/2003/11/news016.html\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ek4OH2N8Irw",
        "outputId": "d8d635e6-279f-4a52-fcd6-85d2fb79874a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 23s - loss: 1.8095 - accuracy: 0.2688 - val_loss: 1.4305 - val_accuracy: 0.3600 - 23s/epoch - 13ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 18s - loss: 1.1348 - accuracy: 0.5196 - val_loss: 0.9388 - val_accuracy: 0.6292 - 18s/epoch - 10ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 20s - loss: 0.9248 - accuracy: 0.6242 - val_loss: 0.8201 - val_accuracy: 0.6810 - 20s/epoch - 11ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 17s - loss: 0.8170 - accuracy: 0.6777 - val_loss: 0.7776 - val_accuracy: 0.6996 - 17s/epoch - 10ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 17s - loss: 0.8745 - accuracy: 0.6497 - val_loss: 0.8889 - val_accuracy: 0.6558 - 17s/epoch - 10ms/step\n",
            "----------------------------------------\n",
            "157/157 - 1s - loss: 4.0805 - accuracy: 0.1690 - 816ms/epoch - 5ms/step\n",
            "[test loss, test accuracy]: [4.080451965332031, 0.16899999976158142]\n",
            "----------------------------------------\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_180 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_184 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_216 (Dense)           (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,256,410\n",
            "Trainable params: 1,256,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with 100 hidden layers, RELU activation function\n",
        "# This should perform worse than SELU, since it suffers from the vanishing/exploding gradients problem.\n",
        "\n",
        "def listing2_3_5():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    # Scale the inputs to mean 0 and standard deviation 1.\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "    model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "\n",
        "    for layer in range(99):\n",
        "        model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())    \n",
        "\n",
        "listing2_3_5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "HQCM4m0y8Irx",
        "outputId": "399beb5a-281c-4974-a5a5-42888f5dadcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: 0: mean: 0.40, std deviation: 0.58\n",
            "Layer: 1: mean: 0.30, std deviation: 0.35\n",
            "Layer: 2: mean: 0.19, std deviation: 0.20\n",
            "Layer: 3: mean: 0.14, std deviation: 0.13\n",
            "Layer: 4: mean: 0.09, std deviation: 0.08\n",
            "Layer: 5: mean: 0.06, std deviation: 0.05\n",
            "Layer: 6: mean: 0.04, std deviation: 0.03\n",
            "Layer: 7: mean: 0.03, std deviation: 0.02\n",
            "Layer: 8: mean: 0.02, std deviation: 0.01\n",
            "Layer: 9: mean: 0.01, std deviation: 0.01\n",
            "Layer: 10: mean: 0.01, std deviation: 0.00\n",
            "Layer: 11: mean: 0.00, std deviation: 0.00\n",
            "Layer: 12: mean: 0.00, std deviation: 0.00\n",
            "Layer: 13: mean: 0.00, std deviation: 0.00\n",
            "Layer: 14: mean: 0.00, std deviation: 0.00\n",
            "Layer: 15: mean: 0.00, std deviation: 0.00\n",
            "Layer: 16: mean: 0.00, std deviation: 0.00\n",
            "Layer: 17: mean: 0.00, std deviation: 0.00\n",
            "Layer: 18: mean: 0.00, std deviation: 0.00\n",
            "Layer: 19: mean: 0.00, std deviation: 0.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# This illustrates the dying ReLUs, where in training some neurons stop outputting anything other than 0.\n",
        "def listing2_3_5_extra():\n",
        "    from scipy.special import erfc\n",
        "    import pandas as pd\n",
        "\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # alpha and scale to self normalize with mean 0 and standard deviation 1 (see equation 14 in the paper):\n",
        "    alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "    scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
        "        \n",
        "    # Built-in relu functions\n",
        "    # def relu(z):\n",
        "    #     return tf.nn.relu(z)\n",
        "    \n",
        "    def relu(z, alpha=1):\n",
        "        return np.where(z > 0, z, 0)\n",
        "\n",
        "    data_means = []\n",
        "    Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "    #for layer in range(1000):\n",
        "    for layer in range(20):\n",
        "        W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "        Z = relu(np.dot(Z, W))\n",
        "        means = np.mean(Z, axis=0).mean()\n",
        "        stds = np.std(Z, axis=0).mean()\n",
        "        \n",
        "        # Print every iteration to show how quickly ReLU dies here:\n",
        "        print(f\"Layer: {layer}: mean: {means:.2f}, std deviation: {stds:.2f}\")\n",
        "        data_means.append(means)\n",
        " \n",
        "    df = pd.DataFrame(data_means)\n",
        "    df.plot(grid=True, legend=False)\n",
        "    plt.show()\n",
        "    \n",
        "listing2_3_5_extra()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqClBwGF8Ir0"
      },
      "source": [
        "<a id='2.3.6'></a><a name='2.3.6'></a>\n",
        "### 2.3.6 Overall Test of Activation Functions (added)\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uchyT6h68Ir0",
        "outputId": "1be06033-2fb5-424e-b63d-3f086dd8c15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid\n",
            "Layer: 0: mean: 0.499, std deviation: 0.208\n",
            "Layer: 2: mean: 0.496, std deviation: 0.011\n",
            "Layer: 4: mean: 0.491, std deviation: 0.001\n",
            "Layer: 6: mean: 0.506, std deviation: 0.000\n",
            "Layer: 8: mean: 0.503, std deviation: 0.000\n",
            "Layer: 10: mean: 0.499, std deviation: 0.000\n",
            "Layer: 12: mean: 0.515, std deviation: 0.000\n",
            "Layer: 14: mean: 0.508, std deviation: 0.000\n",
            "Layer: 16: mean: 0.507, std deviation: 0.000\n",
            "Layer: 18: mean: 0.502, std deviation: 0.000\n",
            "Layer: 20: mean: 0.494, std deviation: 0.000\n",
            "Layer: 22: mean: 0.505, std deviation: 0.000\n",
            "Layer: 24: mean: 0.501, std deviation: 0.000\n",
            "Layer: 26: mean: 0.474, std deviation: 0.000\n",
            "Layer: 28: mean: 0.485, std deviation: 0.000\n",
            "----------------------------------------\n",
            "SELU\n",
            "Layer: 0: mean: -0.006, std deviation: 0.995\n",
            "Layer: 2: mean: 0.005, std deviation: 0.984\n",
            "Layer: 4: mean: -0.004, std deviation: 0.972\n",
            "Layer: 6: mean: -0.009, std deviation: 0.964\n",
            "Layer: 8: mean: -0.000, std deviation: 0.978\n",
            "Layer: 10: mean: -0.003, std deviation: 0.965\n",
            "Layer: 12: mean: 0.002, std deviation: 1.001\n",
            "Layer: 14: mean: 0.001, std deviation: 0.974\n",
            "Layer: 16: mean: -0.008, std deviation: 0.975\n",
            "Layer: 18: mean: 0.014, std deviation: 0.984\n",
            "Layer: 20: mean: 0.012, std deviation: 1.002\n",
            "Layer: 22: mean: -0.004, std deviation: 0.981\n",
            "Layer: 24: mean: -0.003, std deviation: 0.992\n",
            "Layer: 26: mean: 0.007, std deviation: 0.978\n",
            "Layer: 28: mean: 0.024, std deviation: 1.012\n",
            "----------------------------------------\n",
            "RELU\n",
            "Layer: 0: mean: 0.400, std deviation: 0.585\n",
            "Layer: 2: mean: 0.205, std deviation: 0.201\n",
            "Layer: 4: mean: 0.112, std deviation: 0.083\n",
            "Layer: 6: mean: 0.052, std deviation: 0.036\n",
            "Layer: 8: mean: 0.019, std deviation: 0.014\n",
            "Layer: 10: mean: 0.009, std deviation: 0.006\n",
            "Layer: 12: mean: 0.005, std deviation: 0.003\n",
            "Layer: 14: mean: 0.003, std deviation: 0.001\n",
            "Layer: 16: mean: 0.001, std deviation: 0.001\n",
            "Layer: 18: mean: 0.001, std deviation: 0.000\n",
            "Layer: 20: mean: 0.000, std deviation: 0.000\n",
            "Layer: 22: mean: 0.000, std deviation: 0.000\n",
            "Layer: 24: mean: 0.000, std deviation: 0.000\n",
            "Layer: 26: mean: 0.000, std deviation: 0.000\n",
            "Layer: 28: mean: 0.000, std deviation: 0.000\n",
            "----------------------------------------\n",
            "Leaky RELU\n",
            "Layer: 0: mean: 0.390, std deviation: 0.577\n",
            "Layer: 2: mean: 0.179, std deviation: 0.195\n",
            "Layer: 4: mean: 0.091, std deviation: 0.078\n",
            "Layer: 6: mean: 0.039, std deviation: 0.030\n",
            "Layer: 8: mean: 0.023, std deviation: 0.014\n",
            "Layer: 10: mean: 0.015, std deviation: 0.008\n",
            "Layer: 12: mean: 0.007, std deviation: 0.003\n",
            "Layer: 14: mean: 0.003, std deviation: 0.001\n",
            "Layer: 16: mean: 0.001, std deviation: 0.001\n",
            "Layer: 18: mean: 0.001, std deviation: 0.000\n",
            "Layer: 20: mean: 0.000, std deviation: 0.000\n",
            "Layer: 22: mean: 0.000, std deviation: 0.000\n",
            "Layer: 24: mean: 0.000, std deviation: 0.000\n",
            "Layer: 26: mean: 0.000, std deviation: 0.000\n",
            "Layer: 28: mean: 0.000, std deviation: 0.000\n",
            "----------------------------------------\n",
            "    data_sigmoid      selu      relu  leaky_relu\n",
            "0   2.080282e-01  0.994965  0.585025    0.577141\n",
            "1   4.812896e-02  0.986550  0.342377    0.336168\n",
            "2   1.115798e-02  0.984145  0.200834    0.195270\n",
            "3   2.572709e-03  0.987638  0.131415    0.126311\n",
            "4   6.145401e-04  0.972419  0.082898    0.078021\n",
            "5   1.448996e-04  0.970567  0.057994    0.050587\n",
            "6   3.475201e-05  0.964336  0.035986    0.029871\n",
            "7   8.479860e-06  0.975944  0.021836    0.021163\n",
            "8   2.011261e-06  0.978131  0.013867    0.014159\n",
            "9   4.741207e-07  0.989163  0.008844    0.009665\n",
            "10  1.063946e-07  0.964875  0.005552    0.007530\n",
            "11  2.494907e-08  0.990246  0.004305    0.004964\n",
            "12  6.010320e-09  1.000868  0.002587    0.003332\n",
            "13  1.452982e-09  0.977578  0.001801    0.002150\n",
            "14  3.421472e-10  0.973918  0.001278    0.001411\n",
            "15  7.711474e-11  0.980890  0.000824    0.001087\n",
            "16  1.761760e-11  0.975160  0.000649    0.000613\n",
            "17  4.187589e-12  0.961039  0.000446    0.000427\n",
            "18  9.732295e-13  0.984240  0.000283    0.000285\n",
            "19  2.281787e-13  1.006227  0.000199    0.000214\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing_activation_functions():\n",
        "    import pandas as pd\n",
        "    from scipy.special import erfc\n",
        "\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # alpha and scale to self normalize with mean 0 and standard deviation 1 (see equation 14 in the paper):\n",
        "    alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "    scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
        "    \n",
        "    def logit(z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def elu(z, alpha=1):\n",
        "        return np.where(z < 0, alpha * (np.exp(z) - 1), z)\n",
        "        \n",
        "    def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "        return scale * elu(z, alpha)\n",
        "\n",
        "    def leaky_relu(z, alpha=0.01):\n",
        "        return np.maximum(alpha*z, z)\n",
        "    \n",
        "    # def relu(z, alpha=0.01):\n",
        "    #     return np.where(z > 0, z, 0)\n",
        "    \n",
        "    # equivalent to  np.where(x1 >= x2, x1, x2) when neither x1 nor x2 are nans,\n",
        "    def relu(z):\n",
        "        return(np.maximum(0, z)) \n",
        "    \n",
        "    Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "    \n",
        "    def run_layer(activation_fn, Z):\n",
        "        #data_means = []\n",
        "        data_stds = []\n",
        "        \n",
        "        for layer in range(30): # 1000\n",
        "            W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "\n",
        "            # Make this a parameter\n",
        "            Z = activation_fn(np.dot(Z, W))\n",
        "\n",
        "            means = np.mean(Z, axis=0).mean()\n",
        "            stds = np.std(Z, axis=0).mean()\n",
        "            if layer % 2 == 0:\n",
        "                print(f\"Layer: {layer}: mean: {means:.3f}, std deviation: {stds:.3f}\")\n",
        "            #data_means.append(means)\n",
        "            data_stds.append(stds)\n",
        "        HR()\n",
        "        return data_stds\n",
        "\n",
        "    print(\"Sigmoid\")\n",
        "    data_sigmoid = run_layer(logit, Z)\n",
        "    \n",
        "    print(\"SELU\")\n",
        "    data_selu = run_layer(selu, Z)\n",
        "    \n",
        "    print(\"RELU\")\n",
        "    data_relu = run_layer(relu, Z)\n",
        "    \n",
        "    print(\"Leaky RELU\")\n",
        "    data_leaky_relu = run_layer(leaky_relu, Z)\n",
        "    \n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        list(zip(data_sigmoid, data_selu, data_relu, data_leaky_relu)), \n",
        "        columns =['data_sigmoid', 'selu', 'relu', 'leaky_relu']\n",
        "    )\n",
        "    \n",
        "    print(df.head(20))\n",
        "    df.plot(grid=True, legend=True, alpha=0.75, figsize=(8,6))\n",
        "    plt.show()\n",
        "    \n",
        "listing_activation_functions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMhVj4at8Ir1"
      },
      "source": [
        "---\n",
        "<a id='2.4'></a><a name='2.4'></a>\n",
        "## 2.4. Batch Normalization / バッチ正規化\n",
        "\n",
        "バッチ正規化(Batch Normalization) は，主に畳み込みニューラルネットワーク(CNN)の隠れ層において，ミニバッチ内のデータ分布をもとに，各チャンネルごとに，特徴を正規化したのち，スケール・シフトを行う微分可能な変換(層)である [Ioffe and Szegedy, 2015]．バッチ正規化は，元のCNNの表現力の高さを保ちつつも，学習の収束の高速化と安定化を達成できるので，層の深いモデルを安定して学習するために必須の技術である．\n",
        "\n",
        "* https://cvml-expertguide.net/terms/dl/layers/batch-normalization-layer/\n",
        "\n",
        "During training, BN standardizes its inputs, then rescales and offsets them.\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnvjVUI_8Ir1",
        "outputId": "031e9b71-776e-42e4-efb4-52e74bab3875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "[('batch_normalization/gamma:0', True), ('batch_normalization/beta:0', True), ('batch_normalization/moving_mean:0', False), ('batch_normalization/moving_variance:0', False)]\n",
            "Epoch 1/3\n",
            "1719/1719 - 7s - loss: 0.8558 - accuracy: 0.7167 - val_loss: 0.5625 - val_accuracy: 0.8152 - 7s/epoch - 4ms/step\n",
            "Epoch 2/3\n",
            "1719/1719 - 7s - loss: 0.5782 - accuracy: 0.8041 - val_loss: 0.4834 - val_accuracy: 0.8388 - 7s/epoch - 4ms/step\n",
            "Epoch 3/3\n",
            "1719/1719 - 6s - loss: 0.5225 - accuracy: 0.8209 - val_loss: 0.4465 - val_accuracy: 0.8498 - 6s/epoch - 4ms/step\n",
            "----------------------------------------\n",
            "157/157 - 1s - loss: 0.4465 - accuracy: 0.8498 - 800ms/epoch - 5ms/step\n",
            "[test loss, test accuracy]: [0.4465329945087433, 0.8497999906539917]\n",
            "----------------------------------------\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def listing2_4():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    HR()\n",
        "        \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(300, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(100, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    bn1 = model.layers[1]\n",
        "    print([(var.name, var.trainable) for var in bn1.variables])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=3,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())  \n",
        "    \n",
        "listing2_4()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ZPoQm28Ir2"
      },
      "source": [
        "---\n",
        "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chgBPis8Ir2",
        "outputId": "4ef061bf-8960-400f-d25e-749cb634cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 784)              3136      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 300)               235200    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 300)              1200      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 300)               0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 100)               30000     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 270,946\n",
            "Trainable params: 268,578\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------\n",
            "Epoch 1/5\n",
            "1719/1719 - 9s - loss: 1.0391 - accuracy: 0.6783 - val_loss: 0.6719 - val_accuracy: 0.7962 - 9s/epoch - 5ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 7s - loss: 0.6757 - accuracy: 0.7855 - val_loss: 0.5561 - val_accuracy: 0.8250 - 7s/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 6s - loss: 0.5952 - accuracy: 0.8052 - val_loss: 0.5025 - val_accuracy: 0.8354 - 6s/epoch - 4ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 6s - loss: 0.5455 - accuracy: 0.8199 - val_loss: 0.4699 - val_accuracy: 0.8450 - 6s/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 6s - loss: 0.5126 - accuracy: 0.8279 - val_loss: 0.4459 - val_accuracy: 0.8524 - 6s/epoch - 3ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4459 - accuracy: 0.8524 - 322ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.4458855986595154, 0.852400004863739]\n"
          ]
        }
      ],
      "source": [
        "def listing2_4b():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dense(300, use_bias=False),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation(\"relu\"),\n",
        "        keras.layers.Dense(100, use_bias=False),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Activation(\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    print(model.summary())\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    \n",
        "listing2_4b()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQdaajdZ8Ir2"
      },
      "source": [
        "<a id='2.5'></a><a name='2.5'></a>\n",
        "## 2.5 Gradient Clipping\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/clip_by_norm\n",
        "* https://www.tensorflow.org/api_docs/python/tf/clip_by_global_norm\n",
        "* https://www.tensorflow.org/api_docs/python/tf/clip_by_value\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Another popular technique to mitigate the exploding gradients problem is to clip the gradients during backpropagation so that they never exceed some threshold.\n",
        "\n",
        "This technique is most often used in recurrent neural networks, as Batch Normalization is tricky to use in RNNs. For other types of networks, Batch Normalization is usually sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo72hPGn8Ir3"
      },
      "source": [
        "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZThWstbL8Ir3"
      },
      "outputs": [],
      "source": [
        "# Clips tensor values to a specified min and max.\n",
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FdwC6CBY8Ir4"
      },
      "outputs": [],
      "source": [
        "# Clips tensor values to a maximum L2-norm.\n",
        "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBC00RGs8Ir4"
      },
      "source": [
        "<a id='2.5.1'></a><a name='2.5.1'></a>\n",
        "### 2.5.1 Gradient Clipping: Clip tensor values to a specified min and max\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFzU02D78Ir4",
        "outputId": "d091794b-4250-48d3-b06f-96f105a8a814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,510\n",
            "Trainable params: 238,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------\n",
            "Epoch 1/5\n",
            "1719/1719 - 4s - loss: 0.7451 - accuracy: 0.7603 - val_loss: 0.5415 - val_accuracy: 0.8276 - 4s/epoch - 2ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 4s - loss: 0.5165 - accuracy: 0.8249 - val_loss: 0.4689 - val_accuracy: 0.8456 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 4s - loss: 0.4705 - accuracy: 0.8372 - val_loss: 0.5006 - val_accuracy: 0.8148 - 4s/epoch - 2ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 4s - loss: 0.4452 - accuracy: 0.8467 - val_loss: 0.4290 - val_accuracy: 0.8560 - 4s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 4s - loss: 0.4287 - accuracy: 0.8515 - val_loss: 0.4088 - val_accuracy: 0.8604 - 4s/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4088 - accuracy: 0.8604 - 304ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.4088192880153656, 0.8604000210762024]\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with Gradient Clipping\n",
        "\n",
        "def listing2_5_1():\n",
        "    \n",
        "    # Only tensorflow random seed has an influence on the random choice of weights.\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        # This optimizer will clip every component of the gradient vector to a value between –1.0 and 1.0\n",
        "        # This means that all the partial derivatives of the loss (with regard to each and every trainable parameter) will be clipped between –1.0 and 1.0. \n",
        "        optimizer=keras.optimizers.SGD(clipvalue=1.0),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "    HR()\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    \n",
        "listing2_5_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic_enQ9t8Ir5"
      },
      "source": [
        "<a id='2.5.2'></a><a name='2.5.2'></a>\n",
        "### 2.5.2 Gradient Clipping: Clip tensor values to a maximum L2-norm\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "If you want to ensure that Gradient Clipping does not change the direction of the gradient vector, you should clip by norm by setting `clipnorm`. This will clip the whole gradient if its l2 norm is greater than the threshold you picked.\n",
        "\n",
        "For example, if you set `clipnorm=1.0`, then the vector [0.9, 100.0] will be clipped to [0.00899964, 0.9999595], preserving its orientation but almost eliminating the first component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3ALTnPC8Ir6",
        "outputId": "a31df2a1-9d96-4ab4-84ed-d94806b21fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,510\n",
            "Trainable params: 238,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------\n",
            "Epoch 1/5\n",
            "1719/1719 - 5s - loss: 0.8301 - accuracy: 0.7386 - val_loss: 0.5756 - val_accuracy: 0.8154 - 5s/epoch - 3ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 4s - loss: 0.5457 - accuracy: 0.8173 - val_loss: 0.4980 - val_accuracy: 0.8342 - 4s/epoch - 2ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 5s - loss: 0.4939 - accuracy: 0.8299 - val_loss: 0.4750 - val_accuracy: 0.8364 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 4s - loss: 0.4664 - accuracy: 0.8388 - val_loss: 0.4463 - val_accuracy: 0.8500 - 4s/epoch - 2ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 4s - loss: 0.4494 - accuracy: 0.8445 - val_loss: 0.4303 - val_accuracy: 0.8532 - 4s/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4303 - accuracy: 0.8532 - 296ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.43032315373420715, 0.8532000184059143]\n"
          ]
        }
      ],
      "source": [
        "# Data: Fashion MNIST\n",
        "# Model: MLP with Gradient Clipping\n",
        "\n",
        "def listing2_5_2():\n",
        "    \n",
        "    # Only tensorflow random seed has an influence on the random choice of weights.\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        # The gradient of each weight is individually clipped so that its norm is no higher than this value.\n",
        "        optimizer=keras.optimizers.SGD(clipnorm=1.0),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        epochs=5,\n",
        "        validation_data=(X_valid, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    \n",
        "listing2_5_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twZxs6tA8Ir6"
      },
      "source": [
        "---\n",
        "<a id='3.0'></a><a name='3.0'></a>\n",
        "# 3. Reusing Pretrained Layers / 事前学習済みの層の再利用\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DndIHH4H8Ir7"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## 3.1  Transfer Learning with Keras / Kerasによる転移学習\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U6fq0Rk8Ir7"
      },
      "source": [
        "Let's split the fashion MNIST training set in two:\n",
        "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
        "\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). \n",
        "\n",
        "We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). \n",
        "\n",
        "However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter).\n",
        "\n",
        "---\n",
        "\n",
        "It turns out that transfer learning does not work very well with small dense networks, presumably because small networks learn few patterns, and dense networks learn very specific patterns, which are unlikely to be useful in other tasks. Transfer learning works best with deep convolutional neural networks, which tend to learn feature detectors that are much more general (especially in the lower layers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lTTOPsj-8Ir8"
      },
      "outputs": [],
      "source": [
        "def split_dataset(X, y):\n",
        "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
        "    y_A = y[~y_5_or_6]\n",
        "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
        "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
        "    return ((X[~y_5_or_6], y_A),\n",
        "            (X[y_5_or_6], y_B))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_R7FQGp8Ir8",
        "outputId": "1e7a3a16-eb0c-4808-d64e-6bdb6b9801d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_228 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_232 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 8)                 408       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276,158\n",
            "Trainable params: 276,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "----------------------------------------\n",
            "Epoch 1/20\n",
            "1375/1375 - 4s - loss: 0.5926 - accuracy: 0.8103 - val_loss: 0.3895 - val_accuracy: 0.8667 - 4s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "1375/1375 - 3s - loss: 0.3523 - accuracy: 0.8787 - val_loss: 0.3291 - val_accuracy: 0.8824 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1375/1375 - 3s - loss: 0.3170 - accuracy: 0.8896 - val_loss: 0.3014 - val_accuracy: 0.8991 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1375/1375 - 3s - loss: 0.2972 - accuracy: 0.8975 - val_loss: 0.2892 - val_accuracy: 0.9016 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1375/1375 - 4s - loss: 0.2834 - accuracy: 0.9022 - val_loss: 0.2773 - val_accuracy: 0.9063 - 4s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1375/1375 - 4s - loss: 0.2729 - accuracy: 0.9062 - val_loss: 0.2733 - val_accuracy: 0.9073 - 4s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1375/1375 - 3s - loss: 0.2640 - accuracy: 0.9090 - val_loss: 0.2720 - val_accuracy: 0.9088 - 3s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1375/1375 - 3s - loss: 0.2572 - accuracy: 0.9126 - val_loss: 0.2588 - val_accuracy: 0.9145 - 3s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1375/1375 - 3s - loss: 0.2518 - accuracy: 0.9135 - val_loss: 0.2562 - val_accuracy: 0.9145 - 3s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1375/1375 - 3s - loss: 0.2468 - accuracy: 0.9152 - val_loss: 0.2541 - val_accuracy: 0.9163 - 3s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "1375/1375 - 3s - loss: 0.2422 - accuracy: 0.9176 - val_loss: 0.2496 - val_accuracy: 0.9150 - 3s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "1375/1375 - 3s - loss: 0.2382 - accuracy: 0.9188 - val_loss: 0.2512 - val_accuracy: 0.9128 - 3s/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "1375/1375 - 3s - loss: 0.2350 - accuracy: 0.9199 - val_loss: 0.2446 - val_accuracy: 0.9165 - 3s/epoch - 2ms/step\n",
            "Epoch 14/20\n",
            "1375/1375 - 4s - loss: 0.2315 - accuracy: 0.9214 - val_loss: 0.2414 - val_accuracy: 0.9175 - 4s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1375/1375 - 6s - loss: 0.2287 - accuracy: 0.9212 - val_loss: 0.2449 - val_accuracy: 0.9195 - 6s/epoch - 4ms/step\n",
            "Epoch 16/20\n",
            "1375/1375 - 3s - loss: 0.2254 - accuracy: 0.9224 - val_loss: 0.2385 - val_accuracy: 0.9193 - 3s/epoch - 2ms/step\n",
            "Epoch 17/20\n",
            "1375/1375 - 3s - loss: 0.2230 - accuracy: 0.9232 - val_loss: 0.2404 - val_accuracy: 0.9178 - 3s/epoch - 2ms/step\n",
            "Epoch 18/20\n",
            "1375/1375 - 5s - loss: 0.2200 - accuracy: 0.9244 - val_loss: 0.2426 - val_accuracy: 0.9153 - 5s/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "1375/1375 - 3s - loss: 0.2177 - accuracy: 0.9253 - val_loss: 0.2330 - val_accuracy: 0.9200 - 3s/epoch - 2ms/step\n",
            "Epoch 20/20\n",
            "1375/1375 - 3s - loss: 0.2155 - accuracy: 0.9262 - val_loss: 0.2332 - val_accuracy: 0.9205 - 3s/epoch - 3ms/step\n",
            "----------------------------------------\n",
            "126/126 - 0s - loss: 0.2332 - accuracy: 0.9205 - 249ms/epoch - 2ms/step\n",
            "Model A: [test loss, test accuracy]: [0.23320527374744415, 0.9205281734466553]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def listing3_1_model_A():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "    \n",
        "    # All images of all items except for sandals and shirts (classes 5 and 6).\n",
        "    (X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "    (X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "    (X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "    \n",
        "    # A much smaller training set of just the first 200 images of sandals or shirts.\n",
        "    X_train_B = X_train_B[:200]\n",
        "    y_train_B = y_train_B[:200]\n",
        "   \n",
        "    model_A = keras.models.Sequential()\n",
        "    model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "\n",
        "    for n_hidden in (300, 100, 50, 50, 50):\n",
        "        model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "\n",
        "    model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "    model_A.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    print(model_A.summary())\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    history = model_A.fit(\n",
        "        X_train_A, \n",
        "        y_train_A, \n",
        "        epochs=20,\n",
        "        validation_data=(X_valid_A, y_valid_A),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model_A.evaluate (\n",
        "        X_valid_A,\n",
        "        y_valid_A,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    print(\"Model A: [test loss, test accuracy]:\", eval_result)\n",
        "\n",
        "    HR()\n",
        "  \n",
        "    model_A.save(f\"{DATA_ROOT}/my_model_A.h5\")\n",
        "    \n",
        "listing3_1_model_A()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr4AH4A58Ir9",
        "outputId": "df8e4255-e510-4395-86d1-e1f4d6bfdfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_236 (Dense)           (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 275,801\n",
            "Trainable params: 275,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "7/7 - 1s - loss: 0.5808 - accuracy: 0.7350 - val_loss: 0.5192 - val_accuracy: 0.7911 - 678ms/epoch - 97ms/step\n",
            "Epoch 2/20\n",
            "7/7 - 0s - loss: 0.4778 - accuracy: 0.7900 - val_loss: 0.4383 - val_accuracy: 0.8408 - 97ms/epoch - 14ms/step\n",
            "Epoch 3/20\n",
            "7/7 - 0s - loss: 0.3997 - accuracy: 0.8650 - val_loss: 0.3794 - val_accuracy: 0.8773 - 99ms/epoch - 14ms/step\n",
            "Epoch 4/20\n",
            "7/7 - 0s - loss: 0.3443 - accuracy: 0.8800 - val_loss: 0.3344 - val_accuracy: 0.9026 - 100ms/epoch - 14ms/step\n",
            "Epoch 5/20\n",
            "7/7 - 0s - loss: 0.3016 - accuracy: 0.9150 - val_loss: 0.2994 - val_accuracy: 0.9168 - 181ms/epoch - 26ms/step\n",
            "Epoch 6/20\n",
            "7/7 - 0s - loss: 0.2668 - accuracy: 0.9450 - val_loss: 0.2712 - val_accuracy: 0.9290 - 95ms/epoch - 14ms/step\n",
            "Epoch 7/20\n",
            "7/7 - 0s - loss: 0.2396 - accuracy: 0.9600 - val_loss: 0.2482 - val_accuracy: 0.9341 - 94ms/epoch - 13ms/step\n",
            "Epoch 8/20\n",
            "7/7 - 0s - loss: 0.2162 - accuracy: 0.9750 - val_loss: 0.2286 - val_accuracy: 0.9483 - 102ms/epoch - 15ms/step\n",
            "Epoch 9/20\n",
            "7/7 - 0s - loss: 0.1973 - accuracy: 0.9850 - val_loss: 0.2116 - val_accuracy: 0.9594 - 96ms/epoch - 14ms/step\n",
            "Epoch 10/20\n",
            "7/7 - 0s - loss: 0.1811 - accuracy: 0.9900 - val_loss: 0.1983 - val_accuracy: 0.9615 - 185ms/epoch - 26ms/step\n",
            "Epoch 11/20\n",
            "7/7 - 0s - loss: 0.1681 - accuracy: 0.9950 - val_loss: 0.1864 - val_accuracy: 0.9604 - 100ms/epoch - 14ms/step\n",
            "Epoch 12/20\n",
            "7/7 - 0s - loss: 0.1564 - accuracy: 0.9950 - val_loss: 0.1761 - val_accuracy: 0.9645 - 103ms/epoch - 15ms/step\n",
            "Epoch 13/20\n",
            "7/7 - 0s - loss: 0.1463 - accuracy: 0.9950 - val_loss: 0.1664 - val_accuracy: 0.9675 - 99ms/epoch - 14ms/step\n",
            "Epoch 14/20\n",
            "7/7 - 0s - loss: 0.1371 - accuracy: 0.9950 - val_loss: 0.1583 - val_accuracy: 0.9675 - 96ms/epoch - 14ms/step\n",
            "Epoch 15/20\n",
            "7/7 - 0s - loss: 0.1293 - accuracy: 0.9950 - val_loss: 0.1503 - val_accuracy: 0.9686 - 97ms/epoch - 14ms/step\n",
            "Epoch 16/20\n",
            "7/7 - 0s - loss: 0.1220 - accuracy: 0.9950 - val_loss: 0.1439 - val_accuracy: 0.9696 - 97ms/epoch - 14ms/step\n",
            "Epoch 17/20\n",
            "7/7 - 0s - loss: 0.1159 - accuracy: 0.9950 - val_loss: 0.1380 - val_accuracy: 0.9706 - 101ms/epoch - 14ms/step\n",
            "Epoch 18/20\n",
            "7/7 - 0s - loss: 0.1103 - accuracy: 0.9950 - val_loss: 0.1324 - val_accuracy: 0.9706 - 101ms/epoch - 14ms/step\n",
            "Epoch 19/20\n",
            "7/7 - 0s - loss: 0.1047 - accuracy: 0.9950 - val_loss: 0.1273 - val_accuracy: 0.9706 - 179ms/epoch - 26ms/step\n",
            "Epoch 20/20\n",
            "7/7 - 0s - loss: 0.0997 - accuracy: 0.9950 - val_loss: 0.1231 - val_accuracy: 0.9726 - 96ms/epoch - 14ms/step\n",
            "----------------------------------------\n",
            "31/31 - 0s - loss: 0.1231 - accuracy: 0.9726 - 79ms/epoch - 3ms/step\n",
            "Model B: [test loss, test accuracy]: [0.12305506318807602, 0.9726166129112244]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def listing3_1_model_B():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "    \n",
        "    # All images of all items except for sandals and shirts (classes 5 and 6).\n",
        "    (X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "    (X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "    (X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "    \n",
        "    # A much smaller training set of just the first 200 images of sandals or shirts.\n",
        "    X_train_B = X_train_B[:200]\n",
        "    y_train_B = y_train_B[:200]\n",
        "\n",
        "\n",
        "    model_B = keras.models.Sequential()\n",
        "    model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "\n",
        "    for n_hidden in (300, 100, 50, 50, 50):\n",
        "        model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
        "\n",
        "    model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model_B.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    print(model_B.summary())\n",
        "    \n",
        "    history = model_B.fit(\n",
        "        X_train_B, \n",
        "        y_train_B, \n",
        "        epochs=20,\n",
        "        validation_data=(X_valid_B, y_valid_B),\n",
        "        verbose=2\n",
        "    )\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model_B.evaluate (\n",
        "        X_valid_B,\n",
        "        y_valid_B,\n",
        "        verbose=2\n",
        "    )\n",
        "    print(\"Model B: [test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    model_B.save(f\"{DATA_ROOT}/my_model_B.h5\")\n",
        "    \n",
        "listing3_1_model_B()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX7G1rMN8Ir9",
        "outputId": "d736200b-106a-4df2-887a-17be3342e8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freeze the reused layers during the first few epochs, \n",
            "giving the new layer some time to learn reasonable weights.\n",
            "\n",
            "----------------------------------------\n",
            "Unfreeze the reused layers (which requires compiling the model again) \n",
            "and continue training to fine-tune the reused layers for task B.\n",
            "\n",
            "After unfreezing the reused layers, it is usually a good idea to reduce \n",
            "the learning rate, once again to avoid damaging the reused weights:\n",
            "----------------------------------------\n",
            "63/63 - 0s - loss: 0.1234 - accuracy: 0.9840 - 254ms/epoch - 4ms/step\n",
            "[model_B: test loss, test accuracy]: 0.12341559678316116 0.984000027179718\n",
            "----------------------------------------\n",
            "63/63 - 0s - loss: 0.0774 - accuracy: 0.9955 - 136ms/epoch - 2ms/step\n",
            "[model_B_on_A: test loss, test accuracy]: 0.07743138819932938 0.9955000281333923\n",
            "----------------------------------------\n",
            "The amount of transfer: error rate dropped by a factor of 3.56%\n"
          ]
        }
      ],
      "source": [
        "def listing3_1_transfer_learning():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "    \n",
        "    # All images of all items except for sandals and shirts (classes 5 and 6).\n",
        "    (X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "    (X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "    (X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "    \n",
        "    # A much smaller training set of just the first 200 images of sandals or shirts.\n",
        "    X_train_B = X_train_B[:200]\n",
        "    y_train_B = y_train_B[:200]\n",
        "        \n",
        "    \n",
        "    model_A = keras.models.load_model(f\"{DATA_ROOT}/my_model_A.h5\")\n",
        "    model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
        "    model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "    \n",
        "    # Note that model_B_on_A and model_A actually share layers now, so when we train one, \n",
        "    # it will update both models. If we want to avoid that, we need to build model_B_on_A \n",
        "    # on top of a clone of model_A:\n",
        "    model_A_clone = keras.models.clone_model(model_A)\n",
        "    model_A_clone.set_weights(model_A.get_weights())\n",
        "    model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
        "    model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "    \n",
        "    \n",
        "    print(\"\"\"Freeze the reused layers during the first few epochs, \n",
        "giving the new layer some time to learn reasonable weights.\n",
        "\"\"\")\n",
        "    \n",
        "    for layer in model_B_on_A.layers[:-1]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model_B_on_A.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    history = model_B_on_A.fit(\n",
        "        X_train_B, \n",
        "        y_train_B, \n",
        "        epochs=4,\n",
        "        validation_data=(X_valid_B, y_valid_B),\n",
        "        verbose=0\n",
        "    )\n",
        "    HR()\n",
        "    \n",
        "    \n",
        "    print(\"\"\"Unfreeze the reused layers (which requires compiling the model again) \n",
        "and continue training to fine-tune the reused layers for task B.\n",
        "\n",
        "After unfreezing the reused layers, it is usually a good idea to reduce \n",
        "the learning rate, once again to avoid damaging the reused weights:\"\"\")\n",
        "\n",
        "    for layer in model_B_on_A.layers[:-1]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model_B_on_A.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    history = model_B_on_A.fit(\n",
        "        X_train_B, \n",
        "        y_train_B, \n",
        "        epochs=16,\n",
        "        validation_data=(X_valid_B, y_valid_B),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    # So, what's the final verdict?\n",
        "    model_B = keras.models.load_model(f\"{DATA_ROOT}/my_model_B.h5\")\n",
        "        \n",
        "    er_B_loss, er_B_accuracy = model_B.evaluate(X_test_B, y_test_B, verbose=2)\n",
        "    print(\"[model_B: test loss, test accuracy]:\", er_B_loss, er_B_accuracy)\n",
        "    HR()\n",
        "    \n",
        "    er_B_on_A_loss, er_B_on_A_accuracy = model_B_on_A.evaluate(X_test_B, y_test_B, verbose=2)\n",
        "    print(\"[model_B_on_A: test loss, test accuracy]:\", er_B_on_A_loss, er_B_on_A_accuracy)\n",
        "    HR()\n",
        "     \n",
        "    # We got quite a bit of transfer: the error rate dropped by a factor of 4.9!\n",
        "    error_rate_change = ((1 - er_B_accuracy) / (1 - er_B_on_A_accuracy))\n",
        "    if error_rate_change > 0:\n",
        "        changed_text = 'dropped'\n",
        "    else:\n",
        "        changed_text = 'increased'\n",
        "        \n",
        "    print(f\"The amount of transfer: error rate {changed_text} by a factor of {error_rate_change:.2f}%\")\n",
        "\n",
        "listing3_1_transfer_learning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmaTzMqC8Ir-"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## 3.2  Unsupervised Pretraining / 教師なし事前学習\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Unsupervised pretraining (today typically using autoencoders or GANs rather than restricted Boltzmann machines or RBMs) is still a good option when you have a complex task to solve, no similar model you can reuse, and little labeled training data but plenty of unlabeled training data.\n",
        "\n",
        "People generally train the full unsupervised model in one shot, and use autoencoders or GANs rather than RBMs.\n",
        "\n",
        "**No source code**\n",
        "\n",
        "Reference:\n",
        "\n",
        "* [Effect of pretraining in MNIST dataset (autoencoder-pretrained model)](https://www.kaggle.com/code/ychunhuang/effect-of-pretraining-in-mnist-dataset/notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmq-p5X58IsA"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## 3.3  Pretraining on an Auxiliary Task / 関連タスクの事前学習\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "If you do not have much labeled training data, one last option is to train a first neural network on an auxiliary task for which you can easily obtain or generate labeled training data, then reuse the lower layers of that network for your actual task. The first neural network’s lower layers will learn feature detectors that will likely be reusable by the second neural network.\n",
        "\n",
        "**No source code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_tV2d7x8IsB"
      },
      "source": [
        "---\n",
        "<a name='4.0'></a>\n",
        "# 4. Faster Optimizers / オプティマイザの高速化\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "1. Apply a good initialization strategy for the connection weights\n",
        "2. Use a good activation function\n",
        "3. Use Batch Normalization\n",
        "4. Reuse parts of a pretrained network (possibly built on an auxiliary task or using unsupervised learning).\n",
        "\n",
        "Here we explore another huge speed boost. This comes from using a faster optimizer than the regular Gradient Descent optimizer. In this section we will present the most popular algorithms for optimizers:\n",
        "\n",
        "1. Momentum optimization\n",
        "2. Nesterov Accelerated Gradient\n",
        "3. AdaGrad\n",
        "4. RMSProp\n",
        "5. Adam\n",
        "6. Nadam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgrzNEiQ8IsB"
      },
      "source": [
        "---\n",
        "\n",
        "**Optimizer Comparison**\n",
        "\n",
        "| Class                            | Convergence speed | Convergence quality |\n",
        "|----------------------------------|-------------------|---------------------|\n",
        "| SGD                              | 1                 | 3                   |\n",
        "| SGD(momentum=...)                | 2                 | 3                   |\n",
        "| SGD(momentum=..., nesterov=True) | 2                 | 3                   |\n",
        "| Adagrad                          | 3                 | 1, stops too early  |\n",
        "| RMSproper                        | 3                 | 2 or 3              |\n",
        "| Adam                             | 3                 | 2 or 3              |\n",
        "| Nadam                            | 3                 | 2 or 3              |\n",
        "| AdaMax                           | 3                 | 2 or 3              |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Sqg8UF8IsC"
      },
      "source": [
        "<a name='4.1'></a>\n",
        "## 4.1 Momentum optimization / モーメンタム最適化\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\n",
        "* https://keras.io/api/optimizers/sgd/\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azecuLXd8IsC",
        "outputId": "4b3324bf-cd95-4729-f36b-6055ee07ee4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'decay': 0.0,\n",
            "    'learning_rate': 0.001,\n",
            "    'momentum': 0.9,\n",
            "    'name': 'SGD',\n",
            "    'nesterov': False}\n"
          ]
        }
      ],
      "source": [
        "def listing4_1():\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "listing4_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLLkfS758IsD"
      },
      "source": [
        "<a id='4.2'></a>\n",
        "## 4.2 Nesterov Accelerated Gradient (NAG)\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtrlUYrX8IsD",
        "outputId": "a6949ad4-d741-4933-ceb6-71e78fefc0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'decay': 0.0,\n",
            "    'learning_rate': 0.001,\n",
            "    'momentum': 0.9,\n",
            "    'name': 'SGD',\n",
            "    'nesterov': True}\n"
          ]
        }
      ],
      "source": [
        "def listing4_2():\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "listing4_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prK1AgFw8IsD"
      },
      "source": [
        "<a id='4.3'></a>\n",
        "## 4.3 AdaGrad\n",
        "\n",
        "**Adaptive learning rate algorithm**\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orB8C61c8IsD",
        "outputId": "e58dec20-6ed7-4d9f-8b92-99fe1640da8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'decay': 0.0,\n",
            "    'epsilon': 1e-07,\n",
            "    'initial_accumulator_value': 0.1,\n",
            "    'learning_rate': 0.001,\n",
            "    'name': 'Adagrad'}\n"
          ]
        }
      ],
      "source": [
        "def listing4_2():\n",
        "    optimizer = keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "    \n",
        "listing4_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEP3-ABE8IsE"
      },
      "source": [
        "<a id='4.4'></a>\n",
        "## 4.4  RMSProp\n",
        "\n",
        "**Adaptive learning rate algorithm**\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At2adjI-8IsE",
        "outputId": "269163a8-7b33-405d-fbff-81878cf873c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'centered': False,\n",
            "    'decay': 0.0,\n",
            "    'epsilon': 1e-07,\n",
            "    'learning_rate': 0.001,\n",
            "    'momentum': 0.0,\n",
            "    'name': 'RMSprop',\n",
            "    'rho': 0.9}\n"
          ]
        }
      ],
      "source": [
        "def listing4_4():\n",
        "    optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "    \n",
        "listing4_4()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKqi2sIu8IsE"
      },
      "source": [
        "<a id='4.5'></a>\n",
        "## 4.5 Adam (adaptive moment estimation) Optimization\n",
        "\n",
        "**Adaptive learning rate algorithm**\n",
        "\n",
        "Combines the ideas of momentum optimization and RMSProp: just like momentum optimization, it keeps track of an exponentially decaying average of past gradients; and just like RMSProp, it keeps track of an exponentially decaying average of past squared gradients.\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxzpgcOC8IsF",
        "outputId": "15497ecc-2efa-4e37-95d4-e87b8b792072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'amsgrad': False,\n",
            "    'beta_1': 0.9,\n",
            "    'beta_2': 0.999,\n",
            "    'decay': 0.0,\n",
            "    'epsilon': 1e-07,\n",
            "    'learning_rate': 0.001,\n",
            "    'name': 'Adam'}\n"
          ]
        }
      ],
      "source": [
        "def listing4_5():\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "    \n",
        "listing4_5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S2RSuM_8IsF"
      },
      "source": [
        "<a id='4.5.1'></a>\n",
        "### 4.5.1 Adamax Optimization\n",
        "\n",
        "**Adaptive learning rate algorithm**\n",
        "\n",
        "AdaMax, introduced in the same paper as Adam, replaces the l2 norm with the l∞ norm (a fancy way of saying the max)\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adamax\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwsjrhxd8IsF",
        "outputId": "4eb48189-4ec9-4439-d0eb-b74406782180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'beta_1': 0.9,\n",
            "    'beta_2': 0.999,\n",
            "    'decay': 0.0,\n",
            "    'epsilon': 1e-07,\n",
            "    'learning_rate': 0.001,\n",
            "    'name': 'Adamax'}\n"
          ]
        }
      ],
      "source": [
        "def listing4_5_1():\n",
        "    optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "    \n",
        "listing4_5_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX9MTIes8IsF"
      },
      "source": [
        "<a id='4.5.2'></a>\n",
        "### 4.5.2 Nadam Optimization\n",
        "\n",
        "**Adaptive learning rate algorithm**\n",
        "\n",
        "Nadam optimization is Adam optimization plus the Nesterov trick, so it will often converge slightly faster than Adam. Nadam generally outperforms Adam but is sometimes outperformed by RMSProp.\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam\n",
        "\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_Gd1_uy8IsF",
        "outputId": "2a335e59-7424-491e-bc30-15a4154fa8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   'beta_1': 0.9,\n",
            "    'beta_2': 0.999,\n",
            "    'decay': 0.004,\n",
            "    'epsilon': 1e-07,\n",
            "    'learning_rate': 0.001,\n",
            "    'name': 'Nadam'}\n"
          ]
        }
      ],
      "source": [
        "def listing4_5_2():\n",
        "    optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    pp.pprint(optimizer.get_config())\n",
        "    \n",
        "listing4_5_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYiiah6x8IsH"
      },
      "source": [
        "<a id='4.6'></a>\n",
        "## 4.6 Learning Rate Scheduling / 学習率のスケジューリング\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4P5-l8A8IsI"
      },
      "source": [
        "<a id='4.6.1'></a>\n",
        "### 4.6.1 Power Scheduling\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icg4WL698IsJ"
      },
      "source": [
        "Set the learning rate to a function of the iteration number\n",
        "\n",
        "```lr = lr0 / (1 + steps / s)**c```\n",
        "* Keras uses `c=1` and `s = 1 / decay`\n",
        "* This schedule first drops quickly, then more and more slowly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "ZMsdUdHU8IsJ",
        "outputId": "c5f8a764-5d8d-4a3a-ce0a-2162930ac368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3235 - accuracy: 0.8882 - 305ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.32349693775177, 0.8881999850273132]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_1():\n",
        "    import math\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=0.0001)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 15 # 25\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "        \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    decay = 0.0001 # 1e-4\n",
        "    batch_size = 32\n",
        "    n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
        "    epochs = np.arange(n_epochs)\n",
        "    lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
        "\n",
        "    plt.plot(epochs, lrs,  \"o-\")\n",
        "    plt.axis([0, n_epochs - 1, 0, 0.01])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Power Scheduling\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "listing4_6_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTs0UBfB8IsK"
      },
      "source": [
        "<a id='4.6.2'></a>\n",
        "### 4.6.2 Exponential Scheduling\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "The learning rate will gradually drop by a factor of 10 every s steps. While power scheduling reduces the learning rate more and more slowly, exponential scheduling keeps slashing it by a factor of 10 every s steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k63dxvB88IsK"
      },
      "source": [
        "<a id='4.6.2.1'></a>\n",
        "#### 4.6.2.1 Exponential Scheduling - Standard\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruk25bUK8IsK"
      },
      "source": [
        "```lr = lr0 * 0.1**(epoch / s)```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "spGcvI618IsK",
        "outputId": "11fa625d-9453-4add-c04f-185e01999e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4602 - accuracy: 0.8822 - 300ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.4602213501930237, 0.8822000026702881]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_2_1():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    def exponential_decay(lr0, s):\n",
        "        def exponential_decay_fn(epoch):\n",
        "            return lr0 * 0.1**(epoch / s)\n",
        "        return exponential_decay_fn\n",
        "\n",
        "    exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15 # 25\n",
        "    \n",
        "    lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,   \n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[lr_scheduler],\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
        "    plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "listing4_6_2_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV9L8NV28IsK"
      },
      "source": [
        "<a id='4.6.2.2'></a>\n",
        "#### 4.6.2.2 Exponential Scheduling - Using current LR\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "The schedule function can take the current learning rate as a second argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "E_wT-DKW8IsK",
        "outputId": "35fa524c-7080-441c-b607-69507be9d87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3009 - accuracy: 0.9000 - 302ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.3008546829223633, 0.8999999761581421]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_2_2():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    def exponential_decay(lr0, s):\n",
        "        # The schedule function can take the current learning rate as a second argument.\n",
        "        def exponential_decay_fn(epoch, lr0):\n",
        "            return lr0 * 0.1**(epoch / s)\n",
        "        return exponential_decay_fn\n",
        "\n",
        "    exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15 # 25\n",
        "    \n",
        "    lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,   \n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[lr_scheduler],\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
        "    plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "listing4_6_2_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFPzbSJU8IsM"
      },
      "source": [
        "<a id='4.6.2.3'></a>\n",
        "#### 4.6.2.3 Exponential Scheduling - Update LR at each iteration\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Bu7tjnjv8IsM",
        "outputId": "f04a5cef-4ba0-4acc-d89d-452693cc9496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s: 25781\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4551 - accuracy: 0.8892 - 309ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.45512855052948, 0.88919997215271]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_2_3():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    K = keras.backend\n",
        "\n",
        "    class ExponentialDecay(keras.callbacks.Callback):\n",
        "        def __init__(self, s=40000):\n",
        "            super().__init__()\n",
        "            self.s = s\n",
        "\n",
        "        def on_batch_begin(self, batch, logs=None):\n",
        "            # Note: the `batch` argument is reset at each epoch\n",
        "            lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "            K.set_value(self.model.optimizer.learning_rate, lr * 0.1**(1 / self.s))\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            logs = logs or {}\n",
        "            logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "            \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    lr0 = 0.01\n",
        "    optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 15 # 25\n",
        "    s = n_epochs * len(X_train) // 32 # number of steps in n_epochs (batch size = 32)\n",
        "    \n",
        "    print(f\"s: {s}\")\n",
        "\n",
        "    exp_decay = ExponentialDecay(s)\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[exp_decay],\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "\n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "        \n",
        "    n_steps = n_epochs * len(X_train) // 32\n",
        "    steps = np.arange(n_steps)\n",
        "    lrs = lr0 * 0.1**(steps / s)\n",
        "\n",
        "    plt.plot(steps, lrs, \"-\", linewidth=2)\n",
        "    plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "listing4_6_2_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVzqrL8k8IsM"
      },
      "source": [
        "<a id='4.6.3'></a>\n",
        "### 4.6.3 Piecewise Constant Scheduling\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Use a constant learning rate for a number of epochs (e.g., η0 = 0.1 for 5 epochs), then a smaller learning rate for another number of epochs (e.g., η1 = 0.001 for 50 epochs), and so on. Although this solution can work very well, it requires fiddling around to figure out the right sequence of learning rates and how long to use each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "RPT8AFIo8IsM",
        "outputId": "db349968-d45f-4cfa-c1e1-0978e8aa00d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.6636 - accuracy: 0.8386 - 305ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.6636028289794922, 0.8385999798774719]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_3():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    def piecewise_constant_fn(epoch):\n",
        "        if epoch < 5:\n",
        "            return 0.01\n",
        "        elif epoch < 15:\n",
        "            return 0.005\n",
        "        else:\n",
        "            return 0.001\n",
        "\n",
        "    def piecewise_constant(boundaries, values):\n",
        "        boundaries = np.array([0] + boundaries)\n",
        "        values = np.array(values)\n",
        "        def piecewise_constant_fn(epoch):\n",
        "            return values[np.argmax(boundaries > epoch) - 1]\n",
        "        return piecewise_constant_fn\n",
        "\n",
        "    piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])\n",
        "\n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15 # 25\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[lr_scheduler],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
        "    plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Learning Rate\")\n",
        "    plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "listing4_6_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS9Fyx3k8IsN"
      },
      "source": [
        "<a id='4.6.4'></a>\n",
        "### 4.6.4 Performance Scheduling\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Measure the validation error every N steps (just like for early stopping), and reduce the learning rate by a factor of λ when the error stops dropping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "l2_Kw9Gt8IsN",
        "outputId": "aba8339c-97de-4972-c17f-108793e1a4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.5216 - accuracy: 0.8966 - 329ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.5216023325920105, 0.8966000080108643]\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_4():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "            \n",
        "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 25\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[lr_scheduler],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Learning Rate\", color='b')\n",
        "    plt.tick_params('y', colors='b')\n",
        "    plt.gca().set_xlim(0, n_epochs - 1)\n",
        "    plt.grid(True)\n",
        "\n",
        "    ax2 = plt.gca().twinx()\n",
        "    ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
        "    ax2.set_ylabel('Validation Loss', color='r')\n",
        "    ax2.tick_params('y', colors='r')\n",
        "\n",
        "    plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "listing4_6_4()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee4uuzT58IsN"
      },
      "source": [
        "<a id='4.6.5'></a>\n",
        "### 4.6.5 tf.keras schedulers\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYx4Tnlw8IsN"
      },
      "source": [
        "<a id='4.6.5.1'></a>\n",
        "#### 4.6.5.1 tf.keras scheduler using ExponentialDecay\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VxP5NEa8IsN",
        "outputId": "d741a6f6-6e5b-4d75-9707-073a3ddf687a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3266 - accuracy: 0.8852 - 303ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.326625257730484, 0.885200023651123]\n",
            "----------------------------------------\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ],
      "source": [
        "def listing4_6_5_1():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "    learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15 # 25\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(history.history.keys())\n",
        "    \n",
        "listing4_6_5_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLQSNxv_8IsP"
      },
      "source": [
        "<a id='4.6.5.2'></a>\n",
        "#### 4.6.5.2 tf.keras scheduler using PiecewiseConstantDecay\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJCMaKaJ8IsP",
        "outputId": "97da747c-7593-4f80-e421-acb692d6552f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3239 - accuracy: 0.8844 - 287ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.32387539744377136, 0.8844000101089478]\n",
            "----------------------------------------\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ],
      "source": [
        "def listing4_6_5_2():\n",
        "    import math\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "    \n",
        "    \n",
        "    # For piecewise constant scheduling\n",
        "    batch_size = 32\n",
        "    n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
        "    learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
        "        values=[0.01, 0.005, 0.001]\n",
        "    )\n",
        "    \n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15 # 25\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    HR()\n",
        "    \n",
        "    print(history.history.keys())\n",
        "    \n",
        "listing4_6_5_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGe5OKOk8IsP"
      },
      "source": [
        "<a id='4.6.6'></a>\n",
        "### 4.6.6 1Cycle scheduling\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "TlJ09Qq88IsQ",
        "outputId": "41205983-12d0-427e-9b6d-97315fe79fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430/430 [==============================] - 2s 4ms/step - loss: nan - accuracy: 0.3862\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3174 - accuracy: 0.8932 - 309ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.31738173961639404, 0.8931999802589417]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3jU5Z338fd3ciCEQDgkEEg4iyABFAHxVEtrBdRWa9XWQ2237Zay7W7ba/u0+7S7T7dee23b3T7tXu2229Y+WntQe7DaopZ6VlpFNCjIGZUziAkgkHAIycz3+WMGTDEJCZl7fpOZz+u65jKT34+Z753AfLzv3/27b3N3REQkf8WiLkBERKKlIBARyXMKAhGRPKcgEBHJcwoCEZE8pyAQEclzhVEX0F0VFRU+ZsyYqMuQHPPmoWPs2H+EM4aW0beoIOpy5CSHj8V5raGJMUP60b+k131sZYXly5fvcffK9o71up/omDFjqKuri7oMyTENjc2c9/XH+OSlE/j8e86Muhw5yfKt+7j2h0u57ePn8c4z2/0sk1Mws60dHdPQkAhQ2b8P544axKNr34i6FOmERV1AjlIQiKRcNnkYa3YdZOf+I1GXIifRAghhKQhEUi6bPAyAx9QryDrHc8DUJQhCQSCSMr6yjHGV/TQ8lMVMg0NBKAhE2phXW8XSTXvZd+hY1KVIGxoaCktBINLGlVOHE084f1q9O+pSpB0aGgojWBCY2Ugze9LM1prZGjP7XDvnTDKzpWbWbGb/K1QtIl1VO2IAYyv68eDLu6IuRdrQcvlhhewRtAJfcPfJwPnAZ8xs8knn7AM+C/zfgHWIdJmZ8d5pw3lu014aGpujLkdSTlwsjrSK3BUsCNz9dXd/MfV1I7AOqD7pnHp3fwFoCVWHSHe9d9oIEg6LV78edSlyMiVBEBm5RmBmY4DpwLJMvJ9IT0ys6s/4yn48vEbXCbKFRobCCh4EZlYG/A74vLsfPM3XWGBmdWZW19DQkN4CRdoxt7aK5zbtY/9hzR7KJpo+GkbQIDCzIpIhcJe733e6r+Put7n7THefWVmpdUYkvHm1VcQTzuPr6qMuRQBHXYKQQs4aMuB2YJ27fyfU+4iEMK26nKoBJRoeyhapHND00TBCrj56EXALsMrMVqS+9xVgFIC7/8jMqoA6YACQMLPPA5NPdwhJJF1iMWNu7TB+U7edI8fi9C3W0tTZQDkQRrAgcPe/cIrfm7vvBmpC1SDSE/Nqq/j50q08vbGB+VOqoi4nr2lgKCzdWSzSgfPGDqa8bxGPrNXwULYwjQ0FoSAQ6UBRQYxLzxrK4+vqaYknoi4nr2n6aFgKApFOzKut4sCRFp7fvC/qUvLa8VlD6hCEoSAQ6cQlEyopKYpp9lCWUA6EoSAQ6UTf4gIumVDJI2veIJHQ+ERUNDQUloJA5BTm1Vax++BRXt55IOpS8pZ2KAtLQSByCpeeNZSCmPGIhoeygJIgBAWByCkMLC3m/HGDdZ0gQtqPICwFgUgXzKut4rWGQ7xa3xR1KXlNQ0NhKAhEuuCyycMA1CuIiPoDYSkIRLpgeHlfzq4p13WCqBxfdC7aKnKWgkCki+bWVrFyxwFeP3Ak6lLylpaYCENBINJF82qTC889uvaNiCvJP9qPICwFgUgXnTG0TFtYRkz9gTAUBCLdME9bWEZCs0fDUhCIdIO2sIyGa4eyoBQEIt0wraacEeUlLF6t4aEoaPP6MBQEIt1gZsyfMpwlrzTQeLQl6nLyhkaGwlIQiHTTldOqONaa0PBQBDQ0FIaCQKSbpo8cRNWAEh5a9XrUpeQNrTUUloJApJtiMePyqVU8vbGBpubWqMvJC4qBsBQEIqfhiqnDU8NDurkskzQ0FIaCQOQ0zBg1iGED+vBHDQ9lhEaGwlIQiJyGWMy4fMpwntrQwCEND2WMpo+GoSAQOU2XT6miuTXBE+s1eyg8dQlCUhCInKaZYwZT2V/DQ5mgO4vDUhCInKaCmHH5lCqe3FDP4WMaHsoEBUEYCgKRHrhi6nCOtmh4KDQNDIWlIBDpgVljBlNR1ofFq7T2UEgnhoZ0sTgIBYFIDxTEjPlThvHE+nqOHItHXU7O09BQGAoCkR66YupwjrTEeXKDhodC0Q5lYSkIRHpo9tghDOlXrLWHMkAdgjCCBYGZjTSzJ81srZmtMbPPtXOOmdn3zOxVM3vZzM4NVY9IKAUxY96UKp7U8FAwurM4rJA9glbgC+4+GTgf+IyZTT7pnMuBCanHAuCHAesRCebKqcM5fCzO0xs1PBTC8RzQNYIwggWBu7/u7i+mvm4E1gHVJ512NfBzT3oOGGhmw0PVJBLK7LGDGdyvmIc0eygwJUEIGblGYGZjgOnAspMOVQPb2zzfwdvDQiTrFRbEmFc7jMfXvcHRFg0PpZv2IwgreBCYWRnwO+Dz7n7wNF9jgZnVmVldQ0NDegsUSZMrTgwP6e9oKBoaCiNoEJhZEckQuMvd72vnlJ3AyDbPa1Lf+yvufpu7z3T3mZWVlWGKFemhC8YNYVBpkdYekl4n5KwhA24H1rn7dzo4bRHwkdTsofOBA+6uf0XSKyWHh6p4fF29hofS7K07iyWEkD2Ci4BbgHeb2YrU4wozW2hmC1Pn/BHYBLwK/AT4dMB6RIK7fOpwmppbWaLhobRKpJIgprGhIApDvbC7/4VTBLgnrwB9JlQNIpl24fghDCwtYvHq3cytrYq6nJwRTySDoCCmIAhBdxaLpFFRQYy5k4fx2No3aG7V8FC6KAjCUhCIpNnlU4fT2NzKnzfuibqUnBF3BUFICgKRNLtofAUDSgo1eyiNEuoRBKUgEEmz4sIYc2ureHSdhofSpfV4EOhicRAKApEArpw6nMajrTzzqoaH0uH4NYKYegRBKAhEArjojAr6lxTy4MsaHkqHhK4RBKUgEAmguDDGFVOG8/Dq3VqaOg3iieR/CxUEQSgIRAJ5//RqDh2L88harUjaU/FEMgl0Q1kYCgKRQGaPHcyI8hJ+/9Lbls+SbjreI9DQUBgKApFAYjHj6unVLHllD3uamqMup1eLn1hiIuJCcpSCQCSga6ZXE084D67cFXUpvVoi4RTEDNPQUBAKApGAzhzWn8nDB3D/CgVBT7QmXPcQBKQgEAnsA+dWs3L7fl5raIq6lF4r4U5Mn1bB6EcrEtj7zh5BzOAPumh82uLqEQSlIBAJbNiAEi4cX8Gilbu09+5piqeuEUgYCgKRDLh8ahVb9h5m4xsaHjodCoKwFAQiGXDZ5GGYwZ9W6+ay0xF3BUFICgKRDBjav4SZowexeLXWHjodiYTrruKAFAQiGTKvtor1uxvZsudQ1KX0Oq0J1zpDASkIRDJk/pTkHsYP6OaybkskXEtQB6QgEMmQmkGlzB47mPte2qnZQ92kawRhKQhEMujaGTVs3nOIF7ftj7qUXkWzhsJSEIhk0BVTh1NSFON3L+6IupReRTeUhaUgEMmgsj6FzK+t4oGVuzjaog1ruko9grAUBCIZdt2MkTQebeWxdW9EXUqvkXBNHw1JQSCSYReMH8Lw8hLuXa7hoa6KJ5zCAgVBKAoCkQwriBnXTK9mycYG6g8ejbqcXqFVN5QFpSAQicC1M2pIONyvFUm7JKHpo0EpCEQiML6yjOmjBvK7F3fonoIu0KyhsBQEIhG5bkYNG99oYvXOg1GXkvUSCW1cH5KCQCQi7502guLCGPcu3x51KVmvNZFQEASkIBCJSHnfIuZOHsYfVu6iuVX3FHQm7mitoYCCBYGZ3WFm9Wa2uoPjg8zsfjN72cyeN7MpoWoRyVbXzahh/+EWnlxfH3UpWS2RcDR7NJyQPYI7gfmdHP8KsMLdpwEfAb4bsBaRrPSOCZUM7d9H9xScQmvCKdDu9cEE+8m6+xJgXyenTAaeSJ27HhhjZsNC1SOSjQpixjXnVvPkhgYaGpujLidrJRJOgXIgmCh/tCuBDwCY2XnAaKCmvRPNbIGZ1ZlZXUNDQwZLFAnvunNriCecP6zQPQUd0TLUYUUZBN8EBprZCuAfgJeAdq+Yuftt7j7T3WdWVlZmskaR4CYM68/ZNeUaHuqEtqoMK7IgcPeD7v4xdz+H5DWCSmBTVPWIROm6GTWs393Iml0Hoi4lK2mryrAiCwIzG2hmxamnfwsscXfdWSN56X1nj6C4IKZeQQfi2qoyqJDTR+8BlgITzWyHmX3CzBaa2cLUKWcBq81sA3A58LlQtYhku4Glxbxn8lD+sGIXx1oTUZeTdRKuJSZCKgz1wu5+4ymOLwXODPX+Ir3NdTNq+OOq3Ty1oZ65tVVRl5NVtAx1WJqQJZIlLplQSUVZH21j2Y64LhYH1aUgMLN+ZhZLfX2mmV1lZkVhSxPJL4UFMa6ZPoLH19Wzt0n3FLSl6aNhdbVHsAQoMbNq4BHgFpJ3DotIGl07o4bWhLNo5a6oS8kq6hGE1dUgMHc/TPIGsP9x9+uB2nBlieSnSVUDmFI9QMNDJ0lo+mhQXQ4CM7sAuBl4KPW9gjAlieS3a8+tYfXOg6zfrdnUxyXXGlIQhNLVIPg88GXgfndfY2bjgCfDlSWSv64+p5qiAuN3uqfghITrPoKQuhQE7v60u1/l7v+Rumi8x90/G7g2kbw0uF8x7540lPtf2kVLXPcUgLaqDK2rs4buNrMBZtYPWA2sNbMvhi1NJH9de24Ne5qaWbJRiyy6OwnXVpUhdXVoaHJq+Yf3A4uBsSRnDolIAO+aNJQh/Yp10ZhkbwAUBCF1NQiKUvcNvB9Y5O4tgIcrSyS/FRXEuPqcah5bW8++Q8eiLidScVcQhNbVIPgxsAXoBywxs9GApjSIBPShWSM5Fk/k/eb2idRlEt1HEE5XLxZ/z92r3f0KT9oKvCtwbSJ5bWJVf2aNGcQ9z28nkcjfDnhrKgl0H0E4Xb1YXG5m3zm+S5iZfZtk70BEArpp9ig27znE0k17oy4lMid6BAqCYLo6NHQH0Ah8MPU4CPw0VFEiknT5lOEMLC3irmVboy4lMieuESgHgunqMtTj3f3aNs9vTW0xKSIBlRQVcN25Ndz57BbqG48ytH9J1CVlnGYNhdfVHsERM7v4+BMzuwg4EqYkEWnrxtmjaE04v63Lz6mkbwWBVs0Ppas/2YXAD8xsi5ltAb4PfCpYVSJywvjKMi4cP4S7l2078aGYT96aPhpxITmsq7OGVrr72cA0YJq7TwfeHbQyETnhptmj2Ln/CE9vrI+6lIw7PmNK00fD6VbGuvvBNhvM/2OAekSkHXMnV1HZvw+/fG5b1KVk3PFekLaqDKcnnS39VkQypLgwxo2zRvLkhnq27zscdTkZ1aoeQXA9CYL8G6wUidAN543CgLuW5VevIKElJoLrNAjMrNHMDrbzaARGZKhGEQFGDOzLe84axm/qttPcGo+6nIw5MWtIPYJgOg0Cd+/v7gPaefR3967egyAiaXLLBaPZd+gYi1ftjrqUjNF9BOFpQpZIL3LR+ApGDynlVy/kz/CQgiA8BYFILxKLGdfPqOG5TfvYuvdQ1OVkxPH7CLTWUDgKApFe5roZI4kZ/KYuP5anTugaQXAKApFepqq8hHeeWcm9y3fQmgd7Gh+fPqplqMNREIj0QjecN4o3Djbz2Lrcv9P4xJ3FCoJgFAQivdClk4ZSPbAvP3t2S9SlBKetKsNTEIj0QoUFMT58/miWbtrLht2NUZcTVFx3FgenIBDppW6YNZI+hTF+tnRL1KUEFdc1guAUBCK91KB+xVx19gh+/9JODh5tibqcYHQfQXjBgsDM7jCzejNb3cHxcjN7wMxWmtkaM/tYqFpEctUtF4zm8LE49y3P3U1rjq81pKGhcEL2CO4E5ndy/DPA2tQ+B3OAb5tZccB6RHLOtJqBnD1yIL94bivuubkO5PEZslqGOpxgQeDuS4B9nZ0C9DczA8pS57aGqkckV33k/NG81nCIpa/tjbqUIFoTySRQjyCcKK8RfB84C9gFrAI+5+7t3h1jZgvMrM7M6hoaGjJZo0jWu3LacAaVFvHzpVujLiUILUMdXpRBMA9YQXI563OA75vZgPZOdPfb3H2mu8+srKzMZI0iWa+kqIAPzhrJo+ve4PUDR6IuJ+2ODw1piYlwogyCjwH3edKrwGZgUoT1iPRaH549moQ7d+fgpjUn1hrSNYJgogyCbcClAGY2DJgIbIqwHpFea+TgUt49cSh3L9vG0Zbc2rSmVYvOBRdy+ug9wFJgopntMLNPmNlCM1uYOuXfgAvNbBXwOPBP7r4nVD0iue7jF49l76FjLFqxK+pS0uqtZagjLiSHBdtlzN1vPMXxXcDcUO8vkm8uHD+ESVX9ueOZzVw/swbLkf+D1jLU4SljRXKEmfHxi8eyfncjf34ldzrXby1DrY+rUPSTFckhV58zgqoBJXz/yVejLiVt3lqGOuJCcph+tCI5pE9hAQsuGcfzm/exYvv+qMtJCy1DHZ6CQCTHXD+zhtLiAn75XG7cYKZlqMNTEIjkmP4lRVwzvZoHVu7izUPHoi6nx7QMdXgKApEcdMsFo2luTXBvDqxKqmWow1MQiOSgSVUDOG/MYH65bOuJi629VcIdM3JmOmw2UhCI5KgPXzCarXsPs+SV3r1QYzzhuocgMAWBSI6aX1tFRVlxr79oHE+4hoUCUxCI5Kjiwhg3zBrF4+vr2b7vcNTlnDYFQXgKApEcdvP5oygw4/a/bI66lNMWdw0NhaYgEMlhw8v7cvU51fz6he29dippIuFagjowBYFIjltwyTiOtMR77bWCVl0sDk5BIJLjJlb1510TK7nz2S29cq+ChDsxXSMISkEgkgc+9c7x7D10rFfeYKbpo+EpCETywOyxgzl75EB+8udNJ+7U7S1aNWsoOAWBSB4wMz51yTi27j3MI2t2R11OtyQUBMEpCETyxLzaKkYPKeVHT7+Ge+/pFcRd6wyFpiAQyRMFMeOT7xjHyh0HWLZ5X9TldFki4SgHwlIQiOSR62bUMKRfMbct2RR1KV3Wmkhom8rA9NMVySMlRQV89MIxPLG+ng27G6Mup0viCTR9NDAFgUieueX80fQtKug1vYKEOwX6pApKP16RPDOoXzEfmjWSP6zYyesHjkRdzinpPoLwFAQieegTF4/FgZ8+syXqUk5Jq4+GpyAQyUMjB5dy5dTh3L1sGweOtERdTqcUBOEpCETy1IJLxtHU3Mrdy7ZFXUqn4u7ENDQUlIJAJE9NqS7nHRMq+OkzmznWmoi6nA7pzuLwFAQieeyT7xhHfWMzD63aFXUpHdJaQ+EpCETy2DsmVHDG0DJu/8vmrF12Ijl9VEEQkoJAJI+ZGR+7aAyrdx6kbuubUZfTLk0fDU9BIJLnPjC9hvK+RdyRpfsaa9ZQeAoCkTzXt7iAm2aP4uE1u9m+73DU5byNgiC8YEFgZneYWb2Zre7g+BfNbEXqsdrM4mY2OFQ9ItKxj1wwmsJYjP96bGPUpbxNXFtVBheyR3AnML+jg+7+LXc/x93PAb4MPO3uvWdtXJEcMry8Lx+/eCz3vbiTl3fsj7qcv5LQNYLgggWBuy8BuvrBfiNwT6haROTUPvOu8VSUFfNvD67NqhlErQmnUD2CoCK/RmBmpSR7Dr/r5JwFZlZnZnUNDQ2ZK04kj/QvKeIfL5vIC1veZPHq7NnOMpHQ0FBokQcB8D7gmc6Ghdz9Nnef6e4zKysrM1iaSH750KyRTKrqzzcWr+NoSzzqcoDkNQINDYWVDUFwAxoWEskKBTHjX66czPZ9R7g9S6aTamOa8CINAjMrB94J/CHKOkTkLRdPqODyKVV89/FX2LznUNTl0NwSp09hNvw/a+4KOX30HmApMNHMdpjZJ8xsoZktbHPaNcAj7h793zYROeHWq2rpUxjjn+9fFemF46MtcRqbW6koK46shnxQGOqF3f3GLpxzJ8lppiKSRYYOKOFL8yfxf36/msfW1XPZ5GGR1LGnqRmAyv59Inn/fKH+loi068ZZIxlX0Y9vPbyeeCKaXkFDYzIIKsoUBCEpCESkXYUFMb4wdyIb32ji9y/tjKSGPU3HAPUIQlMQiEiHLp9SxdTqcr7z6EaaWzM/nfT40JB6BGEpCESkQ7GY8aX5E9m5/wjffiTz6xAdHxoaoovFQSkIRKRT75hQyS3nj+a2JZv4bd32jL73nqZmyvsW0aewIKPvm28UBCJySl9932QuPqOCr9y/iuc27c3Y++5patbU0QxQEIjIKRUVxPjBTecycnApH7njeR5b+0ZG3vfAkRYGlioIQlMQiEiXlJcWce/CCzlzWBlf+O1KXj9wJPh7NjXHKesT7HYnSVEQiEiXDe5XzH/feC4t8QRf+M1KWuOJoO/XdLRFQZABCgIR6ZaxFf342lW1PPvaXr66aE3Q92pqblUQZICCQES67YMzR/Kpd47j7mXbePDlXcHep+loK2UlCoLQFAQiclq+cNlEptWU8/d3v8Q3Fq8jkeZlKBIJ59AxXSPIBAWBiJyW4sIYv15wATeeN5IfP72Jnz67Ja2vf+hYK4CCIAMUBCJy2voWF/D1a6Zy6aShfOvh9ezcn76ZRE3NqSDQ0FBwCgIR6REz49ara3GH/1i8Pm2v23RUPYJMURCISI/VDCplwSXjWLRyF8u3drj9eLec6BEoCIJTEIhIWix853iGDejDrQ+sTcuFYw0NZY6CQETSol+fQr40bxIv7zjAPS9s6/HraWgocxQEIpI210yv5sLxQ/j6Q+vYvu9wj15LQ0OZoyAQkbSJxYz/uHYaAF/p4cb3CoLMURCISFqNHFzKl+ZP4s+v7OGRHqxSevCIrhFkioJARNLu5tmjOHNYGf/+0DqOtpzeFpcNTUcZVFpEUYE+pkLTT1hE0q6wIMZX31vLtn2H+dK9L3OstfurlDY0NmvT+gxREIhIEBdPqOBL8yeyaOUu/vbndRxOLRnRVfWNzQztXxKoOmlLQSAiwXx6zhl88wNT+csrDXzqF8u7dfFYPYLMURCISFA3nDeKW6+q5c+v7OGXy7p2f4G7KwgySEEgIsHdPHs0l5xZydcWreHRLswkOni0lebWBEMVBBmhIBCR4GIx44c3n8uU6nI+fddyvrF4HS2dbHPZ0NgMoB5BhigIRCQj+vUp5Gcfm8X7z6nmx09v4uafLGNPU3O75+5KLWetIMgMBYGIZMzA0mK+df3ZfPeGc3h5535u/skyDhxpedt5L23bjxnUjiiPoMr8oyAQkYy7+pxqbv/oLF5taOJri9a87fgLW/YxqWoA5X2LIqgu/wQLAjO7w8zqzWx1J+fMMbMVZrbGzJ4OVYuIZJ+LzqjgM3PGc/9LO6nb8tYeBq3xBC9ue5NZYwZFWF1+CdkjuBOY39FBMxsI/A9wlbvXAtcHrEVEstDCOeOpKOvDfz684cQ9Bmt2HeTwsTizxgyOuLr8ESwI3H0J0NlWRTcB97n7ttT59aFqEZHsVFpcyGcvPYPnN+/jqQ0NQHJYCOC8sQqCTInyGsGZwCAze8rMlpvZRyKsRUQicsOsUYyt6MdX7l9FfeNRntu0l1GDSxk2QMtLZEqU67sWAjOAS4G+wFIze87dN558opktABYA9OnThzlz5mSyThEJrLl0KLtrb+K8f3sYYoUM2PU8c+bcGnVZecN6snHEKV/cbAzwoLtPaefY/wb6uvu/pp7fDvzJ3X97itdsBDb0sLRy4EAPz2vv2Km+d/Lx9o5VAHu6UFtn1L5Tn5fO9rX9fq60r6Ove1P7uvL38eSvc7l9o929st13c/dgD2AMsLqDY2cBj5PsGZQCq4EpXXjNujTUdVtPz2vv2Km+d/Lx9o6pfb2vfSedkxPt6+TrXtO+rvx9zLf2dfQINjRkZvcAc4AKM9sB/CtQBODuP3L3dWb2J+BlIAH8P3fvcKppmj2QhvPaO3aq7518vLNjPaH2nfq8dLYvnW3rzuuFbF+o3113Xq+n7evq38e8b1/QoaEQzKzO3WdGXUcoal/vpvb1brnevo70xjuLb4u6gMDUvt5N7evdcr197ep1PQIREUmv3tgjEBGRNFIQiIjkOQWBiEiey6kgSK1m+mcz+5GZzYm6nhDMrJ+Z1ZnZe6OuJd3M7KzU7+5eM/u7qOtJNzN7v5n9xMx+bWZzo64n3cxsnJndbmb3Rl1LOqT+rf0s9Tu7Oep6QsqaIOho2Wozm29mG8zs1dTdyJ1xoAkoAXaEqvV0pKl9AP8E/CZMlacvHe1z93XuvhD4IHBRyHq7K03t+727fxJYCHwoZL3dlab2bXL3T4SttGe62c4PAPemfmdXZbzYDMqaWUNmdgnJD/Gfe2pJCjMrADYCl5H8YH8BuBEoAL5x0kt8HNjj7gkzGwZ8x92zJsXT1L6zgSEkg26Puz+YmepPLR3tc/d6M7sK+DvgF+5+d6bqP5V0tS/1574N3OXuL2ao/FNKc/vudffrMlV7d3SznVcDi919hZnd7e43RVR2cFEuOvdX3H1Jam2its4DXnX3TQBm9ivganf/BtDZ0MibQFZtdpqO9qWGu/oBk4EjZvZHd+94B/AMStfvz90XAYvM7CEga4IgTb8/A75J8sMla0IA0v7vL2t1p50kQ6EGWEEWjZ6EkDVB0IFqYHub5zuA2R2dbGYfAOYBA4Hvhy0tLbrVPnf/ZwAz+xtSvZ+g1fVcd39/c0h2x/sAfwxaWXp0q33APwDvAcrN7Ax3/1HI4tKgu7+/IcC/A9PN7MupwOgNOmrn94Dvm9mVpH8ZiqyS7UHQLe5+H3Bf1HWE5u53Rl1DCO7+FPBUxGUE4+7fI/nhkpPcfS/J6x85wd0PAR+Luo5MyPbuzk5gZJvnNanv5Qq1r3dT+3JDvrSzQ9keBC8AE8xsrJkVAzcAiyKuKZ3Uvt5N7csN+dLODmVNEFhy2eqlwEQz22Fmn3D3VuDvgYeBdcBv3H1NlHWeLrVP7ctmud6+4/Klnd2VNdNHRUQkGlnTIxARkWgoCERE8pyCQEQkzykIRETynIJARCTPKQhERPKcgkByhpk1Zfj9ns3w+w00s09n8j0lPygIRDpgZp2uxeXuF2b4PQcCCgJJOwWB5DQzG29mfzKz5ZbcvW5S6vvvM7NlZvaSmT2W2sMCM/Dd5y0AAAKPSURBVPuamf3CzJ4BfpF6foeZPWVmm8zss21euyn13zmp4/ea2Xozuyu15DRmdkXqe8vN7Htm9rY9JMzsb8xskZk9ATxuZmVm9riZvWhmq8zs6tSp3wTGm9kKM/tW6s9+0cxeMLOXzezWkD9LyWHuroceOfEAmtr53uPAhNTXs4EnUl8P4q076/8W+Hbq668By4G+bZ4/S3Jp7ApgL1DU9v2AOcABkouVxUguYXAxyQ2EtgNjU+fdAzzYTo1/Q3Lp48Gp54XAgNTXFcCrgAFjgNVt/txc4LbUsRjwIHBJ1L8HPXrfI6eWoRZpy8zKgAuB36b+Bx3e2rCoBvi1mQ0HioHNbf7oInc/0ub5Q+7eDDSbWT0wjLdvhfq8u+9Ive8Kkh/aTcAmdz/+2vcACzoo91F333e8dODrqd20EiTXyx/Wzp+Zm3q8lHpeBkwAlnTwHiLtUhBILosB+939nHaO/TfJ7UwXpTbE+VqbY4dOOre5zddx2v9305VzOtP2PW8GKoEZ7t5iZltI9i5OZsA33P3H3Xwvkb+iawSSs9z9ILDZzK6H5FaRZnZ26nA5b605/9FAJWwAxrXZGrGrG9aXA/WpEHgXMDr1/Uagf5vzHgY+nur5YGbVZja0x1VL3lGPQHJJqZm1HbL5Dsn/u/6hmf0LUAT8ClhJsgfwWzN7E3gCGJvuYtz9SGq655/M7BDJde+74i7gATNbBdQB61Ovt9fMnjGz1ST3Pf6imZ0FLE0NfTUBHwbq090WyW1ahlokIDMrc/em1CyiHwCvuPt/RV2XSFsaGhIJ65Opi8drSA75aDxfso56BCIieU49AhGRPKcgEBHJcwoCEZE8pyAQEclzCgIRkTynIBARyXP/H3pf26wQAyegAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def listing4_6_6_1():\n",
        "    import math\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "    \n",
        "    K = keras.backend\n",
        "\n",
        "    class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "        def __init__(self, factor):\n",
        "            self.factor = factor\n",
        "            self.rates = []\n",
        "            self.losses = []\n",
        "        def on_batch_end(self, batch, logs):\n",
        "            self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "            self.losses.append(logs[\"loss\"])\n",
        "            K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
        "\n",
        "    def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
        "        init_weights = model.get_weights()\n",
        "        iterations = math.ceil(len(X) / batch_size) * epochs\n",
        "        factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
        "        init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "        K.set_value(model.optimizer.learning_rate, min_rate)\n",
        "        exp_lr = ExponentialLearningRate(factor)\n",
        "        history = model.fit(\n",
        "            X, \n",
        "            y, \n",
        "            epochs=epochs, \n",
        "            batch_size=batch_size,\n",
        "            callbacks=[exp_lr]\n",
        "        )\n",
        "        K.set_value(model.optimizer.learning_rate, init_lr)\n",
        "        model.set_weights(init_weights)\n",
        "        return exp_lr.rates, exp_lr.losses\n",
        "\n",
        "    def plot_lr_vs_loss(rates, losses):\n",
        "        plt.plot(rates, losses)\n",
        "        plt.gca().set_xscale('log')\n",
        "        plt.hlines(min(losses), min(rates), max(rates))\n",
        "        plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
        "        plt.xlabel(\"Learning rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    batch_size = 128\n",
        "    rates, losses = find_learning_rate(\n",
        "        model, \n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=1, \n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    plot_lr_vs_loss(rates, losses)\n",
        "    \n",
        "    class OneCycleScheduler(keras.callbacks.Callback):\n",
        "        def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                     last_iterations=None, last_rate=None):\n",
        "            self.iterations = iterations\n",
        "            self.max_rate = max_rate\n",
        "            self.start_rate = start_rate or max_rate / 10\n",
        "            self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "            self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "            self.last_rate = last_rate or self.start_rate / 1000\n",
        "            self.iteration = 0\n",
        "        def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "            return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                    / (iter2 - iter1) + rate1)\n",
        "        def on_batch_begin(self, batch, logs):\n",
        "            if self.iteration < self.half_iteration:\n",
        "                rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "            elif self.iteration < 2 * self.half_iteration:\n",
        "                rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                         self.max_rate, self.start_rate)\n",
        "            else:\n",
        "                rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                         self.start_rate, self.last_rate)\n",
        "            self.iteration += 1\n",
        "            K.set_value(self.model.optimizer.learning_rate, rate)\n",
        "    \n",
        "    n_epochs = 25\n",
        "    onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs, \n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        callbacks=[onecycle],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "\n",
        "listing4_6_6_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnvSaPUA8IsR"
      },
      "source": [
        "---\n",
        "<a name='5.0'></a>\n",
        "# 5. Avoiding Overfitting Through Regularization / 正則化による過学習の防止\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "We already implemented one of the best regularization techniques in Chapter 10: early stopping. Moreover, even though Batch Normalization was designed to solve the unstable gradients problems, it also acts like a pretty good regularizer. In this section we will examine other popular regularization techniques for neural networks: l1 and l2 regularization, dropout, and max-norm regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbMCCu8Y8IsS"
      },
      "source": [
        "<a name='5.1'></a>\n",
        "## 5.1 $\\ell_1$ and $\\ell_2$ regularization / ℓ1、ℓ2 正則化\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsAIqlXv8IsT",
        "outputId": "ea9bf461-c956-471e-8379-c74af5db1ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.6615 - accuracy: 0.8480 - 314ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.6614769101142883, 0.8479999899864197]\n"
          ]
        }
      ],
      "source": [
        "def listing5_1():\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(\n",
        "            300, activation=\"elu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=keras.regularizers.l2(0.01)\n",
        "            # or l1(0.1) for ℓ1 regularization with a factor of 0.1\n",
        "            # or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, \n",
        "            #    with factors 0.1 and 0.01 respectively\n",
        "        ),\n",
        "        keras.layers.Dense(\n",
        "            100, activation=\"elu\",\n",
        "            kernel_initializer=\"he_normal\",\n",
        "            kernel_regularizer=keras.regularizers.l2(0.01)\n",
        "        ),\n",
        "        keras.layers.Dense(\n",
        "            10, activation=\"softmax\",\n",
        "            kernel_regularizer=keras.regularizers.l2(0.01)\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 15\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)    \n",
        "    \n",
        "listing5_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcAZHqBA8IsU"
      },
      "source": [
        "<a name='5.1.1'></a>\n",
        "### 5.1.1 $\\ell_1$ and $\\ell_2$ regularization using functools.partial()\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0nPos3q8IsU",
        "outputId": "5e416a90-112f-476d-acb9-4a6369864a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.6828 - accuracy: 0.8382 - 316ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.6828034520149231, 0.8381999731063843]\n"
          ]
        }
      ],
      "source": [
        "def listing5_1_1():\n",
        "    from functools import partial\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    RegularizedDense = partial(\n",
        "        keras.layers.Dense,\n",
        "        activation=\"elu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        kernel_regularizer=keras.regularizers.l2(0.01)\n",
        "    )\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        RegularizedDense(300),\n",
        "        RegularizedDense(100),\n",
        "        RegularizedDense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 2\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)    \n",
        "    \n",
        "listing5_1_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbc98mLm8IsU"
      },
      "source": [
        "<a id='5.2'></a>\n",
        "## 5.2 Dropout / ドロップアウト\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Neurons trained with dropout cannot co-adapt with their neighboring neurons; they have to be as useful as possible on their own. They also cannot rely excessively on just a few input neurons; they must pay attention to each of their input neurons. They end up being less sensitive to slight changes in the inputs. In the end, you get a more robust network that generalizes better.\n",
        "\n",
        "Many state-of-the-art architectures only use dropout after the last hidden layer.\n",
        "\n",
        "Dropout rate guideline:\n",
        "\n",
        "* 10-20% for normal networks\n",
        "* 20–30% in recurrent neural nets\n",
        "* 40–50% in convolutional neural networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipcWdufP8IsV",
        "outputId": "7af220e3-80bd-4a77-8542-11f537049bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3026 - accuracy: 0.8942 - 299ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.30263271927833557, 0.8942000269889832]\n"
          ]
        }
      ],
      "source": [
        "def listing5_2():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    n_epochs = 25\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    print(\"[test loss, test accuracy]:\", eval_result)   \n",
        "\n",
        "listing5_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpzmwROu8IsV"
      },
      "source": [
        "<a id='5.3'></a>\n",
        "## 5.3 Alpha Dropout\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "If you want to regularize a self-normalizing network based on the SELU activation function (as discussed earlier), you should use alpha dropout: this is a variant of dropout that preserves the mean and standard deviation of its inputs (it was introduced in the same paper as SELU, as regular dropout would break self-normalization)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFPu9aNO8IsV",
        "outputId": "3c556b25-c4f2-415f-f013-94e436d14e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_23 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " alpha_dropout (AlphaDropout  (None, 784)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_278 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " alpha_dropout_1 (AlphaDropo  (None, 300)              0         \n",
            " ut)                                                             \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " alpha_dropout_2 (AlphaDropo  (None, 100)              0         \n",
            " ut)                                                             \n",
            "                                                                 \n",
            " dense_280 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "----------------------------------------\n",
            "313/313 - 1s - loss: 0.4677 - accuracy: 0.8629 - 598ms/epoch - 2ms/step\n",
            "Run 1: [test loss, test accuracy]: [0.4676779806613922, 0.8629000186920166]\n",
            "----------------------------------------\n",
            "1719/1719 - 4s - loss: 0.3434 - accuracy: 0.8833 - 4s/epoch - 2ms/step\n",
            "Run 2: [test loss, test accuracy]: [0.3433915376663208, 0.8833272457122803]\n"
          ]
        }
      ],
      "source": [
        "def listing5_3():\n",
        "\n",
        "    tf.random.set_seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        learning_rate=0.01, \n",
        "        momentum=0.9, \n",
        "        nesterov=True\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    n_epochs = 20\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "    print(\"Run 1: [test loss, test accuracy]:\", eval_result)   \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate(X_train_scaled, y_train, verbose=2)\n",
        "    print(\"Run 2: [test loss, test accuracy]:\", eval_result) \n",
        "    \n",
        "listing5_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvBlyyPz8IsV"
      },
      "source": [
        "<a id='5.4'></a>\n",
        "## 5.4 Monte Carlo (MC) Dropout / モンテカルロ（MC）ドロップアウト\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Averaging over multiple predictions with dropout on gives us a Monte Carlo estimate that is generally more reliable than the result of a single prediction with dropout off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIPhikm18IsV"
      },
      "source": [
        "<a id='5.4.1'></a>\n",
        "### 5.4.1 MC Dropout, Model with standard layers\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Here we force training mode, since the model layers do not behave in a special way during training (such as `BatchNormalization` layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOK_GISS8IsV",
        "outputId": "ee212d83-3895-451f-e6e6-06511293fa2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval 1: [test loss, test accuracy]: [0.4643721580505371, 0.8431000113487244]\n",
            "----------------------------------------\n",
            "Eval 2: [test loss, test accuracy]: [0.39823269844055176, 0.8605272769927979]\n",
            "----------------------------------------\n",
            "The number of Monte Carlo samples you use (100 in this example) is a hyperparameter you can tweak. \n",
            "The higher it is, the more accurate the predictions and their uncertainty estimates will be.\n",
            "However, inference time is accordingly increased.\n",
            "----------------------------------------\n",
            "shape of y_probas: (100, 10000, 10)\n",
            "----------------------------------------\n",
            "shape of y_proba: (10000, 10)\n",
            "----------------------------------------\n",
            "Model's prediction for the first instance in the test set, with dropout off:\n",
            "[[0.   0.   0.   0.   0.   0.03 0.   0.14 0.   0.83]]\n",
            "----------------------------------------\n",
            "Model's prediction for first few instances, with dropout activated:\n",
            "[[[0.   0.   0.   0.   0.   0.05 0.   0.43 0.   0.52]]\n",
            "\n",
            " [[0.   0.   0.   0.   0.   0.01 0.   0.03 0.   0.96]]\n",
            "\n",
            " [[0.   0.   0.   0.   0.   0.01 0.   0.11 0.   0.89]]\n",
            "\n",
            " [[0.   0.   0.   0.   0.   0.04 0.   0.22 0.   0.74]]\n",
            "\n",
            " [[0.   0.   0.   0.   0.   0.23 0.   0.69 0.   0.08]]]\n",
            "----------------------------------------\n",
            "Average over the first dimension, to get the following MC Dropout predictions:\n",
            "[[0.   0.   0.   0.   0.   0.08 0.   0.21 0.   0.71]]\n",
            "----------------------------------------\n",
            "Standard deviation of the probability estimates:\n",
            "[[0.   0.   0.   0.   0.   0.12 0.   0.18 0.   0.21]]\n",
            "----------------------------------------\n",
            "Model accuracy: 0.8424\n"
          ]
        }
      ],
      "source": [
        "def listing5_4_1():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    # Use regular Dropout layer here\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        learning_rate=0.01, \n",
        "        momentum=0.9, \n",
        "        nesterov=True\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 2 # 20\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    eval_result = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "    print(\"Eval 1: [test loss, test accuracy]:\", eval_result)   \n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
        "    print(\"Eval 2: [test loss, test accuracy]:\", eval_result) \n",
        "    HR()\n",
        "\n",
        "    # Boost the dropout model we trained earlier without retraining it:\n",
        "    # We just make 100 predictions over the test set, \n",
        "    # setting to training=true ensure that the layer is active, \n",
        "    # and stack the predictions.\n",
        "    # Since dropout is active, all the predictions will be different\n",
        "    MC_samples_num = 100\n",
        "    \n",
        "    print(f\"\"\"The number of Monte Carlo samples you use ({MC_samples_num} in this example) is a hyperparameter you can tweak. \n",
        "The higher it is, the more accurate the predictions and their uncertainty estimates will be.\n",
        "However, inference time is accordingly increased.\"\"\")\n",
        "    HR()\n",
        "    \n",
        "    y_probas = np.stack(\n",
        "        [model(X_test_scaled, training=True) for sample in range(MC_samples_num)]\n",
        "    )\n",
        "    print(f\"shape of y_probas: {y_probas.shape}\")\n",
        "    HR()\n",
        "    \n",
        "    # Average over the first dimension via axis=0,\n",
        "    # then get an array of shape [10000, 10], like we would \n",
        "    # get with a single prediction.\n",
        "    y_proba = y_probas.mean(axis=0)\n",
        "    print(f\"shape of y_proba: {y_proba.shape}\")\n",
        "    HR()\n",
        "    \n",
        "    y_std = y_probas.std(axis=0)\n",
        "\n",
        "    print(\"Model's prediction for the first instance in the test set, with dropout off:\")\n",
        "    print(np.round(model.predict(X_test_scaled[:1]), 2))\n",
        "    HR()\n",
        "\n",
        "    print(\"Model's prediction for first few instances, with dropout activated:\")\n",
        "    print(np.round(y_probas[:, :1], 2)[:5][:])\n",
        "    HR()\n",
        "\n",
        "    print(\"Average over the first dimension, to get the following MC Dropout predictions:\")\n",
        "    print(np.round(y_proba[:1], 2))\n",
        "    HR()\n",
        "    \n",
        "    y_std = y_probas.std(axis=0)\n",
        "    print(\"Standard deviation of the probability estimates:\")\n",
        "    print(np.round(y_std[:1], 2))\n",
        "    HR()\n",
        "\n",
        "    y_pred = np.argmax(y_proba, axis=1)\n",
        "\n",
        "    accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "    print(f\"Model accuracy: {accuracy}\")\n",
        "    \n",
        "listing5_4_1()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVoLyJCH8IsW"
      },
      "source": [
        "<a id='5.4.2'></a>\n",
        "### 5.4.2 MC Dropout, Model with customized layers\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "If you have a model that was already trained using `Dropout` or `AlphaDropout`, you need to create a new model that’s identical to the existing model except that it replaces the layers with `MCDropout`, then copy the existing model's weights to your new model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z6xdenC8IsX",
        "outputId": "ffc298c8-6c80-43ad-cb29-9c2eec0b4f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.4528 - accuracy: 0.8486 - 295ms/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_25 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " alpha_dropout_3 (AlphaDropo  (None, 784)              0         \n",
            " ut)                                                             \n",
            "                                                                 \n",
            " dense_284 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " alpha_dropout_4 (AlphaDropo  (None, 300)              0         \n",
            " ut)                                                             \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Check for AlphaDropout or Dropout layers to replace:\n",
            "False <keras.layers.core.flatten.Flatten object at 0x7fdfeb062a10>\n",
            "True <keras.layers.noise.AlphaDropout object at 0x7fdfeb0a0990>\n",
            "False <keras.layers.core.dense.Dense object at 0x7fdfeb18f190>\n",
            "True <keras.layers.noise.AlphaDropout object at 0x7fdfea2cbf50>\n",
            "False <keras.layers.core.dense.Dense object at 0x7fdfeb1a5810>\n",
            "True <keras.layers.core.dropout.Dropout object at 0x7fdfeb1a5450>\n",
            "False <keras.layers.core.dense.Dense object at 0x7fdfeb1a5d10>\n",
            "----------------------------------------\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_25 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " mc_alpha_dropout (MCAlphaDr  (None, 784)              0         \n",
            " opout)                                                          \n",
            "                                                                 \n",
            " dense_284 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " mc_alpha_dropout_1 (MCAlpha  (None, 300)              0         \n",
            " Dropout)                                                        \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " mc_dropout (MCDropout)      (None, 100)               0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model's prediction for the first instance in the test set, with dropout off:\n",
            "result_mc: [[0.   0.   0.   0.   0.   0.12 0.   0.2  0.   0.67]]\n"
          ]
        }
      ],
      "source": [
        "def listing5_4_2():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    class MCDropout(keras.layers.Dropout):\n",
        "        def call(self, inputs):\n",
        "            return super().call(inputs, training=True)\n",
        "\n",
        "    class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "        def call(self, inputs):\n",
        "            return super().call(inputs, training=True)\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        #keras.layers.AlphaDropout(rate=0.2),\n",
        "        keras.layers.Dropout(rate=0.2),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        learning_rate=0.01, \n",
        "        momentum=0.9, \n",
        "        nesterov=True\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 3\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    print(\"Check for AlphaDropout or Dropout layers to replace:\")\n",
        "    for layer in model.layers:\n",
        "        print(isinstance(layer, keras.layers.AlphaDropout) or isinstance(layer, keras.layers.Dropout), layer)\n",
        "        \n",
        "    HR()\n",
        "      \n",
        "    new_model = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, keras.layers.AlphaDropout):\n",
        "            new_model.append(MCAlphaDropout(layer.rate))\n",
        "        elif isinstance(layer, keras.layers.Dropout):\n",
        "            new_model.append(MCDropout(layer.rate))\n",
        "        else:\n",
        "            new_model.append(layer)\n",
        "            \n",
        "    mc_model = keras.models.Sequential(new_model)\n",
        "            \n",
        "    mc_model.summary()\n",
        "    \n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        learning_rate=0.01, \n",
        "        momentum=0.9, \n",
        "        nesterov=True\n",
        "    )\n",
        "    \n",
        "    mc_model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    mc_model.set_weights(model.get_weights())\n",
        "    \n",
        "    MC_samples_num = 100\n",
        "    \n",
        "    # Now we can use the model with MC Dropout:\n",
        "    print(\"Model's prediction for the first instance in the test set, with dropout off:\")\n",
        "    result_mc = np.round(\n",
        "        np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(MC_samples_num)], axis=0), 2\n",
        "    )\n",
        "    print(f\"result_mc: {result_mc}\")\n",
        "    \n",
        "listing5_4_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hfmUC8q8IsX"
      },
      "source": [
        "<a id='5.4.3'></a>\n",
        "### 5.4.3 Creating a model from scratch with MC Dropout layer\n",
        "<a href=\"#top\">[back to top]</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM_ymR4I8IsX",
        "outputId": "06fbc3c2-695d-48b8-dfa3-df6b4f0fc386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_26 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " mc_dropout_1 (MCDropout)    (None, 784)               0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " mc_dropout_2 (MCDropout)    (None, 300)               0         \n",
            "                                                                 \n",
            " dense_288 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " mc_dropout_3 (MCDropout)    (None, 100)               0         \n",
            "                                                                 \n",
            " dense_289 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "157/157 - 0s - loss: 0.4646 - accuracy: 0.8382 - 315ms/epoch - 2ms/step\n",
            "----------------------------------------\n",
            "Model's prediction for the first instance in the test set, with dropout off:\n",
            "result_mc: [[0.   0.   0.   0.   0.   0.03 0.   0.06 0.   0.91]]\n"
          ]
        }
      ],
      "source": [
        "def listing5_4_3():\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    class MCDropout(keras.layers.Dropout):\n",
        "        def call(self, inputs):\n",
        "            return super().call(inputs, training=True)\n",
        "\n",
        "    class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "        def call(self, inputs):\n",
        "            return super().call(inputs, training=True)\n",
        "    \n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        MCDropout(rate=0.2),\n",
        "        keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        MCDropout(rate=0.2),\n",
        "        keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "        MCDropout(rate=0.2),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    optimizer = keras.optimizers.SGD(\n",
        "        learning_rate=0.01, \n",
        "        momentum=0.9, \n",
        "        nesterov=True\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=optimizer, \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 3\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled, \n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    # How to best calculate the prediction now?\n",
        "    \n",
        "    MC_samples_num = 100\n",
        "    \n",
        "    # Now we can use the model with MC Dropout:\n",
        "    print(\"Model's prediction for the first instance in the test set, with dropout off:\")\n",
        "    result_mc = np.round(\n",
        "        np.mean([model.predict(X_test_scaled[:1]) for sample in range(MC_samples_num)], axis=0), 2\n",
        "    )\n",
        "    print(f\"result_mc: {result_mc}\")\n",
        "    \n",
        "listing5_4_3()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6qnA8YC8IsX"
      },
      "source": [
        "<a id='5.5'></a>\n",
        "## 5.5 Max-Norm Regularization / 重み上限正則化\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "MaxNorm weight constraint.\n",
        "\n",
        "Constrains the weights incident to each hidden unit to have a norm less than or equal to a desired value.\n",
        "\n",
        "Also available via the shortcut function tf.keras.constraints.max_norm\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/constraints/MaxNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTC8CAZ28IsY",
        "outputId": "ebe89f07-3e8e-4323-cfe2-e7310e603cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 - 7s - loss: 0.4744 - accuracy: 0.8330 - val_loss: 0.3735 - val_accuracy: 0.8620 - 7s/epoch - 4ms/step\n",
            "Epoch 2/5\n",
            "1719/1719 - 7s - loss: 0.3542 - accuracy: 0.8713 - val_loss: 0.3677 - val_accuracy: 0.8658 - 7s/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "1719/1719 - 6s - loss: 0.3270 - accuracy: 0.8783 - val_loss: 0.3510 - val_accuracy: 0.8700 - 6s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1719/1719 - 6s - loss: 0.3180 - accuracy: 0.8821 - val_loss: 0.3469 - val_accuracy: 0.8720 - 6s/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "1719/1719 - 6s - loss: 0.3116 - accuracy: 0.8833 - val_loss: 0.3247 - val_accuracy: 0.8804 - 6s/epoch - 3ms/step\n",
            "----------------------------------------\n",
            "157/157 - 0s - loss: 0.3247 - accuracy: 0.8804 - 311ms/epoch - 2ms/step\n",
            "[test loss, test accuracy]: [0.3247053921222687, 0.8804000020027161]\n",
            "----------------------------------------\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_27 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_290 (Dense)           (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_292 (Dense)           (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,610\n",
            "Trainable params: 266,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def listing5_5():\n",
        "    from functools import partial\n",
        "    \n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "    X_train_full = X_train_full / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "    y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "    pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "    pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "    X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "    X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "    X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
        "        \n",
        "    MaxNormDense = partial(\n",
        "        keras.layers.Dense,\n",
        "        activation=\"selu\", \n",
        "        kernel_initializer=\"lecun_normal\",\n",
        "        kernel_constraint=keras.constraints.max_norm(1.)\n",
        "    )\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        MaxNormDense(300),\n",
        "        MaxNormDense(100),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\", \n",
        "        optimizer=\"nadam\", \n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    \n",
        "    n_epochs = 5\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train_scaled, \n",
        "        y_train, \n",
        "        epochs=n_epochs,\n",
        "        validation_data=(X_valid_scaled, y_valid),\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    HR()\n",
        "    \n",
        "    eval_result = model.evaluate (\n",
        "        X_valid_scaled,\n",
        "        y_valid,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    print(\"[test loss, test accuracy]:\", eval_result)\n",
        "    \n",
        "    HR()\n",
        "    \n",
        "    print(model.summary())    \n",
        "\n",
        "listing5_5()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nav_menu": {
      "height": "360px",
      "width": "416px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "11_training_deep_neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}