{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQjOJr0xZpZQ"
   },
   "source": [
    "<a id='top'></a><a name='top'></a>\n",
    "# Chapter 12 – Custom Models and Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnaPH6uGZpZT"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/gbih/ml-notes/blob/main/book_hands_on/12_custom_models_and_training_with_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPmSMeqjZpZW"
   },
   "source": [
    "1. [Setup](#setup)\n",
    "2. [A Quick Tour of TensorFlow](#2.0)\n",
    "3. [Using TensorFlow like NumPy](#3.0)\n",
    "    * [3.1 Tensors](#3.1)\n",
    "    * [3.2 Indexing](#3.2)\n",
    "    * [3.3 Tensor Operations](#3.3)\n",
    "    * [3.4 Keras Low-Level API via keras.backend](#3.4)\n",
    "    * [3.5 Tensors and NumPy](#3.5)\n",
    "    * [3.6 Type Conversions](#3.6)\n",
    "    * [3.7 Variables](#3.7)\n",
    "    * [3.8 Other Data Structures](#3.8)\n",
    "        - [3.8.1 Sparse Tensors, tf.SparseTensor](#3.8.1)\n",
    "        - [3.8.2 Tensor Arrays, tf.TensorArray](#3.8.2)\n",
    "        - [3.8.3 Ragged Tensors, tf.RaggedTensor](#3.8.3)\n",
    "        - [3.8.4 String Tensors, tf.string](#3.8.4)\n",
    "        - [3.8.5 Sets](#3.8.5)\n",
    "        - [3.8.6 Queues](#3.8.6)\n",
    "4. [Customizing Models and Training Algorithms](#4.0)\n",
    "    * [4.1 Custom Loss Functions](#4.1)\n",
    "    * [4.2 Saving/Loading Models with Custom Objects](#4.2)\n",
    "    * [4.3 Custom Activation Functions, Initializers, Regularizers, and Constraints](#4.3)\n",
    "    * [4.4 Custom Metrics](#4.4)\n",
    "    * [4.5 Streaming Metrics](#4.5)\n",
    "    * [4.6 Custom Layers](#4.6)\n",
    "        - [4.6.1 Custom Layers: Layers with no weights](#4.6.1)\n",
    "        - [4.6.2 Custom Layers: Layers containing weights](#4.6.2)\n",
    "        - [4.6.3 Custom Layers: Layer with multiple inputs](#4.6.3)\n",
    "    * [4.7 Custom Models](#4.7)\n",
    "    * [4.8 Losses and Metrics Based on Model Internals](#4.8)\n",
    "    * [4.9 Computing Gradients with Autodiff](#4.9)\n",
    "    * [4.10 Custom Training Loops](#4.10)\n",
    "5. [TensorFlow Functions and Graphs](#5.0)\n",
    "    * [5.1 TensorFlow Functions](#5.1)\n",
    "    * [5.2 TF Functions and Concrete Functions](#5.2)\n",
    "    * [5.3 Exploring Function Definitions and Graphs](#5.3)\n",
    "        - [5.3.1 Get list of graph operations via get_operations()](#5.3.1)\n",
    "        - [5.3.2 Get the list of inputs and outputs of the power operation](#5.3.2)\n",
    "        - [5.3.3 Fetch an operation or a tensor by name via get_operation_by_name() or get_tensor_by_name() methods](#5.3.3)\n",
    "    * [5.4 How TF Functions Trace Python Functions to Extract Their Computation Graphs](#5.4)\n",
    "        - [5.4.1 Trace Python Functions](#5.4.1)\n",
    "        - [5.4.2 Specify a particular input signature of the TF Function](#5.4.2)\n",
    "    * [5.5 Using Autograph To Capture Control Flow](#5.5)\n",
    "        - [5.5.1 \"Static\" for loop using range()](#5.5.1)\n",
    "        - [5.5.2 \"Dynamic\" loop using tf.while_loop()](#5.5.2)\n",
    "        - [5.5.3 \"Dynamic\" for loop using tf.range() (captured by autograph)](#5.5.3)\n",
    "    * [5.6 Handling Variables and Other Resources in TF Functions](#5.6)\n",
    "    * [5.7 Using TF Functions with tf.keras (or Not)](#5.7)\n",
    "    * [5.8 Custom Optimizers](#5.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK1hQkpmZpZY"
   },
   "source": [
    "---\n",
    "<a id='setup'></a><a name='setup'></a>\n",
    "# 1. Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyUXSS0sZpZZ",
    "outputId": "8533de58-4028-4881-b017-96ba639de477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded..\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "\n",
    "print(\"Libraries loaded..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iQDnvrhzZpZb"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = 'data_chp12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlMzV41vZpZc"
   },
   "source": [
    "---\n",
    "<a id='2.0'></a><a name='2.0'></a>\n",
    "# 2. A Quick Tour of TensorFlow\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No source code, only text explanations.\n",
    "\n",
    "**Main APIs**:\n",
    "\n",
    "1. High-level Deep Learning APIs\n",
    "    * [tf.keras: Implementation of the Keras API, the high-level API of TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
    "    * [tf.estimator: Estimator: High level tools for working with models](https://www.tensorflow.org/api_docs/python/tf/estimator)\n",
    "2. Low-level Deep Learning APIs\n",
    "    * [tf.nn: Primitive Neural Net (NN) Operations](https://www.tensorflow.org/api_docs/python/tf/nn)\n",
    "    * [tf.keras.losses: Built-in loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n",
    "    * [tf.keras.metrics: All Keras metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n",
    "    * [tf.keras.optimizers: Built-in optimizer classes](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)\n",
    "    * [tf.train: Support for training models](https://www.tensorflow.org/api_docs/python/tf/train)\n",
    "    * [tf.initializers: Keras initializer serialization / deserialization](https://www.tensorflow.org/api_docs/python/tf/initializers)\n",
    "3. Autodiff: Public API for tf.autodiff namespace.\n",
    "    * [tf.GradientTape: Record operations for automatic differentiation](https://www.tensorflow.org/api_docs/python/tf/GradientTape)\n",
    "    * [tf.gradients(): Constructs symbolic derivatives of sum of ys w.r.t. x in xs.](https://www.tensorflow.org/api_docs/python/tf/gradients)\n",
    "4. I/O and preprocessing\n",
    "    * [tf.data: tf.data.Dataset API for input pipelines](https://www.tensorflow.org/api_docs/python/tf/data)\n",
    "    * [tf.feature_column: Public API for tf.feature_column namespace](https://www.tensorflow.org/api_docs/python/tf/feature_column)\n",
    "    * [tf.audio: Public API for tf.audio namespace](https://www.tensorflow.org/api_docs/python/tf/audio)\n",
    "    * [tf.image: Image ops](https://www.tensorflow.org/api_docs/python/tf/image)\n",
    "    * [tf.io: Public API for tf.io namespace](https://www.tensorflow.org/api_docs/python/tf/io)\n",
    "    * [tf.queue: Public API for tf.queue namespace](https://www.tensorflow.org/api_docs/python/tf/queue)\n",
    "5. Visualization with TensorBoard\n",
    "    * [tf.summary: Operations for writing summary data, for use in analysis and visualization](https://www.tensorflow.org/api_docs/python/tf/summary)\n",
    "6. Deployment and optimization\n",
    "    * [tf.distribute: Library for running a computation across multiple devices](https://www.tensorflow.org/api_docs/python/tf/distribute)\n",
    "    * [tf.saved_model: Public API for tf.saved_model namespace](https://www.tensorflow.org/api_docs/python/tf/saved_model)\n",
    "    * [tf.autograph: Conversion of eager-style Python into TensorFlow graph code](https://www.tensorflow.org/api_docs/python/tf/autograph)\n",
    "    * [tf.graph_util: Helpers to manipulate a tensor graph in python](https://www.tensorflow.org/api_docs/python/tf/graph_util)\n",
    "    * [tf.lite: Public API for tf.lite namespace](https://www.tensorflow.org/api_docs/python/tf/lite)\n",
    "    * [tf.quantization: Public API for tf.quantization namespace](https://www.tensorflow.org/api_docs/python/tf/quantization)\n",
    "    * [tf.tpu: Ops related to Tensor Processing Units](https://www.tensorflow.org/api_docs/python/tf/tpu)\n",
    "    * [tf.xla: Public API for tf.xla namespace](https://www.tensorflow.org/api_docs/python/tf/xla)\n",
    "7. Special data structures\n",
    "    * [tf.lookup: Public API for tf.lookup namespace](https://www.tensorflow.org/api_docs/python/tf/lookup)\n",
    "    * [tf.nest: Functions that work with structures](https://www.tensorflow.org/api_docs/python/tf/nest)\n",
    "    * [tf.ragged: Ragged Tensors](https://www.tensorflow.org/api_docs/python/tf/ragged)\n",
    "    * [tf.sets: Tensorflow set operations](https://www.tensorflow.org/api_docs/python/tf/sets)\n",
    "    * [tf.sparse: Sparse Tensor Representation](https://www.tensorflow.org/api_docs/python/tf/sparse)\n",
    "    * [tf.strings: Operations for working with string Tensors](https://www.tensorflow.org/api_docs/python/tf/strings)\n",
    "8. Mathematics, including linear algebra and signal processing\n",
    "    * [tf.math: Math Operations](https://www.tensorflow.org/api_docs/python/tf/math)\n",
    "    * [tf.linalg: Operations for linear algebra](https://www.tensorflow.org/api_docs/python/tf/linalg)\n",
    "    * [tf.signal: Signal processing operations](https://www.tensorflow.org/api_docs/python/tf/signal)\n",
    "    * [tf.random: Public API for tf.random namespace](https://www.tensorflow.org/api_docs/python/tf/random)\n",
    "    * [tf.bitwise: Operations for manipulating the binary representations of integers](https://www.tensorflow.org/api_docs/python/tf/bitwise)\n",
    "9. Miscellaneous\n",
    "    * [tf.compat: Compatibility functions](https://www.tensorflow.org/api_docs/python/tf/compat)\n",
    "    * [tf.config: Public API for tf.config namespace](https://www.tensorflow.org/api_docs/python/tf/config)\n",
    "    * [tf.debugging: Public API for tf.debugging namespace](https://www.tensorflow.org/api_docs/python/tf/debugging)\n",
    "    * [tf.dtypes: Public API for tf.dtypes namespace](https://www.tensorflow.org/api_docs/python/tf/dtypes)\n",
    "    * [tf.errors: Exception types for TensorFlow errors](https://www.tensorflow.org/api_docs/python/tf/errors)\n",
    "    * [tf.experimental: Public API for tf.experimental namespace](https://www.tensorflow.org/api_docs/python/tf/experimental)\n",
    "    * [tf.mlir: Public API for tf.mlir namespace](https://www.tensorflow.org/api_docs/python/tf/mlir)\n",
    "    * [tf.profiler: Public API for tf.profiler namespace](https://www.tensorflow.org/api_docs/python/tf/profiler)\n",
    "    * [tf.raw_ops: Public API for tf.raw_ops namespace](https://www.tensorflow.org/api_docs/python/tf/raw_ops)\n",
    "    * [tf.sysconfig: System configuration library](https://www.tensorflow.org/api_docs/python/tf/sysconfig)\n",
    "    * [tf.test: Testing](https://www.tensorflow.org/api_docs/python/tf/test)\n",
    "    * [tf.types: Public TensorFlow type definitions](https://www.tensorflow.org/api_docs/python/tf/types)\n",
    "    * [tf.version: Public API for tf.version namespace](https://www.tensorflow.org/api_docs/python/tf/version)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ8eS-bJZpZd"
   },
   "source": [
    "---\n",
    "<a id='3.0'></a><a name='3.0'></a>\n",
    "# 3. Using TensorFlow like NumPy\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whxT27Z-ZpZd"
   },
   "source": [
    "<a id='3.1'></a><a name='3.1'></a>\n",
    "## 3.1 Tensors\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Create a tensor with tf.constant()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VArXm1iTZpZe",
    "outputId": "62ad10e1-2e6c-427c-d622-61d8c99431a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntSWMsFTZpZg",
    "outputId": "7c2212f5-9078-4532-d5f2-6a698ead6a9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53qsC1laZpZh"
   },
   "source": [
    "<a id='3.2'></a><a name='3.2'></a>\n",
    "## 3.2 Indexing\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Indexing works much like in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaT4_h0oZpZh",
    "outputId": "cd33d284-ee5b-401f-e153-80f4679d42c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcEXGcEkZpZi",
    "outputId": "6b78e2bf-dc6b-4022-c64a-13f92a1e4915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMM7PdMgZpZj",
    "outputId": "28783a40-849e-4ca5-9381-10a68b58c99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ia7qPrtdZpZj",
    "outputId": "d107af97-ac60-498e-d5ce-3c672a5bd155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "----------------------------------------\n",
      "t2:\n",
      "tf.Tensor(\n",
      "[[[1. 2. 3.]\n",
      "  [4. 5. 6.]]], shape=(1, 2, 3), dtype=float32)\n",
      "----------------------------------------\n",
      "t3:\n",
      "tf.Tensor(\n",
      "[[[1. 2. 3.]]\n",
      "\n",
      " [[4. 5. 6.]]], shape=(2, 1, 3), dtype=float32)\n",
      "----------------------------------------\n",
      "t4:\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]]\n",
      "\n",
      " [[4.]\n",
      "  [5.]\n",
      "  [6.]]], shape=(2, 3, 1), dtype=float32)\n",
      "----------------------------------------\n",
      "t5:\n",
      "tf.Tensor(\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [3.]]\n",
      "\n",
      " [[4.]\n",
      "  [5.]\n",
      "  [6.]]], shape=(2, 3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.expand_dims (input, axis, name=None)\n",
    "# Returns a tensor with a length 1 axis inserted at index axis.\n",
    "# \"-1\" means last axis\n",
    "\n",
    "t1 = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
    "print(\"t1:\")\n",
    "print(t1)\n",
    "HR()\n",
    "\n",
    "t2 = tf.expand_dims(t1, axis=0) # No change\n",
    "print(\"t2:\")\n",
    "print(t2)\n",
    "HR()\n",
    "\n",
    "t3 = tf.expand_dims(t1, axis=1)\n",
    "print(\"t3:\")\n",
    "print(t3)\n",
    "HR()\n",
    "\n",
    "t4 = tf.expand_dims(t1, axis=2)\n",
    "print(\"t4:\")\n",
    "print(t4)\n",
    "HR()\n",
    "\n",
    "t5 = tf.expand_dims(t1, axis=-1) # Same as previous, since it is last axis\n",
    "print(\"t5:\")\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeQC7Jg8ZpZk"
   },
   "source": [
    "<a id='3.3'></a><a name='3.3'></a>\n",
    "## 3.3 Tensor Operations (various)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "TensorFlow provides a variety of math functions including:\n",
    "\n",
    "* Basic arithmetic operators and trigonometric functions.\n",
    "* Special math functions (like: `tf.math.igamma` and `tf.math.zeta`)\n",
    "* Complex number functions (like: `tf.math.imag` and `tf.math.angle`)\n",
    "* Reductions and scans (like: `tf.math.reduce_mean` and `tf.math.cumsum`)\n",
    "* Segment functions (like: `tf.math.segment_sum`)\n",
    "\n",
    "See `tf.linalg` for matrix and tensor functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1smnZbpUZpZm",
    "outputId": "c2ebfa0a-dc58-407a-cc36-6d975938a8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbFWG-HMZpZm",
    "outputId": "e0e67bf5-41b4-4dbd-f67b-2a88f8de8a18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.add(t, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcMJv6FqZpZn"
   },
   "source": [
    "---\n",
    "Note: It is preferable to use tensorflow.math.somefunction, since they natively support operating on Tensorflow tensors, and can take gradients of functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1o3hm1nZpZo",
    "outputId": "165912f0-2fa1-49d7-e542-d67cdffb3b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.add(t, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zq9ctxRZpZo",
    "outputId": "176e4105-1124-4047-c698-8d4f8cd11eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GeiN3ysiZpZo",
    "outputId": "465f0300-65ac-4ee1-84a9-36b8f5efff10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.square([-2., 0., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZh91BsxZpZp",
    "outputId": "8e4091db-ee51-4adb-fda9-0671f3fb4293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY66O7TQZpZp"
   },
   "source": [
    "<a id='3.4'></a><a name='3.4'></a>\n",
    "## 3.4 Keras Low-Level API via `keras.backend`\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uW4lPExtZpZp",
    "outputId": "997bb397-9833-47e0-84ac-3b75a1db5bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtDIha4gZpZq"
   },
   "source": [
    "<a id='3.5'></a><a name='3.5'></a>\n",
    "## 3.5 Tensors and NumPy\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Note: Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set `dtype=tf.float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHooUUeiZpZq",
    "outputId": "86ab2a4b-3dfa-4da6-e9c1-b0febef1e2a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Es4229xrZpZq",
    "outputId": "b201135d-f11d-4b88-d4e5-bde4d1ab5c74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uXP_WO9ZpZr",
    "outputId": "89be6e01-00e6-417d-efee-a9fabe3eead3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wv5WWgPZpZr",
    "outputId": "86a1693d-72f2-48ca-da03-756296d4da25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_C8FK8HZpZr",
    "outputId": "f9e77970-7d7d-4963-a53d-56febe613792"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW13XpCWZpZr"
   },
   "source": [
    "<a id='3.6'></a><a name='3.6'></a>\n",
    "## 3.6 Type Conversions\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbtCv9ciZpZs",
    "outputId": "e9d237a7-8dd0-4eb6-92c8-b77cd106ad99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(40, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "Error: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "print(tf.constant(2.0))\n",
    "print(tf.constant(40))\n",
    "HR()\n",
    "\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfFzOaKJZpZs",
    "outputId": "87031edc-8ace-404d-ee7f-ca5b30b51076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(40.0, shape=(), dtype=float64)\n",
      "----------------------------------------\n",
      "Error: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "print(tf.constant(2.0))\n",
    "print(tf.constant(40., dtype=tf.float64))\n",
    "HR()\n",
    "\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B40XMGpbZpZs",
    "outputId": "b5a5bbe7-720e-488e-bd37-0d83242fb8e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(40, shape=(), dtype=int32)\n",
      "tf.Tensor(40.0, shape=(), dtype=float32)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tf.cast() when you really need to convert types.\n",
    "print(tf.constant(40))\n",
    "print(tf.cast(tf.constant(40), tf.float32))\n",
    "HR()\n",
    "\n",
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhzqB97qZpZt"
   },
   "source": [
    "<a id='3.7'></a><a name='3.7'></a>\n",
    "## 3.7 Variables\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "The values we’ve seen so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. What we\n",
    "need is a `tf.Variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qO3VSUq4ZpZt"
   },
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QV5ejPOZpZt",
    "outputId": "739fb697-174d-4a11-ec01-41be2a6371d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 6.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1vtcZv-ZpZt",
    "outputId": "47689bf1-1b07-4561-e971-682087a59ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify in place\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beyUEvZ5ZpZu",
    "outputId": "3109a990-90e7-4f6f-b2bc-9a8003f223de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  6.]\n",
      " [ 8. 10. 12.]]\n",
      "----------------------------------------\n",
      "[[ 4.  8. 12.]\n",
      " [16. 20. 24.]]\n",
      "----------------------------------------\n",
      "[[ 2.  4.  6.]\n",
      " [ 8. 10. 12.]]\n"
     ]
    }
   ],
   "source": [
    "# Return a Tensor with the same shape and contents as input.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/identity\n",
    "v2 = tf.identity(v)\n",
    "print(v2.numpy())\n",
    "HR()\n",
    "\n",
    "v3 = v.assign_add(v2)\n",
    "print(v3.numpy())\n",
    "HR()\n",
    "\n",
    "v4 = v.assign_sub(v2)\n",
    "print(v4.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZimY5s_SZpZu",
    "outputId": "9375a0d6-10c8-438b-8812-22f13a498bfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same as tf.identity()\n",
    "# Note: v.assign() seems to call read_value() underneath!\n",
    "gb = v.read_value()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVM_ag34ZpZu",
    "outputId": "4b1029f5-9bd4-4bb9-8e50-05b5dc3f8bbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8azSwx2_ZpZv",
    "outputId": "1226d06d-9494-4ce9-bd9a-cb852dc07016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEkQK8NYZpZv",
    "outputId": "da6549d3-3128-4b10-d961-6747ccc7b17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "# Although v is a tf.Variable, we cannot use item assignment on it.\n",
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TCEGRFdZpZw",
    "outputId": "d2677e4f-b874-435e-d3d5-dd9cef04abbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(\n",
    "    indices=[[0, 0], [1, 2]],\n",
    "    updates=[100., 200.]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_XpwlS1ZpZx",
    "outputId": "8f2d0f43-2ca7-458b-e4aa-644549949a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(\n",
    "    values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "    indices=[1, 0]\n",
    ")\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMBoQi3NZpZy"
   },
   "source": [
    "<a id='3.8'></a><a name='3.8'></a>\n",
    "## 3.8 Other Data Structures\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "im9rgN4xZpZy",
    "tags": []
   },
   "source": [
    "<a id='3.8.1'></a><a name='3.8.1'></a>\n",
    "### 3.8.1 Sparse tensors (tf.sparse.SparseTensor)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8ke4iBPZpZz",
    "outputId": "2e7bd9f1-a145-4abd-8561-f98e41a67842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s = tf.SparseTensor(\n",
    "    indices=[[0, 1], [1, 0], [2, 3]],\n",
    "    values=[1., 2., 3.],\n",
    "    dense_shape=[3, 4]\n",
    ")\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-fwFaJ5ZpZz",
    "outputId": "123ae28b-c2e0-48f3-fa36-8faaf0e1bc14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Ar8wEO7RZpZz"
   },
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd96vg1NZpZ0",
    "outputId": "af423ea7-a30a-435c-edcd-c0fe3b0f9e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjcdt5WTZpZ0",
    "outputId": "11fe50e7-efef-42bd-c92f-bf2bf17ae4fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lezRdLN5ZpZ1",
    "outputId": "6bf38616-d8da-47c5-8186-56ce7bce5845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(\n",
    "    indices=[[0, 2], [0, 1]],\n",
    "     values=[1., 2.],\n",
    "     dense_shape=[3, 4]\n",
    ")\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3N6PqALCZpZ1",
    "outputId": "b636f83e-1b1f-493a-cdf1-ae111734b51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLQpxOsNZpZ1",
    "outputId": "ff6564cd-21db-4851-ee53-2a7ad21d759d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYb0wCLYZpZ2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2v_bUwEZpZ3"
   },
   "source": [
    "<a id='3.8.2'></a><a name='3.8.2'></a>\n",
    "### 3.8.2 Tensor Arrays (tf.TensorArray)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/TensorArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKue6BWfZpZ5",
    "outputId": "1cea3f05-1efb-4da1-b812-8b75bde3fd28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7f89608a0bd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yc8Yudz6ZpZ5",
    "outputId": "65b0a9cd-18fc-49c8-e79d-fe05bff5fef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyxljgOtZpZ6",
    "outputId": "45f9c4f2-f509-41b9-97f8-4c2ba84e6e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I33E_WE6ZpZ7",
    "outputId": "1239e8d6-d4cc-4ef4-b319-030ed612ac85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pG8K_W05ZpZ7",
    "outputId": "6d2491a9-4209-479f-f1c2-ab4d7b106c0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MeFuRqsZpZ7"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNqXH_tqZpZ8",
    "tags": []
   },
   "source": [
    "<a id='3.8.3'></a><a name='3.8.3'></a>\n",
    "### 3.8.3 Ragged tensors (tf.RaggedTensor)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/RaggedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRpz8LsmZpZ8",
    "outputId": "bf0c5df2-23ef-455a-c3b8-fd4ce63a35a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])\n",
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWeB_EJTZpZ8",
    "outputId": "d0661abd-f0e4-4cea-fe8a-073cdfd25e13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, None)\n",
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n",
      "<tf.RaggedTensor [[67, 97, 102, 233]]>\n",
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r.shape)\n",
    "print(r[1:3])\n",
    "print(r[0:1])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyCKhFfdZpZ9",
    "outputId": "38f8ef80-4ee5-4991-c6f1-69f490ebc293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ahsG0C1ZpZ9",
    "outputId": "ab302a6b-a327-4ff9-90f1-6038c5243562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4xtKnArZpZ9",
    "outputId": "bde6601d-2b10-41c8-80ad-71a277818e50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccl8cLQmZpZ-",
    "outputId": "1c131531-4616-4477-8ea8-8fd97a61b682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozaLnMrpZpZ-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QP9nJf_IZpaA",
    "tags": []
   },
   "source": [
    "<a id='3.8.4'></a><a name='3.8.4'></a>\n",
    "### 3.8.4 Strings (tf.strings)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIcLM16GZpaB",
    "outputId": "56857217-c7ac-4d16-864c-a77f09b89916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMgDlIIaZpaB",
    "outputId": "e4713a1d-a115-4ec4-a24a-418c2006d54e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZ5PX3CLZpaB",
    "outputId": "f29e89a3-a409-43f8-ebec-c34de53a859e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KyjdB5jMZpaB",
    "outputId": "ef24c3ff-286f-4b71-e42f-2e483bbfa45c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvCfUqvmZpaC",
    "outputId": "bdd1b9b0-31da-45db-9539-372587fe41c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGMjmultZpaC"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYYZ0U3uZpaC",
    "tags": []
   },
   "source": [
    "<a id='3.8.5'></a><a name='3.8.5'></a>\n",
    "### 3.8.5 Sets (tf.sets)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/sets\n",
    "\n",
    "Functions:\n",
    "\n",
    "* difference(...): Compute set difference of elements in last dimension of a and b.\n",
    "* intersection(...): Compute set intersection of elements in last dimension of a and b.\n",
    "* size(...): Compute number of unique elements along last dimension of a.\n",
    "* union(...): Compute set union of elements in last dimension of a and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76CnG7dAZpaD",
    "outputId": "996a38d7-b9c5-4466-fd7e-42bfc9db64ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9E4eleAZpaD",
    "outputId": "59626430-b894-49a4-c51e-e89ef62ff233"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKyv5ti5ZpaD",
    "outputId": "1181fdb7-d731-4c59-edea-6d4654c880da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVBWnPDHZpaD"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQBTBC2iZpaD"
   },
   "source": [
    "<a id='3.8.6'></a><a name='3.8.6'></a>\n",
    "### 3.8.6 Queues (tf.queue)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/queue\n",
    "\n",
    "No source code.\n",
    "\n",
    "* class FIFOQueue: A queue implementation that dequeues elements in first-in first-out order.\n",
    "* class PaddingFIFOQueue: A FIFOQueue that supports batching variable-sized tensors by padding.\n",
    "* class PriorityQueue: A queue implementation that dequeues elements in prioritized order.\n",
    "* class QueueBase: Base class for queue implementations.\n",
    "* class RandomShuffleQueue: A queue implementation that dequeues elements in a random order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXAZ8hEdZpaE"
   },
   "source": [
    "---\n",
    "<a id='4.0'></a><a name='4.0'></a>\n",
    "# 4. Customizing Models and Training Algorithms\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQfCjDIcZpaE"
   },
   "source": [
    "<a id='4.1'></a><a name='4.1'></a>\n",
    "## 4.1 Custom Loss Functions\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Create a custom loss function, which is a simple and common use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "EmHvN4BfZpaE",
    "outputId": "9794694c-dbb4-48d6-f2a8-9920a811a692"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAD8CAYAAACiqQeGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxV8//A8de7mvYNlRYRUr5RU0pJ0UJEkf0byi7rVyFLfEV8bfnZWiwJIUuRSEJoWkRFpJXKkjZK+1TTMvP+/fG+ZZqmmTvNvffce+f9fDzuo7ucOed9Ovfe9/2c8/m8P6KqOOeccy4+FAs6AOecc879wxOzc845F0c8MTvnnHNxxBOzc845F0c8MTvnnHNxxBOzc845F0c8MTuXQESkrYioiFSJ0fauEJH0WGzLOWc8MTsXZSIyTETG5vJ8s1CSrRP7qJxz8coTs3MOESkZdAzOOeOJ2bk4kdtpahGpE3quWY7FTxCRWSKSISIzRaRpjnWdKCKTRGSLiCwXkedFpGK21yeGnvs/EVkNTC1AnNeJyGIR2R7699pcXl8Yiu1vEflMREqEXmsoIl+KyEYRSReRH0WkXUH+n5xLdp6YnUtM/wfcBTQDfgXGikhZsOQHjAfGAKnAeUBj4JUc6+gGCHAScFk4GxWRc4FBwDPAscCzwHMiclbo9WbAYKAfUB84Bfg02yreAlYCzUMxPQBkhL3XzhUBJYIOwLkiomMunagK88P4IVX9DEBErgSWAZcAQ4E7gBGq+uSuhUXkBuAHEammqqtCT/+mqrcXcLu9gTdUdVDo8cJQa/0u4CPgUGAzMEZVNwFLgB+z/f1hwP+p6k+hx4sLuH3nkp63mJ2LjclYCzH77ZJCrO+bXXdUNR2YAzQIPdUU6BY6VZwe+kGw61T1kdnWMXM/tvsv9j7t/VW2bX+OJePfRORNEblcRCpkW/YpYKiITBCRe0Xk6P2Iwbmk5onZudjYoqqLs9+wVm52WaF/JdtzKfuxrWJYyzn7j4BU4ChgVrblNu/HuvdFAUKt5OOAi4A/gD7ATyJSM/T6A1gS/wA4EZgtIldFMA7nEp4nZufix+rQvzWyPdd4H8uesOuOiJTDrvcuCD31PXBMzh8CodvWQsa4AGiV47nWwPxdD1R1p6pOUNU+QCOgHNA52+uLVHWAqnYCXgauKWRMziUVv8bsXPxYDCwFHhCRu4E6wH/3sex/Q72pVwB9ge1YxyqAx4FpIvIC8CKwCTgaOEtVrytkjE8A74rITKyDWUfgUqyDGSLSGTtdPhlYC7QDKgALRKQM1mntXeB34GAsqU8vZEzOJRVPzM7FCVXdISJdgeewDlOzgHuAvYqTAHcDT2I9n+cBnVV1c2g9s0XkZOB/wCSgONZze3QEYvxARP6DdQJ7BruefKOqfhRaZD1wDvZjoSzwC3CNqk4JjZU+ABiGnRVYE9q33oWNy7lkIqoadAzOOeecC/FrzM4551wcCTsxi0hxEflhHzV/S4nIiFAVoOle+9c555zbPwVpMffkn16fOV0NrFPVusDTWOcT55xzzhVQWIlZRA4BOmFjI3PTBXgtdP894BQRkX0s65xzzrl9CLfF/AxwJ/8UQMipFjbMA1XdCWwADip0dM4551wRk+9wqdC4xFWqOlNE2hZmYyLSA+gBULp06aaHHnpoYVYX17KysihWLO/fPRs2pFC6dCalSu3r9078Cmf/Elmy7t/SpUtRVYr6Zy+RJeL+ZWYKO3dKWN91ibh/BbFw4cK/VbVqXsuEM465FXC2iJwJlAYqishwVe2WbZnlQG1gWWh6t0rYGMU9qOoQYAhA/fr19eeffw5vTxLQxIkTadu2bb7Lbd8OIpCyP4UXAxTu/iWqZN2/tm3bsn79embNmpX/wgkqWY/dLom2f8uWQXo6HB1mVfRE27+CEpEl+S2T788SVe2jqoeoah2gKzAhR1IGm17u8tD9C0LL+ADpMFx+OXz5ZdBROOdcdMyeDR9/HHQUiWW/K3+JyIPAd6o6Bqt3+4aILMbK8HWNUHxJ79VXoXTpoKNwzrnoOPNMu7nwFSgxq+pEYGLoft9sz2cAF0YysKKidGl46SVo3hxSU4OOxjnnIufVV2HFCrj33qAjSSxeKzsO1KwJZcsGHYVzzkXWv/8Na9cGHUXi8cQcBzp1gvXrYeNGqFgx6Gicc67wfvwRtm2zs4GuYJK3T3qCue8+7wTmnEseK1fCknz7H7vceIs5TgwYYMOmnHMu0e3YAR07Bh1F4vIWc5wQgRdegA8/DDoS55wrnMcfhyefDDqKxOUt5jhy4olwwAFBR+Gcc4XTpw9s3Rp0FInLW8xxpFEjUPXrMs65xDV2LHz9NZQvH3QkictbzHFmzBioUgUOOyzoSJxzruBKl/aiSYXliTnO3Hxz0BE459z++ftvaNcOihcPOpLE5qey49BLL8ETTwQdhXPOFUz//vD660FHkfi8xRyHzjoLypQJOgrnnCuY/v0hK/FmsY073mKOQ9Wrw/LlMG1a0JE451x4nn4avvoKkngq5Zjx/8I4tXQp/PZb0FE451x4TjgB6tQJOork4Key49Tpp9u/O3ZASkqwsTjnXF4WLLDhnuXKBR1JcvAWcxx76y247bago3DOubwNHQozZgQdRfLIt8UsIqWByUCp0PLvqer9OZa5AngCWB56apCqDo1sqEXPOefABRcEHYVzzuXNy29GVjgt5m1Ae1VNBRoDHUXkhFyWG6GqjUM3T8oRULYsLFwIr70WdCTOOZe7bt1g1qygo0gM4fZYzzcxq0kPPUwJ3XS/IwtZtqwMGzYUdi3Jr2xZHzrlnItf990HDRoEHUX8W7wYmjQJb1lRzT/HikhxYCZQFxisqnfleP0K4FFgNbAQuFVVl+aynh5AD3vUtGmdOpN49NE5VK+eEV60CSQ9PZ3yESoWqwp//12SqlW3R2R9kRDJ/YtHybp/vXr1IjMzk4EDBwYdStQk67HbJZ7276uvqtC48TrKl8+M2Drjaf8iZc6cSvz3v8eycWMKIDNVtVmef6CqYd+AykAacGyO5w8CSoXuXwdMyG9dJUs2UVCtVk112jRNOmlpaRFb14wZqmedFbHVRUQk9y8eJev+tWnTRlNTU4MOI6qS9djtEi/7l5Wl2quX6po1kV1vvOxfpAwfrlqypCqonnGGKvCd5pMfC9QrW1XXhxJzxxzPr1HVbaGHQ4Gm+a3r0EO30KEDrFoFbdvCu+8WJJKipVkzn6fZORdfduywoiIHHhh0JPFJFR54wK7Bb99u8yCMGRPe3+abmEWkqohUDt0vA3QAfsqxTI1sD88GFuS74WLKxx9Djx6QkQEXXQSPPmo74/YkAsuWwbXXBh2Jc87Bzp3QsCGsXRt0JPEpIwMuvRT69bNKaAMGwMCBUCLMyiHhLFYDeC10nbkYMFJVx4rIg1iTfAxwi4icDewE1gJXhLPxlBR44QWoXx9694Z77rFeyC++CCVLhrcDRUWNGvbjRdUStXPOBaVECfj2W6hYMehI4s/q1XDuuTB1qs1J/c470KlTwdYRTq/s2araRFUbqeqxqvpg6Pm+oaSMqvZR1WNUNVVV26nqT3mv9R8iVkTj/fetB/KwYXDaaf5LLKcSJeyU/5QpQUfinCvKMjPh3nuhVKmgI4k/P/1kpUmnToVDDrHa4QVNyhBHlb/OOceSTs2aMGmS7dyiRUFHFV8yMuCZZ+w0knPOBWHbNqhVy89q5vTll5a3fv0Vmja1Smipqfu3rrhJzADHHQfTp9vOLFpkOzl5ctBRxY8KFezMgk9C7pwLypo1cOONfkktu5dfho4dYcMGa2ROmmSXH/dXXCVm+Kf537mznc4+9VSfeDu7bdtskHp6ev7LOudcJK1caWWCfc5lk5UFd90F11xjZzLvuANGjSr8ZB5xl5jBLph/8AH06mVd8i+/3KrL+JvBrut8+KH9HznnXCzVqGHzxPucy7BlC1x4IfTvb2cxhwyx+5H4v4nb/97ixW2M3ODBdv9//4NLLrHrrEXdoYfa/8v2+CkE5pxLcr/9Zi1DP4VtZw7atLFLi5UqwaefRnY4a9wm5l1uvBHGjrXrqyNGQPv2VpSkKBOB9evxWuPOuZipVg2uuiroKII3eza0aAHffQeHHw7ffGOXXCMp7hMz2EX1qVOtpfjNN/afMn9+0FEFa9dwBT+975yLtjVrYM4cOPHEoCMJ1rhx0KoVLF0KLVvaaf1//Svy20mIxAxWZWb6dGjeHH7/3f5TPv886KiCdf758MMPQUfhnEt2v/wCn3wSdBTBGjwYzjrLOt527QoTJthZhGhImMQMUL06pKVZr8CNG+GMM+yCe1H18cc2Xs4556IlK8saRP36BR1JMDIzoWdPq3WdlQV9+8Jbb0Hp0tHbZkIlZrDqYCNGQJ8+9h923XVWzjMzcrOOJYySJeHZZ+00v3PORcOQIZaMiqJNm6BLF6t1nZJiQ3f79Yt+B7gwS2rHl2LF4JFH4KijbBKMJ5+0SajffLPw48cSTbNmdu3dOeei4ZprimZH06VL7dT1jz/aDFqjR8PJJ8dm2wnXYs7uyith/Hg44AAb23vyybBiRdBRxVarVjacbMmSoCNxziWbjz+2ySoOOijoSGJr5kzrZPzjj1CvnvVvilVShgRPzADt2llP7SOPhO+/t2shs2YFHVVsjR7tpUudc5FXvHjRKwH8wQeWhFeutImDvvkG6taNbQwJn5jBpo2cNg1OOgmWL4fWrW3sc1Fx003QvbvPZe2ci5yVK22mv+bNg44kNlTh//4PzjvPqnpdcQV89pmdxo61pEjMAFWq2PCpbt1g82a7YP/ss0UnWY0eDbffHnQUzrlkce+9lpiKgh074Prrrda1qvVheuWV4GbQyrfzl4iUBiYDpULLv6eq9+dYphTwOtAUWAP8W1V/j3i0+ShVynrN1atnvQh79YKFCy1Bl0jIbm7ha9fOSsQ551wkvPxy0BHExvr1VvP6iy9sCNTrr9vjIIXTYt4GtFfVVKAx0FFETsixzNXAOlWtCzwNPB7ZMMMnYhNevPWWJernnrOedRs3BhVRbFSubAPf33036Eicc4muRw8rKpLsdbF/+82qmX3xhRULmTgx+KQMYSRmNbsmGUwJ3XKeIO4CvBa6/x5wikiwh/Tii60yS9WqVmC8Vaui0XN5+fKgI3DOJbpLL4XDDgs6iujaVd55wQI45hjred2iRdBRGdEwLsKKSHFgJlAXGKyqd+V4fS7QUVWXhR7/ArRQ1b9zLNcD6AFQtWrVpiNHjozITuRlxYrS3HNPQ5YsKccBB2znf/+bQ4MGm6K+3fT0dMoHNDdjenoJypffGeVtBLd/sZCs+9erVy8yMzMZOHBg0KFETbIeu12ivX8zZhxIkybrSEkJpoNOLI7fhAnVeOyxo9mxoxjNmq3l/vvnUb58bKpUtWvXbqaqNstzIVUN+wZUBtKAY3M8Pxc4JNvjX4Aqea2rXr16Givr1qmeeqoqqJYurfruu9HfZlpaWvQ3koslS1QbN1bNyorudoLav1hJ1v1r06aNpqamBh1GVCXrsdslmvu3fbvqxRerbt4ctU3kK5r7l5Wl+tBDlgtA9frrVXfsiNrmcgV8p/nk2gL1ylbV9aHE3DHHS8uB2gAiUgKohHUCiwuVK9usINdea/M5X3ghPPpocvbYPvRQmDEj+a8NOeciT8T655QtG3QkkbdtG1x+ufVBEoGnn7Y+SPHYMTjfxCwiVUWkcuh+GaAD8FOOxcYAl4fuXwBMCP0yiBspKfDii/DEE3ZQ7rkHrr4atm8POrLIy8qyYWMZGUFH4pxLFCtX2qQ4yTiV7Jo10KEDvPGG/ej44AMbtROvDZhwWsw1gDQRmQ18C3yuqmNF5EEROTu0zMvAQSKyGLgNuDs64RaOiE14MWoUlCkDr74Kp58Oa9cGHVlklSoFl1xiNcWdcy4cNWpYh9lk+95YuBBOOAGmTIGaNe3fs8/O/++CFE6v7Nmq2kRVG6nqsar6YOj5vqo6JnQ/Q1UvVNW6qtpcVX+NduCFce65dnBq1LDu8S1b2iQYyeTMM63X4bZtQUfinIt3v/xi9R6SrSb2pEmWlBcvhiZN7DLfcccFHVX+kuy3UfiaNrXu8amp9ouqRQtL1snk3Xfh99+DjsI5F+9SUqB27aCjiKxhw+z09bp1Vsti8mSoVSvoqMJTZBMz2BtxyhTo1MlOZ596KgwfHnRUkTNokFVBK4pzVTvnwvPXXzZd7nnnBR1JZGRlWTnRK6+0Upu33molixNpBF2RTswAFSrYlJE9e1pHsO7drZxnfHVd23+33grvvBN0FM65eDV+PDz/fNBRRMbWrVZc6pFHbFas556Dp55KvBmy4rCjeOwVLw7PPANHHQW33AIPPWTXJF55xWqnJrL77rP5qp1zLjfduwcdQWT89ZdNXjR9ujW43n3XOvcmoiLfYs7upptsusgKFeDtt6F9e1i9OuioCuegg+x0/QcfBB2Jcy7e9O4NH38cdBSFN2+e9ROaPt1qOXz9deImZfDEvJczzoCpU+3g7qqlOn9+0FEVTvnyUKlS0FE45+LNbbfZJA6JbPx424clS2zu6OnT4dhjg46qcDwx56JhQzu4xx+/5+wjiappUzjpJBsS4ZxzACNG2GW8RL7U9cILNjR040ar6DhxIlSvHnRUheeJeR+qV7eDfP75sGEDdOwIL70UdFT7b/p0ePDBoKNwzsWLn3+O38pX+cnMtNb+DTfY/T59rJNrmTJBRxYZnpjzULYsjBwJd99tB79HD7jjjsQsWdeqFbz2Wv7LOeeS37p1NvqkWrWgIym49HQb2vX00zb++pVXrBd2MlUsS6JdiY5ixWzCi5dftmLn//d/1orevDnoyArur79swL2Pa3au6Nq2zaphpacHHUnBLV8OJ58MY8bYKfjx4228crLxxBymq66yN0HlytbDuU0bWLEi6KgKplo1ePLJxBvT55yLnFKlYO7cxCq4AfDDD9a564cf4MgjrXNu27ZBRxUdnpgLoF07mDbN3hQzZ1qP7R9/DDqq8IlYx7bnn/ca2s4VRb/+atPfpqQEHUnBfPSRdWBdscL+nTYN6tcPOqro8cRcQPXr25uidWtYtsyu3SbSOEARu760fn3QkTjnYq16dZuTOFGoWvGnLl3s8mG3bvD551ClStCRRZcn5v1QpYoNn+rWzd4sZ58NAwYkThnPe+6x3otbtgQdiXMuVhYvhgULrFGRCHbutKJPt95q360PPgivv26n4pOdJ+b9VKqUvUn69bNe2j17wn/+Y2+mRHD77fDll0FH4ZyLlV9/he+/DzqK8GzcCJ0722W3UqXgrbesvHCiDu8qqHxrZYtIbeB14GBAgSGq+myOZdoCHwK/hZ56f9e8zclMxIYc1K1rPQMHD7YiHiNGBB1Z/l58MbmGFzjn9m3zZjjttKCjCM+ff5aiVSvroFalik0ylOjVyQoqnK/mncDtqtoAOAG4SUQa5LLcFFVtHLolfVLO7pJLYMIEexN9+qldd/7zz/g+31KsmPUuf+yxoCNxzkVbz57w/vtBR5G/6dPhxhubMncuHH20PS5qSRnCaDGr6kpgZej+JhFZANQCEryCdGS1amVvok6d7JfejTc25YgjrHt/vGreHBo3DjoK51y0JcK0ju+9ZzNdZWSU5JRT7HHlykFHFQzRAvRYEpE6wGTgWFXdmO35tsAoYBmwAuitqvNy+fseQA+AqlWrNh05cmQhQo9P6ekluP/+Y/j++wMoWTKTe+75iTZt4neKqg0bSjBnTmVat/67QH+Xnp5O+UQbCFkAybp/vXr1IjMzk4EDBwYdStQk67HbpSD7pwoDB9blkkv+oEqV7VGObP+owltvHcrQoUcAcNppf3DHHb9RokSC9KYtoHbt2s1U1WZ5LqSqYd2A8sBM4LxcXqsIlA/dPxNYlN/66tWrp8lq+3bVTp2Wq73lVB97TDUrK+iocrdiherddxf879LS0iIeSzxJ1v1r06aNpqamBh1GVCXrsdulIPuXlaU6erTqjh3Ri6cwtm1TvfJK+54UUe3fX3XChLSgw4oq4DvNJz+G1f1HRFKwFvGbqrrXlQpV3aiq6aH744AUEUnykWb7lpICt9++kP79rYPY3XfDNdfA9jj8wVqjhpUc3bAh6Eicc5GkamN+u3SxcsLxZu1amzP51Vdt+OaoUTYXQVHpeZ2XfBOziAjwMrBAVZ/axzLVQ8shIs1D610TyUATjYi9yUaNsjfdK6/YDFXr1gUd2d62bbPrzZs2BR2Jcy5SVq+G4cPjs77C4sXQsuU/0zROngznnht0VPEjnBZzK6A70F5EZoVuZ4rI9SJyfWiZC4C5IvIjMADoGmqyF3nnnmtvuurVIS3N3oyLFwcd1Z5KlYI5c6BChaAjcc5FQmYmHHig1VqIt2GRU6ZYOeOFC6FRI5gxA5rlfcW1yMn3kKnqV6oqqtpI/xkONU5VX1DVF0LLDFLVY1Q1VVVPUNWvox964mjWzN58jRrZHKgnnABffRV0VHsqWdJa+DNnBh2Jc66wPv7YamLHm+HD4dRT7TT2mWfa92Dt2kFHFX/i7LdU8qpd296EZ54Ja9bAKafYmzSeXHghHHVU0FE45wrrrLPg2WfzXy5WVOH++2041PbtViXxww/9LN2+eGKOoQoV7M14yy325uze3d6s8XLSv3lzm+902rSgI3HO7a8XXrBrtxUrBh2JyciASy+1WtfFitm8AgMGxGeHtHjhiTnGSpSwX7IDB9qb9MEH7U2bkRF0ZGbJEqup65xLTE2aQJ06QUdhVq+2s4Nvv23zP3/0kbWWXd78N0tAbr4ZjjgC/v1ve9MuWWIlMqtWDTaujh3t3zVr4KCDgo3FOVcwEyZYCcvSpYOOxGay6tQJfvvNLuWNHWv9bFz+vMUcoDPPhKlT7U379dfWU3HBgqCjsl7jnTvHzyl251z+VGHYsPgY9vjllzYC5bffoGlTK1fsSTl8npgD1qiRvWmPP97exC1bBj8dY926NqTBB/o7lzi2bbPhUUGfdRs61M68bdhgw0UnTbJCRi58npjjQI0a1lnj/PPtzdyxI7z0UrAxFStmH6o//ww2Dudc/n7/3SbSCfIsV1YW3HWXDdPauRPuvNMmoihXLriYEpUn5jhRtiyMHGlv7J07oUcPe2NnZQUTT7FiVkq0SpEtrOpc4qhTx37cB3WWa8sWG27Zv791cB0yBB5/PP6KmyQK/2+LI8WK2fzIQ4fam/uJJ+CCC2yS8yC0aGGnoX7+OZjtO+fyN3o0vPxycGOCV66ENm1svudKlWxO+ngsbpJIPDHHoauvhs8+s7lIR4+2N/2KFcHEsmKF9dB2zsWn444LrqTl7Nn2A/677+Dww+Gbb2x4lCscT8xxqn17e5MfcYSVyWzRAn78MfZxdO9uJUT9WrNz8Wf8eLuGm5oa+22PG2fXtZcutSFa06fDv/4V+ziSkSfmOHb00fZmb9UKli2D1q2tBm6sffYZ3Htv7LfrnMvblCmwfn3stztokJX9TE+Hiy+2kSRB9wZPJp6Y41yVKvDFF3DJJfYhOPtsqxoWS/HQS9w5t6e1a+Ghh2x4Y6xkZlpJ4f/8xzqm9u0Lb74ZHwVNkokn5gRQurRNePHAA/Zh2PXB2LkzNtsXsZKhrVsH1xHNOfePtWvhpJNgx47YbXPTJujSxRoGJUvCG29Av35e7yAa8k3MIlJbRNJEZL6IzBORnrksIyIyQEQWi8hsETkuOuEWXSI24cXw4fahGDTIWs8bN8Zm+2XLWqvZxyQ6F7wDD4RZsyAlJTbbW7r0n0tpBx1kZ/G6dYvNtouicFrMO4HbVbUBcAJwk4g0yLHMGcBRoVsP4PmIRul2u/RSq4dbpQp88ol9WP74Izbb/te/4LXX4KefYrM959zevvqqCg8+GLuk/N13NvPc7NlQr57NPnfSSbHZdlGVb2JW1ZWq+n3o/iZgAVArx2JdgNfVTAMqi4gXYYuSVq3sw3H00TBnjn1ovv02NtsuXz4223HO5e6449bx73/HZlujR8PJJ9uojLZtbaRILK9pF1UFusYsInWAJsD0HC/VApZme7yMvZO3i6Ajj7SJL9q3h7/++meAf7Sdfz4ceij88UfZ6G/MObeHN9+E9etTqF8/uttRtQJH558PW7fClVfa6IwDD4zudp0Je9pHESkPjAJ6qep+XdkUkR7YqW6qVq3KxIkT92c1CSE9PT0m+9enj1C6dD3GjavB+edDjx6/0LXr0qh2yJgx40BmzDiQQw+dGL2NBCxWxy/W1q9fT2ZmZlLu2y7JeuwAZs6sScOG0d2/nTuFZ545io8/rgnAtdf+ysUX/8HXX0dtk3tI5uMXNlXN9wakAJ8Bt+3j9ReBi7M9/hmokdc669Wrp8ksLS0tZtvKylLt31/VfueqXn216rZt0d1mWlpa1LcRpFgev1hq06aNpqamBh1GVCXrsZszx/6N5v6tW6d6yin2PVK6tOrIkVHb1D4l6/HbBfhO88m54fTKFuBlYIGqPrWPxcYAl4V6Z58AbFDVlYX90eDCIwJ33AGjRkGZMlY394wzYN266G1z27ZipKbGx9yvziW7v/+2YZLRHCL566//TDt78ME2KcaFF0Zve27fwrnG3AroDrQXkVmh25kicr2IXB9aZhzwK7AYeAm4MTrhurycd55NOlG9uvXcbtkSfvklOtsqVSqLr78OrnC+c0VFZqYNUZowwSa3iYavv7bSuz/9BMccYxUHW7SIzrZc/vI9zKr6FZDnFctQ8/ymSAXl9t/xx9uHqnNn67HdogV88IENq4q0Aw6Ap5+2D/Jpp0V+/c45GDbMfmA/8kh01v/229a5a9s2OP10GDHCZolywfHKX0no0EPhq6/sdPaaNTbby5tvRmdbJ58MjRpFZ93OObjiCujdO/LrVbWSnpdcYkn5hhtg7FhPyvHAE3OSqlgRxoyBm2+G7dutSs8DD9iHMZKaNrVr3GPGRHa9zjm49Vb4/ffID1Patg0uv9xqXYvYma/Bg6N3qtwVjCfmJFaihNW1HTAAihWzurbdulnd60jautWqAjnnIuu00+CQQyK7zr//hg4drGr4ZkoAACAASURBVNZ1uXLw4YfQq5fXvI4nnpiLgP/8x1q05cvDW2/BqafC6tWRW3+dOvDf/1qvzki3yJ0rijZvts/qGWdAqVKRW+/PP1snrylToGZN+/essyK3fhcZnpiLiE6d7LrzIYfA1Kn/9MCMFFW4+mpYsiRy63SuqFq9OvIjKiZO/GekRpMmMGOG/evijyfmIiQ11T6MTZta6/aEE2zMYiSI2HCOOnVseIdzbv+sWGFDHu+7L3LrfPVVOy2+bp3NSjd5MtTyoslxyxNzEVOjho11Pvdc2LABOnaEoUMjs24RW9f990dmfc4VRUOGwDvvRGZdWVlwzz1w1VU2d/Ntt1lNfZ+MJr55H7wiqFw5eO896NMH+veHa6+FRYvg0Uetk1hhXHSR9+x0bn9lZkZu9MTWrdbz+t13oXhxm8P9+uvz/zsXPG8xF1HFisHjj8NLL1ki7d/fyu9t2VK49VasaL/Md/1Cd86FZ/NmaNzYPoOF7SH911/Qrp0l5YoVYdw4T8qJxBNzEXfNNfDpp1ZU4P33bfrIlYWscl6xop0qL148MjE6VxSUK2d9PsoWckbVuXOt4t/06XDYYdbZ0yvzJRZPzI5TTrEJ0I84Ar77zj7UP/64/+sTsSEYX3xhp8idc3l7/327tlytWuHW89ln0KqVjY7YlZyPPTYyMbrY8cTsAPjXv2DaNDjxRFi61GprjxtXuHX++aeVBHXO5a15cxslURjPP2/DIjdutMtSaWk2S5RLPJ6Y3W5Vq9qptEsugfR0a/UOGrT/67vsMvvCmTMncjE6l2xeecVOY+9vzfnMTOttfeONdv+ee6xXd5kykY3TxY4nZreH0qVh+HAb8pSVZVXDCjMP7O+/23hMrwjm3N5U7bTz/vbHSE+36V6ffhpSUmy88sMPF350hQuWHz63FxEbsjF8OJQsafW2u3SBTZsKvq4jjrBpJ7du9eTsXHabNlmJzH79rMNkQS1fbrO7jRljU7COH28zUbnEl29iFpFXRGSViMzdx+ttRWSDiMwK3fpGPkwXhEsvtVPbBx1k15tbt4Y//ti/dV12mZUEdM6ZmTNtuOL++OEHu0z0ww9Qt671D2nbNqLhuQCFUwpiGDAIeD2PZaaoaueIROTiSuvW1rOzUyebQapFC/joo4Kv57XX7Dqacw7Wr7dEuj/JdOrUg3jkERvvfNJJ1qO7SpVIR+iClG+LWVUnA2tjEIuLU0ceacOp2rWzntYnnwyTJxfsm6BcOft13717lIJ0LoF06QLz5xfsb1TtWvJ99x3Lli32Wfr8c0/KyUg0jAt/IlIHGKuqe42IE5G2wChgGbAC6K2q8/axnh5AD4CqVas2HTly5P7GHffS09Mpn2QFaXfsEJ5+uh6ffFIDgB49fqFr16VhVynauVNYvrwMhx1WyPJiMZCMxw+gV69eZGZmMnDgwKBDiZp4P3aq9lkqWTL8TheZmcKAAXUZM8Zmnrjqqt/o1m1JUs6hHO/Hr7DatWs3U1Wb5bmQquZ7A+oAc/fxWkWgfOj+mcCicNZZr149TWZpaWlBhxAVWVmqjz2mal8vqtdco7p9e8HW0a+f6qJF0YkvUpL1+LVp00ZTU1ODDiOq4vnYTZ6setllBfub9etVTzvNPm+lSqned9+86AQXJ+L5+EUC8J3mkx8LPd2Aqm7Mdn+ciDwnIlVU9e/CrtvFHxG46y7IyJjLY48dy9ChNoXke+9Zz9BwNG1qJUCdK2pOPBFq1w5/+d9/h86dYd48qzPw4YewbdsqoEG0QnRxoNDDpUSkuoidUBGR5qF1er2nJNemzd9MmmSVhSZMsC+ccCd279TJxki//350Y3Quntx2m31G6tQJb/np062z5bx5Vplv+nRo2TKqIbo4Ec5wqbeBb4D6IrJMRK4WketFZNdcJRcAc0XkR2AA0DXUXHdJrnlzmDEDGjaEn36ykoJTp4b3txkZsGBBdONzLp6cfjocemh4y777rvXYXrUKTj0Vvv4aDj88quG5OJLvqWxVvTif1wdhw6lcEXToofDVV9C1K3zyCbRvb9WHLrkk77877DC4916bLKN+fas45lwy+u03mDLFxvLnRxUee8zKaoLNlT54sFX1ckVH3E5pv3HjRlatWsWOBJ3Ut1KlSixI4iZhzv179tkUTjqpGvfcU5FLL7VZpfr2zX9e2RdesLmbjz8+ygE7F5Dt28Mrubl9O1x3HQwbZp+bJ56w09/J2PPa5S0uE/PGjRv566+/qFWrFmXKlEES8J25adMmKlSoEHQYUZN9/1SVrVu3csEFy6lVC668siIPPGDJeejQvFvDzz9v//75J1SvHv24nYulL76wIj316+e93Nq1VvN60iSbj/nNN+Gcc2ITo4s/cVkre9WqVdSqVYuyZcsmZFIuakSEsmXLUqtWLU48cRVjxkD58vblcuqpsHp13n//8892Ktx7JrhkogojR8Lf+YxPWbTIOnVNmgQ1asDkyZ6Ui7q4TMw7duygjM9ZlnDKlCnDjh076NTJrjsfcoh1BjvhBOscti/161tN7p07rbe2c4luwwY7CzRkiH0O9mXKFPt8LFwIqanW87pp09jF6eJTXCZmwFvKCSj7MUtNtR7bTZvaOOeWLW1Y1b4ULw69esGoUTEI1Lko++ILm5UtL2+8AaecYqexO3WyJF2QMc4uecVtYnaJr0YNOz13zjlWtP/00+Hll/e9/MMPwwUX+Cltl9jWroXzz7f3c25UrWPkZZfBjh023/mHH0ISd0lxBeSJ2UVVuXLWCr7jDjtVfc01cPfduZ+yrlwZ1q2z8Zvbt8c8VOcKbetWm+Rl48bce1NnZNh0qg89BMWKWav62WfD67Xtig5PzC7qihWD/v3teluJEvD443DRRTZtXU4HHggvvgglS8Y+TucKY+dOG4Hw/fdQseLer69ebeP8337bOkeOHQs33xz7OF3888QcYW3btuXmQn7aIrGO/Kxbt46DDz6YX8Koo3nhhRfy5JNPFnqb115rRUgqVbJWdNu2sHLl3ssdfbTV3h48uNCbdC5mHnzQhgfm9qNywQIrr/nNN3YdeepUOOOM2MfoEoMn5iLqkUce4cwzz+TII4/Md9m+ffvy8MMPs2HDhkJv99RT7cvp8MPh22/ty2rOnL2XO/54uybtXCJQtcldLs6lTuIXX1jnx99+s/f19OnQqFHsY3SJwxNzEbI9dOF2y5YtDB06lKuvvjqsv2vYsCFHHHEEw4cPj0gc//oXTJtmX1ZLl0KrVtaSzu6ww+DII+3LLr9xoM4FadEiOPNMKwyScxrhl16Cjh1t+NT558PEidYp0rm8eGKOgqysLPr160eVKlWoVq0avXv3JivU2ym309RXXHEFnTt33uO5nTt30rNnTw444AAOOOAA7rjjjt3rAKu21b9/f4488kjKlClDw4YN90qcbdu25YYbbqB3795UrVqVVq1aATBu3DhEZPdjgP79+yMie9369u0LwNlnn83bb78dsf+jatVs+FTXrrBpk01tl/PUtQg0aQKlSkVss85FXN26MGDAnp29srLgzjuhRw/IzLQfmCNHWvJ2Lj8Jk5hFgrntjzfffJPixYvz9ddfM2jQIJ555hlGjBhR4HVkZWXxzTff8OKLLzJkyBCeeeaZ3a//97//5eWXX2bw4MHMnz+fPn36cN111/Hxxx/vsZ7hw4ejqkyZMoXXX38dgClTptC0adM9xh3fcMMNrFy5cvft9ttvp3r16lwWqrzfvHlzZsyYwdatW/fvPyUXpUvDW2/Z0JGsLOsI07OnfZHt0rWrtTZefDFim3UuYq64wirXHXXUP89t3mzD/p54wjo7Dh1qE1MUS5hvWxe0uKyVnegaNGjAf//7XypUqEC9evV46aWX+PLLL7k4twtQ+1CjRg0GDBiAiHD00UezcOFCnnrqKW677TY2b97MU089xfjx4znppJMAOPzww5kxYwaDBw+mU6dOu9dz+OGH79Vxa8mSJdSsWXOP5ypUqLC79vXjjz/O22+/zcSJE6lbty4ANWvWZMeOHaxYsSKs69LhEoF+/eyL7eqrreXxyy/Wc3XXuM5SpazHq3Px5sYbrcW8y4oVcPbZMHOmDf8bNcp6YjtXEAnzG041mNv+aJSjZ0fNmjVZtWpVgdZxwgkn7NGibdmyJcuXL2fjxo3Mnz+fjIwMOnbsSPny5Xffnn/++b16WTfNpb7f1q1bKb2PmSUeffRRBg4cSFpaGvWzVd7fVSI1ki3m7Lp1s04yBx0EH39shf+XLrXXqlaFm26y63Pz5kVl884VyNix1hJu3txaxWBTmLZoYUn5iCOsk6MnZbc/8m0xi8grQGdglaoem8vrAjwLnAlsAa5Q1e8jHWgiSckxeaqI7L4+XKxYMTRHxi/o1Ja71vXRRx9xaI6Z13Nuu1y5cnv9fZUqVVi3bt1ez//vf//jhRde2KOlvMvatWsBqFq1aoFiLYiTTrJOYZ06wezZ9qX30UfQrJm9/uefPgWeiw8NG0L2k04ff2yXXdLTrTPj6NH2g9K5/RFOi3kY0DGP188AjgrdegDPFz6s5FW1alVW5hi8++OPP+613PTp0/dI4NOmTaNmzZpUrFiRBg0aUKpUKZYsWULdunX3uB122GH5xtCkSRPmz5+/x3MPPvggQ4YMYdKkSXslZYC5c+dSq1YtDj744HB3db/UrWstjXbtLBGffLJ9yYF98Z18sp0ezH4d2rlYWbPG5kiuXRuOO86eGzjQTl+np8Mll9iZH0/KrjDyTcyqOhlYm8ciXYDX1UwDKouIDwjYh/bt2/PJJ58wZswYfv75Z2677TaW7jpnm82KFSvo1asXP//8M++99x5PPPEEt956K2DXg3v37k3v3r155ZVXWLx4MbNmzeKFF15gyJAh+cZw+umns2DBAtasWQNYS3nAgAG88847lCtXjj///JM///yTjIyM3X8zZcoUTo/RwOIDD4RPP4Urr7QSh+efbx1pVC0hf/ml1d52LtbKlrXT1cWKWb+H//zHal1nZcEDD8Dw4XnPP+5cOCLR+asWkD2zLAs9t1dNJxHpgbWqqVq1KhMnTsx1hZUqVWLTpk0RCC32MjMz2b59O5mZmbv3YceOHezcuZNNmzZx4YUX8t1333HllVcCcO2119K5c2fWrFmze/nMzEwuuugitm7dSosWLRARunfvzjXXXLN7mTvvvJNKlSrRv39/brjhBipUqECjRo3o2bPnHuvZvn37Xv+XderUoWnTpgwbNoxrr72WJ554go0bN+4xfApgzJgxtG3bloyMDEaPHs3777+/x7pzO0YZGRn7PK4F1b07lChxKC+9dAR33gmTJq2gV69FXHSR8u23xZg3ryJNm0YnQ6enp0dsP+LJ+vXryczMTMp92yVax+7tt2tzyimrOPjgbYwbV5wHH2zA9OkHkZKSxR13/ESbNquYNCnim91Lsr43d0n2/QuLquZ7A+oAc/fx2ligdbbHXwLN8ltnvXr1dF/mz5+/z9cSxcaNG4MOIU+ffPKJ1qtXT3fu3JnvsoMGDdIOHTrs8dy+9i8ax+7dd1VLl7bueKecorpuneqiRar/+U/EN7VbWlpa9FYeoDZt2mhqamrQYURVNI5dVpbqq6+qbtigumSJasOG9n486CDVKVMivrk8Jet7c5dk3z/gO80nP0aiV/ZyIPssooeEnnNxrGPHjtx0000sW7Ys32VTUlIYmN/kslF0wQU2feTBB9tp7JYt7VTigAFW5nDRosBCc0XAZ5/Z++6KK2Dhwn/KyNavb+U1W7cOOkKXbCJxKnsMcLOIvAO0ADaoai5TE7h4c8stt4S1XI8ePaIcSf6aN7cvwc6dYe5c+3L88ENLysWK7VngwblIKlvWpmV8/30b1rd1q3VOHDUKDjgg6OhcMsq3xSwibwPfAPVFZJmIXC0i14vI9aFFxgG/AouBl4AboxatK9IOO8xm5enY0epnt29vM/l07w5ffWVz3ToXKUuX2lzJrVvb++v88y0pX3WVdU70pOyiJd8Ws6rmWa4qdM78pohF5FweKla0sc09e8Jzz9nwlEWL4K+/rDd3gwZBR+iSRYkSNkVpjx5WTASstOadd/p4ehddCVP5y7ldSpSAQYPgmWfsC/L++2HjRqu2NG7c/ldscw5gxw6bW1nVhj8NHWpDoN57zyaj8KTsos1rZbuEJGKt5iOOsDlwhw+3Gtu1a0ObNpBLwTPnwpaZaZdKfv7ZOh2OGWP9HJyLBU/MLqGddZZd/+vc2SqGrVplX6arV0OM6qG4JPLQQ3Y55LnnrB9Dw4Z26SSMgnrORYyfynYJr3FjmDHDSiT+8gu0bQvDhgUdlUtEf/9t/Rb+/ts6GX71lSdlF3uemF1SqFkTJk+GLl1g0ya7HvjII5CWFnRkLhE89xxcdpmNjd++3aZz/Ogj62zoXKx5YnZJo1w5G1vau7fVMb73XnjqKatj7Ny+bNtmSfiNN2xM/LPPWufCEn6hzwXEE7NLKsWL24QXL75o98eOtWn4pkwJOjIXj4YPh6OPtnHJ5cpZ0ZpbbvGe1y5Ynpgj7Nxzz+WAAw6ge/fuQYdSpPXoAZ98YuNQp02DG26waSSd2+Wnn+C+++D336FWrX86EToXNE/MEdazZ09ef/31Av/d0qVLadu2LQ0aNKBRo0a8++67UYiuaOnQAb7+GurUgXnzrGX0wQdBR+XiwaBB0KiRJeXjjrPOg40bBx2Vc8YTc4S1bduWChUqFPjvSpQowTPPPMP8+fMZP348vXr1YvPmzVGIsGhp0MBqbLdsCRs2WPnOTz8NOioXpCFDoFcvKyTSpYt1GqxZM+ionPuHJ+Y4UaNGDRqHfrJXr16dKlWqsHbt2oCjSg7VqsGECdC1K6SnwxlnQL9+QUflYi0ry3pbX3edFRDp3ds6C3oxGhdvPDHHoZkzZ5KZmUnt2rXzX9iFpXRpePNNu6YI8MAD1sknMzPQsFyMbN1qxWief956Xr/4onUSLF486Mic25sn5jizdu1aLrvsMoYMGRJ0KEmnWDGrgfz66zYUZuBAaz1v2hR0ZC6a/vzTeuaPGwcVKtiljDiYydS5ffLEHEP9+/dHRPa69e3bF4Bt27ZxzjnncPfdd3PiiScGHG3y6t7dJr6vXBk+/9zmdl66NOioXDTMmWOdvH74wSp4TZtmnQKdi2eemCPs1FNP5cILL2T8+PEccsghfPPNN7tfu+GGG1i5cuXu2+2330716tW57LLLUFWuuOIK2rdv70OtYuDkk+Hbb6FuXViwAI4/HmbODDoqF0mffQYnnmh1048/3npe+7SgLhGElZhFpKOI/Cwii0Xk7lxev0JEVovIrNDtmsiHmhi++OILVq9ezV9//cWyZcto2bLl7tcqVKhA9erVqV69Oq+99hpvv/02EydOpG7dukydOpURI0bwwQcf0LhxYxo3bsycOXMC3JPkV7eu9dhu08bmcz7xRBg9OuioXCQMGGCXKdLT4d//hkmTrBOgc4kg36JzIlIcGAx0AJYB34rIGFWdn2PREap6cxRiTDqPPvoogwcPJi0tjXr16gHQunVrsrx2ZMwdeCCMHw9XXWWdw847zzoFNW0adGRuf2RmwqBBRzJqlD2++254+GHrX+Bcogjn7docWKyqv6rqduAdoEt0w8rdAw/YDaBePVi40E4/7voSvf12ePJJu1+zJqxYARMn2mxDYB0+dvWpqlDBOv189JH11gSbVeatt+z+/pTky37duGLFintdSwb43//+x+DBg5k4ceLupOyCVbKk1Ul+5BF7fMcd0L9/PXbsCDYuVzDp6XD22TBqVG1KlIDXXoNHH/Wk7BKPqGreC4hcAHRU1WtCj7sDLbK3jkXkCuBRYDWwELhVVffqTiMiPYAeAFWrVm06cuTIXLdZqVIl6tatuz/7E6hly5bRo0cPVq9eTfHixbnrrrs499xzd7/+2GOP8frrrzN27FiOOOKIACMtvMzMTIrnMtZk8eLFbNiwIYCIImPChKq8/nB5MrOKUe24cvTrN5/y5XcGHVbE9OrVi8zMTAYOHBh0KBG1YkVp+vRpSNYfaylTegc3PbaB1NTEfR/mJT09nfLlywcdRtQk+/61a9dupqo2y3MhVc3zBlwADM32uDswKMcyBwGlQvevAybkt9569erpvsyfP3+fr8WzFStW6A8//KCqqosWLdKaNWtqenq6qqo+9NBDetBBB+nUqVN15cqVu29bt24NMuT9tnHjxlyfT9Rjl920aaqVK29TUK1XT/WXX4KOKHLatGmjqampQYcRUePHq1aurAqqRx2l+sYb04IOKarS0tKCDiGqkn3/gO80n/wYzkme5UD2SheHhJ7LntzXqOq20MOhQJG8Qpe9etfBBx+8u3qXqvLEE0+wZs0aWrVqRY0aNXbfpk6dGnDULqcWv49g7GX9qV/fLpekptosVS6+qMLjj8Ppp8P69XDmmTCrzwiaLPw46NCcK5RwEvO3wFEicriIlAS6AmOyLyAiNbI9PBtYELkQE9MPP/ywu3qXiLBhw4ZcfxmdcsopQYfqcnr+eY6Z9B7Tp9tsQ+np1g/h3nu9Uli8SE+Hbt2sc5cq9Olj/UXKvvY8tcaMyX8FzsWxfBOzqu4EbgY+wxLuSFWdJyIPisjZocVuEZF5IvIjcAtwRbQCTgRr167luuuu8+pdCa5SJZuf97HHrDPgI4/Y+OdVq4KOrGibNcuKhrz1FpQta/WuH3nEO3m55BHWW1lVx6lqPVU9UlUfDj3XV1XHhO73UdVjVDVVVdup6k/RDDqe7aredeutt3r1riRQrBjcdZdVCqtY0aaRTE2FL74IOrKiR9XGJzdvDr/9ZuPQv/3Whrg5l0z8N2YEabbqXRdffHHQ4bgIatfOKoS1bm21lzt0gNtug4yMoCMrGtauhfPPh549bbrG666D2bO9kpdLTp6YIyh79a5WrVp59a4kU7MmpKXZDFXFisHTT1timD076MiS20cfwVFHWVW2ihVh5Eh44QUoUyboyJyLjnwrf7nwZa/etWnTJipUqBBwRG6/vPce86ZOpVUuL5UoYTNUde4M555rp1SbNbNkfffdkJIS82iT1rp1cO217K7ilZpqyfnww/P4ozyOnXOJwlvMzuVUpQo7KlXKc5HmzW0o1XXX2anVvn0tQc+YEaMYk9xHH8Exx1hSTkmBp56yKn95JmUI69g5F+88MTuX07BhVP/003wXK1fOTqmOH29TCs6ebVNI9uzpczzvr99/h3POsdKaK1dCy5Ywdy7ceivkUmhub2EeO+fimSdm53Iq4Jd7hw4wf74lZBHrOXzUUTB8OPi8JOHJyID777ca+B9+aNeP+/eHKVPsubB5YnZJwBOzcxFQtiw88wx8/71NqvLXX9C9u7X4vv466Ojil6pdN27QwK7d79hh0zQuWmSTiYTVSnYuyXhidi6CGje2OZ5feQWqV7drzq1aQdeu8MsvQUcXXyZOtB8u551nnegaNIAJE+Cdd6BWraCjcy44cZuYNZ9Zr1z88WNmiheHK6+0Vt+dd0KpUjBihJ3evvJKWLw46AiDNXMmdOxoY8OnT4eqVe1sw6xZ9pxzRV1cJuaUlBS2bt0adBiugLZu3UqKjxfarXx5m2Rh0SJrMYvAsGF2zbRrV+vVXVSoWvW0du2s9/pnn1nnufvvh19/tevz/tZxzsRlYq5WrRrLly9ny5Yt3gpLAKrKli1bWL58OdWqVQs6nMIbN47Zjz0WsdXVrg1vv22J+Mor7bkRI6B+fWjb1np1J+vbfOdOKwjSoAGceqqdvi5ZEm6/HZYsgQcesB8wERPhY+dcEOKywEjFihUBWLFiBTt27Ag4mv2TkZFB6dKlgw4janLuX0pKCgcffPDuY5fQypYlKwrH7sgj7drzfffZpAvDhsGkSXarXds6O112mU2ekeh+/RWGDoXnn7cpGcH268474YYb4IADorThKB0752IpLhMzWHJO5C/5iRMn0qRJk6DDiJqk3r/nnqPmwoXWnI2Cww+Hl16y5PzSSzBoECxdCrfcYi3JDh2scEnHjta6TBSbNtm81YMG7dkT/cgjoXdvuPzyGJTRjPKxcy4W4jYxOxeYkSOptquZF0VVq8I991hL+YMPrHWZlgbjxtmtbFm45BKbC/qUU+yabLxZt86qdL33nsW8a77qEiXg4outpGbr1nZ9PSZidOyci6awErOIdASeBYoDQ1X1sRyvlwJeB5oCa4B/q+rvkQ3VueSUkgIXXmi3pUvtevSwYTab1dChditRwpLzGWdYY/DYY4MZ45uRAdOmweefw+TJ1jLOXkSlRQvo1g0uvTSKp6udS3L5JmYRKQ4MBjoAy4BvRWSMqs7PttjVwDpVrSsiXYHHgX9HI2Dnklnt2nYd9s47rcTnhx9a56m5c60n82ef2XJly1py7tDBejkffbSdMo5kz+bt262i2Q8/2FCmqVNhzhx7fhcROP5469R2zjlQo0bktu9cURVOi7k5sFhVfwUQkXeALkD2xNwFeCB0/z1gkIiIepdq5/Zbo0Z2u+8+WLXKkvLo0ZYkf/vNipdknzSjeHE4+GCrPFa1qiXJ6tWhWjWbLrFECeuItXlzCb75BjZvtuvCu27Ll9t6V6601vqaNf+cms4Z18knw2mnwUknQeXKsfs/ca4okPxyp4hcAHRU1WtCj7sDLVT15mzLzA0tsyz0+JfQMn/va71ly5bV5s2bR2AX4tP69eupnMTfWEm9f7NmsXPnTko0axZ0JPu0fTts3Gi3DRtg2za75W9W6N/GYW2nTBkoXdqSb/nyUKFCnI83ToBjV1hJ/dkj+fdv0qRJM1U1zzdoTDt/iUgPoEfo4bZJkybNjeX2Y6wKsM8fJkkg+fdv0qRk3b8qEN6+bd1qt3Xroh1SRCXzsYOi8NlL7v2rn98C4STm5UDtbI8PCT2X2zLLRKQEUAnrBLYHJhB2AAAABNxJREFUVR0CDAEQke/y+9WQyHz/Elsy718y7xv4/iW6orB/+S0TTuWvb4GjRORwESkJdAXG5FhmDHB56P4FwAS/vuycc84VXL4tZlXdKSI3A59hw6VeUdV5IvIg8J2qjgFeBt4QkcXAWix5O+ecc66AwrrGrKrjgHE5nuub7X4GcGEBtz2kgMsnGt+/xJbM+5fM+wa+f4muyO9fvr2ynXPOORc7cTm7lHPOOVdUxUViFpHbRURFpErQsUSSiDwkIrNFZJaIjBeRmkHHFEki8oSI/BTax9EikjSDD0XkQhGZJyJZIpI0PURFpKOI/Cwii0Xk7qDjiSQReUVEVoXqKiQdEaktImkiMj/03uwZdEyRIiKlRWSGiPwY2rd+QccUDSJSXER+EJGxeS0XeGIWkdrAacAfQccSBU+oaiNVbQyMBfrm9wcJ5nPgWFVtBCwE+gQcTyTNBc4DJgcdSKRkK697BtAAuFhEGgQbVUQNAzoGHUQU7QRuV9UGwAnATUl0/LYB7VU1Fat+01FETgg4pmjoCSzIb6HAEzPwNHAnkHQXu1V1Y7aH5UiyfVTV8aq6M/RwGjbGPSmo6gJV/TnoOCJsd3ldVd0O7CqvmxRUdTI2KiQpqepKVf0+dH8T9gVfK9ioIkNNeuhhSuiWVN+XInII0AkYmt+ygSZmEekCLFfVH4OMI5pE5GERWQpcSvK1mLO7Cvgk6CBcnmoBS7M9XkaSfLEXNSJSB2gCTA82ksgJneadBawCPlfVpNm3kGewRmhWfgtGvSSniHwBVM/lpXuBe7DT2Akrr/1T1Q9V9V7gXhHpA9wM3B/TAAspv/0LLXMvdprtzVjGVljh7Jtz8UZEygOjgF45zsolNFXNBBqH+qqMFpFjVTUp+guISGdglarOFJG2+S0f9cSsqqfm9ryINAQOB34Um0X9EOB7EWmuqn9GO65I2df+5eJNbCx4QiXm/PZPRK4AOgOnJFq1twIcu2QRTnldF8dEJAVLym+q6vtBxxMNqrpeRNKw/gJJkZiBVsDZInImUBqoKCLDVbVbbgsHdipbVeeoajVVraOqdbDTasclUlLOj4gcle1hF+CnoGKJBhHpiJ2aOVtVtwQdj8tXOOV1XZwSa8G8DCxQ1aeCjieSRKTqrlEdIlIG6EASfV+qah9VPSSU67piZatzTcoQH52/ktljIjJXRGZjp+yTZnhDyCCgAvB5aEjYC0EHFCkicq6ILANaAh+LyGdBx1RYoY56u8rrLgBGquq8YKOKHBF5G/gGqC8iy0Tk6qBjirBWQHegfejzNivUAksGNYC00Hflt9g15jyHFCUzr/zlnHPOxRFvMTvnnHNxxBOzc845F0c8MTvnnHNxxBOzc845F0c8MTvnnHNxxBOzc845F0c8MTvnnHNxxBOzc0WIiEzIVpwiQ0QuCjom59yevMCIc0WQiNwAtAMuDk0e4JyLE1GfxMI5F19E5DLgDOB8T8rOxR9PzM4VISJyITY3eBdV3RF0PM65vXlidq6ICM0JeyPQWVUzgo7HOZc7v8bsXBEhImuAtcDm0FMDVfXlAENyzuXCE7NzzjkXR3y4lHPOORdHPDE755xzccQTs3POORdHPDE755xzccQTs3POORdHPDE755xzccQTs3POORdHPDE755xzceT/AUwWqjbddQn4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 6s - loss: 0.6235 - mae: 0.9953 - val_loss: 0.2862 - val_mae: 0.5866 - 6s/epoch - 15ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 2s - loss: 0.2197 - mae: 0.5177 - val_loss: 0.2382 - val_mae: 0.5281 - 2s/epoch - 5ms/step\n",
      "----------------------------------------\n",
      "121/121 - 0s - loss: 0.2382 - mae: 0.5281 - 294ms/epoch - 2ms/step\n",
      "[test loss, test accuracy]: [0.2382367104291916, 0.5281380414962769]\n",
      "----------------------------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Implement a Huber loss function from scratch, even though it is\n",
    "# built-in as tf.keras.losses.Huber. Our function will be slow, \n",
    "# since it is not a vectorized implementation.\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    \n",
    "def listing4_4():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(8, 3.5))\n",
    "    z = np.linspace(-4, 4, 200)\n",
    "    plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "    plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "    plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "    plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "    plt.gca().axhline(y=0, color='k')\n",
    "    plt.gca().axvline(x=0, color='k')\n",
    "    plt.axis([-4, 4, 0, 4])\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"$z$\")\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(\"Huber loss\", fontsize=14)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, activation=\"selu\", kernel_initializer=\"lecun_normal\", input_shape=input_shape),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=huber_fn, \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate (\n",
    "        X_valid_scaled,\n",
    "        y_valid,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "\n",
    "    HR()\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_calif = listing4_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urFhXj18ZpaF"
   },
   "source": [
    "<a id='4.2'></a><a name='4.2'></a>\n",
    "## 4.2 Saving/Loading Models that Contain Custom Components\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDwiXkjJZpaF",
    "outputId": "f94efc35-4b86-4331-8816-71dd8db0e374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32K\tdata_chp12/my_model_with_a_custom_loss.h5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Save simple MLP model for California data\n",
    "def listing4_2(model):\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_loss.h5\")\n",
    "    !du -h {DATA_ROOT}/my_model_with_a_custom_loss.h5\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "listing4_2(model_calif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8nAsueBZpaG"
   },
   "source": [
    "---\n",
    "This model has contains custom objects.\n",
    "To specify a different threshold from (-1..1),\n",
    "we create a function that creates a configured loss function\n",
    "\n",
    "However, when we save this mode, the threshold will not be\n",
    "saved. This means we have to specify the threshold value \n",
    "when loading the model. We use the name \"huber_fn\", which \n",
    "is the name of the function we gave to Keras, not the\n",
    "name of the function that created it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "MTQz36p-ZpaG"
   },
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI-NfagxZpaG",
    "outputId": "75ceb2c1-534c-41c1-ca87-5fc11c453732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 0.2333 - mae: 0.5030 - val_loss: 0.2825 - val_mae: 0.5116\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2263 - mae: 0.4953 - val_loss: 0.2659 - val_mae: 0.5086\n",
      "----------------------------------------\n",
      "121/121 - 0s - loss: 0.2659 - mae: 0.5086 - 293ms/epoch - 2ms/step\n",
      "[test loss, test accuracy]: [0.26590704917907715, 0.5086389780044556]\n",
      "----------------------------------------\n",
      "32K\tdata_chp12/my_model_with_a_custom_loss_threshold_2.h5\n"
     ]
    }
   ],
   "source": [
    "def listing4_2b():    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_loss.h5\",\n",
    "        custom_objects={\"huber_fn\": huber_fn}\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=create_huber(2.0), \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid)\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate (\n",
    "        X_valid_scaled,\n",
    "        y_valid,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "    HR()\n",
    "    \n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_loss_threshold_2.h5\")\n",
    "    !du -h {DATA_ROOT}/my_model_with_a_custom_loss_threshold_2.h5\n",
    "    \n",
    "listing4_2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aL1yjL4NZpaH",
    "outputId": "048c244c-a224-4b6e-ca39-486a0428137c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2216 - mae: 0.4892 - val_loss: 0.2414 - val_mae: 0.4844\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2177 - mae: 0.4841 - val_loss: 0.2240 - val_mae: 0.4812\n",
      "----------------------------------------\n",
      "121/121 - 0s - loss: 0.2240 - mae: 0.4812 - 382ms/epoch - 3ms/step\n",
      "[test loss, test accuracy]: [0.22396036982536316, 0.48115274310112]\n"
     ]
    }
   ],
   "source": [
    "def listing4_2c():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "        custom_objects={\"huber_fn\": create_huber(2.0)}\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid)\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate (\n",
    "        X_valid_scaled,\n",
    "        y_valid,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "    \n",
    "listing4_2c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHrGbYVQZpaH"
   },
   "source": [
    "---\n",
    "We can solve this problem by creating a subclass of the\n",
    "keras.losses.Loss class, and then implementing its\n",
    "get_config() method.\n",
    "\n",
    "The Keras API currently only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If you build other components (such as losses, metrics, initializers, or constraints) using subclassing, they may not be portable to other Keras implementations. It’s likely that the Keras API will be updated to specify subclassing for all these components as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "fB0Oy5IoZpaI"
   },
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fKvuGLOZpaI",
    "outputId": "e65a1363-d8d5-43df-aba0-4b721d26b256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 3s - loss: 0.7095 - mae: 0.8863 - val_loss: 0.3378 - val_mae: 0.5485 - 3s/epoch - 9ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 2s - loss: 0.2416 - mae: 0.5083 - val_loss: 0.2660 - val_mae: 0.5089 - 2s/epoch - 5ms/step\n",
      "----------------------------------------\n",
      "Save model: chp12/my_model_with_a_custom_loss_class.h5\n",
      "----------------------------------------\n",
      "Load model: chp12/my_model_with_a_custom_loss_class.h5\n",
      "----------------------------------------\n",
      "Epoch 1/2\n",
      "363/363 - 2s - loss: 0.2286 - mae: 0.4970 - val_loss: 0.2120 - val_mae: 0.4723 - 2s/epoch - 6ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 2s - loss: 0.2216 - mae: 0.4904 - val_loss: 0.2045 - val_mae: 0.4725 - 2s/epoch - 5ms/step\n",
      "----------------------------------------\n",
      "model.loss.threshold: 2.0\n",
      "----------------------------------------\n",
      "model.loss.get_config():\n",
      "{'name': None, 'reduction': 'auto', 'threshold': 2.0}\n"
     ]
    }
   ],
   "source": [
    "def listing4_2d():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            units=30, \n",
    "            activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\", \n",
    "            input_shape=X_train.shape[1:]\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ])  \n",
    "\n",
    "    # Use any instance of this class when you compile the model.\n",
    "    model.compile(\n",
    "        loss=HuberLoss(2.), \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[\"mae\"]\n",
    "    ) \n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    HR()\n",
    "    \n",
    "    # When you save the model, the threshold will be saved along with it.\n",
    "    print(\"Save model: chp12/my_model_with_a_custom_loss_class.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_loss_class.h5\")\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    # when you load the model, you just need to map the class name to the class itself.\n",
    "    print(\"Load model: chp12/my_model_with_a_custom_loss_class.h5\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_loss_class.h5\",\n",
    "        custom_objects={\"HuberLoss\": HuberLoss}\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    print(f\"model.loss.threshold: {model.loss.threshold}\")\n",
    "    HR()\n",
    "    \n",
    "    print(\"model.loss.get_config():\")\n",
    "    pp.pprint(model.loss.get_config())\n",
    "    \n",
    "listing4_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-INz_evZpaM"
   },
   "source": [
    "<a id='4.3'></a><a name='4.3'></a>\n",
    "## 4.3 Custom Activation Functions, Initializers, Regularizers, and Constraints\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "11OFuo_1ZpaP"
   },
   "outputs": [],
   "source": [
    "# custom activation function, equivalent to tf.nn.softplus or keras.activations.softplus)()\n",
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "# custom Glorot initializer, equivalent to keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "# custom l1 regularizer, equivalent to keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "# custom constraint that ensures weights are all positive,\n",
    "# equivalent to keras.constraints.nonneg() or tf.nn.relu()\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKI6wWy9ZpaR",
    "outputId": "5633858a-e0ba-4bbf-d21f-5544c77ef662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'activation': 'my_softplus',\n",
      "    'activity_regularizer': None,\n",
      "    'bias_constraint': None,\n",
      "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      "    'bias_regularizer': None,\n",
      "    'dtype': 'float32',\n",
      "    'kernel_constraint': 'my_positive_weights',\n",
      "    'kernel_initializer': 'my_glorot_initializer',\n",
      "    'kernel_regularizer': 'my_l1_regularizer',\n",
      "    'name': 'custom_functions_layer',\n",
      "    'trainable': True,\n",
      "    'units': 1,\n",
      "    'use_bias': True}\n"
     ]
    }
   ],
   "source": [
    "def listing4_3():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Use the custom functions on a single layer\n",
    "    layer = keras.layers.Dense(\n",
    "        1, \n",
    "        activation=my_softplus,\n",
    "        kernel_initializer=my_glorot_initializer,\n",
    "        kernel_regularizer=my_l1_regularizer,\n",
    "        kernel_constraint=my_positive_weights,\n",
    "        name=\"custom_functions_layer\"\n",
    "    )\n",
    "\n",
    "    pp.pprint(layer.get_config())\n",
    "    \n",
    "listing4_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g9YdclXMZpaS",
    "outputId": "10a2e4be-1373-4fca-801b-d246591e6aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 7ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4399 - val_mae: 0.5137\n",
      "----------------------------------------\n",
      "Save: chp12/my_model_with_many_custom_parts.h5\n",
      "32K\tdata_chp12/my_model_with_many_custom_parts.h5\n",
      "----------------------------------------\n",
      "Load: chp12/my_model_with_many_custom_parts.h5\n"
     ]
    }
   ],
   "source": [
    "def listing4_3b():\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\",\n",
    "            input_shape=X_train.shape[1:]\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            1, \n",
    "            activation=my_softplus,\n",
    "            kernel_regularizer=my_l1_regularizer,\n",
    "            kernel_constraint=my_positive_weights,\n",
    "            kernel_initializer=my_glorot_initializer\n",
    "        ),\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid)\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(\"Save: chp12/my_model_with_many_custom_parts.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_many_custom_parts.h5\")\n",
    "    !du -h {DATA_ROOT}/my_model_with_many_custom_parts.h5\n",
    "\n",
    "    HR()\n",
    "    \n",
    "    print(\"Load: chp12/my_model_with_many_custom_parts.h5\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_many_custom_parts.h5\",\n",
    "        custom_objects={\n",
    "           \"my_l1_regularizer\": my_l1_regularizer,\n",
    "           \"my_positive_weights\": my_positive_weights,\n",
    "           \"my_glorot_initializer\": my_glorot_initializer,\n",
    "           \"my_softplus\": my_softplus,\n",
    "        })\n",
    "\n",
    "listing4_3b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "567u4idxZpaS"
   },
   "source": [
    "---\n",
    "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as keras.regularizers.Regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTFdMsLkZpaT",
    "outputId": "a54e6b48-c86e-44d0-b43c-725d995f1bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.5542 - mae: 0.8962 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5943 - mae: 0.5256 - val_loss: 1.4399 - val_mae: 0.5137\n",
      "----------------------------------------\n",
      "Save: chp12/my_model_with_many_custom_parts.h5\n",
      "32K\tdata_chp12/my_model_with_many_custom_parts.h5\n",
      "----------------------------------------\n",
      "Load: chp12/my_model_with_many_custom_parts.h5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n",
    "        \n",
    "        \n",
    "def listing4_3c():\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, \n",
    "            activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\",\n",
    "            input_shape=X_train.shape[1:]\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            1, \n",
    "            activation=my_softplus,\n",
    "            kernel_regularizer=MyL1Regularizer(0.01),\n",
    "            kernel_constraint=my_positive_weights,\n",
    "            kernel_initializer=my_glorot_initializer),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid)\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(\"Save: chp12/my_model_with_many_custom_parts.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_many_custom_parts.h5\")\n",
    "    !du -h {DATA_ROOT}/my_model_with_many_custom_parts.h5\n",
    "\n",
    "    HR()\n",
    "    \n",
    "    print(\"Load: chp12/my_model_with_many_custom_parts.h5\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_many_custom_parts.h5\",\n",
    "        custom_objects={\n",
    "           \"MyL1Regularizer\": MyL1Regularizer,\n",
    "           \"my_positive_weights\": my_positive_weights,\n",
    "           \"my_glorot_initializer\": my_glorot_initializer,\n",
    "           \"my_softplus\": my_softplus,\n",
    "        })\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "listing4_3c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGpj8BGIZpaT"
   },
   "source": [
    "<a id='4.4'></a><a name='4.4'></a>\n",
    "## 4.4 Custom Metrics\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Losses and metrics are conceptually not the same thing: losses (e.g., cross entropy) are used by Gradient Descent to train a model, so they must be differentiable (at least where they are evaluated), and their gradients should not be 0 everywhere. Plus, it’s OK if they are not easily interpretable by humans. \n",
    "\n",
    "In contrast, metrics (e.g., accuracy) are used to evaluate a model: they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eD4YQR3eZpaU",
    "outputId": "1f505a94-9ffa-4305-b383-b344c4e0fbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 - 1s - loss: 2.0982 - huber_fn: 0.9192 - 1s/epoch - 4ms/step\n",
      "----------------------------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "{   'class_name': 'InputLayer',\n",
      "    'config': {   'batch_input_shape': (None, 8),\n",
      "                  'dtype': 'float32',\n",
      "                  'name': 'dense_input',\n",
      "                  'ragged': False,\n",
      "                  'sparse': False}}\n",
      "{   'class_name': 'Dense',\n",
      "    'config': {   'activation': 'selu',\n",
      "                  'activity_regularizer': None,\n",
      "                  'batch_input_shape': (None, 8),\n",
      "                  'bias_constraint': None,\n",
      "                  'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      "                  'bias_regularizer': None,\n",
      "                  'dtype': 'float32',\n",
      "                  'kernel_constraint': None,\n",
      "                  'kernel_initializer': {   'class_name': 'LecunNormal',\n",
      "                                            'config': {'seed': None}},\n",
      "                  'kernel_regularizer': None,\n",
      "                  'name': 'dense',\n",
      "                  'trainable': True,\n",
      "                  'units': 30,\n",
      "                  'use_bias': True}}\n",
      "{   'class_name': 'Dense',\n",
      "    'config': {   'activation': 'linear',\n",
      "                  'activity_regularizer': None,\n",
      "                  'bias_constraint': None,\n",
      "                  'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      "                  'bias_regularizer': None,\n",
      "                  'dtype': 'float32',\n",
      "                  'kernel_constraint': None,\n",
      "                  'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
      "                                            'config': {'seed': None}},\n",
      "                  'kernel_regularizer': None,\n",
      "                  'name': 'dense_1',\n",
      "                  'trainable': True,\n",
      "                  'units': 1,\n",
      "                  'use_bias': True}}\n"
     ]
    }
   ],
   "source": [
    "def listing4_4():\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "    input_shape = X_train.shape[1:]\n",
    "        \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, \n",
    "            activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\", \n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\", \n",
    "        # custom metric function\n",
    "        metrics=[create_huber(2.0)]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs = 1,\n",
    "        verbose = 2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    model.summary()\n",
    "        \n",
    "    # Cleaner version of model.get_config()\n",
    "    for x in model.get_config()['layers']:\n",
    "        pp.pprint(x)\n",
    "        \n",
    "listing4_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVPbrg7TZpaU"
   },
   "source": [
    "---\n",
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error).\n",
    "\n",
    "---\n",
    "\n",
    "sample_weights functionality adds more importance to some samples \n",
    "than others during training.so that the loss function used by the \n",
    "model is weighted per-sample not per class. It changes the way the \n",
    "loss is calculated.\n",
    "\n",
    "https://androidkt.com/set-sample-weight-in-keras/\n",
    "\n",
    "A “sample weights” array is an array of numbers that specify how \n",
    "much weight each sample in a batch should have in computing the \n",
    "total loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "iMv9BZwXZpaU",
    "outputId": "09d47544-6971-409d-d2bd-845d1dcaebc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(y_train): 11610\n",
      "----------------------------------------\n",
      "                  0\n",
      "count  11610.000000\n",
      "mean       0.496247\n",
      "std        0.287536\n",
      "min        0.000012\n",
      "25%        0.248310\n",
      "50%        0.494810\n",
      "75%        0.743298\n",
      "max        0.999718\n",
      "----------------------------------------\n",
      "Epoch 1/2\n",
      "363/363 - 1s - loss: 0.4455 - huber_fn: 0.8931 - 1s/epoch - 4ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.1305 - huber_fn: 0.2662 - 859ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "dict_keys(['loss', 'huber_fn'])\n",
      "----------------------------------------\n",
      "0.44554364681243896 0.4432061472773172\n",
      "----------------------------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def listing4_4b():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import pandas as pd\n",
    "    \n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, \n",
    "            activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\", \n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # Use the same function as the loss and a metric.\n",
    "    model.compile(\n",
    "        loss=create_huber(2.0), \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[create_huber(2.0)]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    sample_weight = np.random.rand(len(y_train))\n",
    "    print(f\"len(y_train): {len(y_train)}\")\n",
    "    HR()\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(sample_weight)\n",
    "    df.hist(legend=False, grid=True)\n",
    "    print(df.describe())\n",
    "    HR()\n",
    "    \n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2, \n",
    "        sample_weight=sample_weight,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(history.history.keys())\n",
    "    HR()\n",
    "    \n",
    "\n",
    "    # Show results for first epoch only\n",
    "    print(\n",
    "        history.history[\"loss\"][0], \n",
    "        history.history[\"huber_fn\"][0] * sample_weight.mean()\n",
    "    )\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    model.summary()\n",
    "        \n",
    "listing4_4b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyPCvUb1ZpaV"
   },
   "source": [
    "<a id='4.5'></a><a name='4.5'></a>\n",
    "## 4.5 Streaming Metrics\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "precision is the number of true positives divided by the number of positive predictions (including both true positives and false positives)\n",
    "\n",
    "This is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested. This is precisely what the `keras.metrics.Precision` class does:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQTYEqWqZpaV",
    "outputId": "77a027ac-6335-47e4-ed8a-933c47b44e63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standalone usage\n",
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpQSxI3AZpaW",
    "outputId": "f34dd225-ac60-4633-c4ec-22b4ecc37743"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWrNsRY5ZpaW",
    "outputId": "5c82bae7-e602-44df-8d6b-90ab99f9861f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFjMhpXoZpaW",
    "outputId": "de6f7873-7d5c-4d2b-b120-6c9a8e7a6ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "2F_tycoNZpaX"
   },
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHAxAScUZpaX",
    "outputId": "e751e09a-b91d-41ad-89c5-2fa7dc230579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'class_name': 'InputLayer',\n",
      "    'config': {   'batch_input_shape': (None, 8),\n",
      "                  'dtype': 'float32',\n",
      "                  'name': 'dense_2_input',\n",
      "                  'ragged': False,\n",
      "                  'sparse': False}}\n",
      "{   'class_name': 'Dense',\n",
      "    'config': {   'activation': 'selu',\n",
      "                  'activity_regularizer': None,\n",
      "                  'batch_input_shape': (None, 8),\n",
      "                  'bias_constraint': None,\n",
      "                  'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      "                  'bias_regularizer': None,\n",
      "                  'dtype': 'float32',\n",
      "                  'kernel_constraint': None,\n",
      "                  'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
      "                                            'config': {'seed': None}},\n",
      "                  'kernel_regularizer': None,\n",
      "                  'name': 'dense_2',\n",
      "                  'trainable': True,\n",
      "                  'units': 30,\n",
      "                  'use_bias': True}}\n",
      "{   'class_name': 'Dense',\n",
      "    'config': {   'activation': 'linear',\n",
      "                  'activity_regularizer': None,\n",
      "                  'bias_constraint': None,\n",
      "                  'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      "                  'bias_regularizer': None,\n",
      "                  'dtype': 'float32',\n",
      "                  'kernel_constraint': None,\n",
      "                  'kernel_initializer': {   'class_name': 'GlorotUniform',\n",
      "                                            'config': {'seed': None}},\n",
      "                  'kernel_regularizer': None,\n",
      "                  'name': 'dense_3',\n",
      "                  'trainable': True,\n",
      "                  'units': 1,\n",
      "                  'use_bias': True}}\n"
     ]
    }
   ],
   "source": [
    "def listing3_5_compile_api():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"selu\", input_shape=[8]),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='sgd',\n",
    "        loss='mse',\n",
    "        # Usage with compile() API:\n",
    "        metrics=[tf.keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    for x in model.get_config()['layers']:\n",
    "        pp.pprint(x)\n",
    "    \n",
    "listing3_5_compile_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-6KyCh4ZpaX"
   },
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "aXuUhSRiZpaY"
   },
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UR8l3YuTZpaY",
    "outputId": "cf7622d7-1dfb-40ed-8d34-e62032a1bda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m.result():\n",
      "tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "----------------------------------------\n",
      "m.variables:\n",
      "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>, <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]\n",
      "----------------------------------------\n",
      "Reset via m.reset_states()\n",
      "\n",
      "m.variables:\n",
      "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]\n"
     ]
    }
   ],
   "source": [
    "# Creating a streaming metric by creating a subclass of keras.metrics.Metric class.\n",
    "def listing4_5():\n",
    "    \n",
    "    m = HuberMetric(2.)\n",
    "\n",
    "    # total = 2 * |10 - 2| - 2²/2 = 14\n",
    "    # count = 1\n",
    "    # result = 14 / 1 = 14\n",
    "    m(tf.constant([[2.]]), tf.constant([[10.]])) \n",
    "\n",
    "\n",
    "    # total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "    # count = count + 2 = 3\n",
    "    # result = total / count = 21 / 3 = 7\n",
    "    m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "    print(\"m.result():\")\n",
    "    print(m.result())\n",
    "    HR()\n",
    "    \n",
    "    print(\"m.variables:\")\n",
    "    print(m.variables)\n",
    "    HR()\n",
    "    \n",
    "    m.reset_states()\n",
    "    print(\"Reset via m.reset_states()\\n\")    \n",
    "    print(\"m.variables:\")\n",
    "    print(m.variables)\n",
    "\n",
    "listing4_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_5fTC9LZpaY",
    "outputId": "27109aba-f8f9-47c4-f4e7-5fe31b1c4f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 1s - loss: 0.8707 - huber_metric: 0.8707 - 1s/epoch - 4ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.2595 - huber_metric: 0.2595 - 810ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "Saving model: chp12/my_model_with_a_custom_metric.h5\n",
      "32K\tdata_chp12/my_model_with_a_custom_metric.h5\n"
     ]
    }
   ],
   "source": [
    "# Creating a streaming metric by creating a subclass of keras.metrics.Metric class.\n",
    "def listing4_5b():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "        \n",
    "    # Let's check that the HuberMetric class works:\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            units=30, \n",
    "            activation=\"selu\", \n",
    "            kernel_initializer=\"lecun_normal\", \n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=create_huber(2.0), \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[HuberMetric(2.0)]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled.astype(np.float32), \n",
    "        y_train.astype(np.float32), \n",
    "        epochs=2,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(\"Saving model: chp12/my_model_with_a_custom_metric.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_metric.h5\")\n",
    "    !du -h {DATA_ROOT}/my_model_with_a_custom_metric.h5\n",
    "\n",
    "listing4_5b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-I2aTqAZpaZ",
    "outputId": "57c99744-e0c2-4baa-f412-e26b1126bc36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 1s - loss: 0.2350 - huber_metric: 0.2350 - 1s/epoch - 3ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.2278 - huber_metric: 0.2278 - 1s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "tf.__version__: 2.8.2\n",
      "----------------------------------------\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "def listing4_5c():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "        \n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_metric.h5\",\n",
    "        custom_objects={\n",
    "            \"huber_fn\": create_huber(2.0),\n",
    "            \"HuberMetric\": HuberMetric\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled.astype(np.float32), \n",
    "        y_train.astype(np.float32), \n",
    "        epochs=2,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    # Warning: In TF 2.2, tf.keras adds an extra first metric in \n",
    "    # model.metrics at position 0 (see TF issue #38150). This forces \n",
    "    # us to use model.metrics[-1] rather than model.metrics[0] to \n",
    "    # access the HuberMetric.\n",
    "    print(f\"tf.__version__: {tf.__version__}\")\n",
    "    HR()\n",
    "    print(model.metrics[-1].threshold)\n",
    "    \n",
    "listing4_5c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXJmDo_sZpab"
   },
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzcPgUDTZpab",
    "outputId": "16562716-b76a-4355-8296-01e3c07474a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 2s - loss: 0.4455 - HuberMetric: 0.8978 - 2s/epoch - 5ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.1305 - HuberMetric: 0.2631 - 1s/epoch - 3ms/step\n",
      "0.44554364681243896 0.44554368685750223\n",
      "Save model: chp12/my_model_with_a_custom_metric_v2.h5\n",
      "Load model: chp12/my_model_with_a_custom_metric_v2.h5\n",
      "Epoch 1/2\n",
      "363/363 - 2s - loss: 0.2377 - HuberMetric: 0.2377 - 2s/epoch - 4ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.2279 - HuberMetric: 0.2279 - 923ms/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "def listing4_5d():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    \n",
    "    # This class handles shapes better, and it also supports sample weights.\n",
    "    class HuberMetric(keras.metrics.Mean):\n",
    "        def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "            self.threshold = threshold\n",
    "            self.huber_fn = create_huber(threshold)\n",
    "            super().__init__(name=name, dtype=dtype)\n",
    "        def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "            metric = self.huber_fn(y_true, y_pred)\n",
    "            super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "        def get_config(self):\n",
    "            base_config = super().get_config()\n",
    "            return {**base_config, \"threshold\": self.threshold} \n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           input_shape=input_shape),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.Huber(2.0), \n",
    "        optimizer=\"nadam\", \n",
    "        weighted_metrics=[HuberMetric(2.0)]\n",
    "    )\n",
    "\n",
    "    sample_weight = np.random.rand(len(y_train))\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled.astype(np.float32), \n",
    "        y_train.astype(np.float32),\n",
    "        epochs=2, \n",
    "        sample_weight=sample_weight,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        history.history[\"loss\"][0], \n",
    "        history.history[\"HuberMetric\"][0] * sample_weight.mean()\n",
    "    )\n",
    "    \n",
    "    print(\"Save model: chp12/my_model_with_a_custom_metric_v2.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_metric_v2.h5\")\n",
    "\n",
    "    \n",
    "    print(\"Load model: chp12/my_model_with_a_custom_metric_v2.h5\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_metric_v2.h5\",\n",
    "        custom_objects={\"HuberMetric\": HuberMetric}\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled.astype(np.float32), \n",
    "        y_train.astype(np.float32), \n",
    "        epochs=2,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(model.metrics[-1].threshold)\n",
    "\n",
    "listing4_5d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQujIFA5Zpae"
   },
   "source": [
    "<a id='4.6'></a><a name='4.6'></a>\n",
    "## 4.6 Custom Layers\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GznpH5y7Zpaf"
   },
   "source": [
    "<a id='4.6.1'></a><a name='4.6.1'></a>\n",
    "### 4.6.1 Custom Layers: Layers with no weights\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Some layers have no weights, such as `keras.layers.Flatten` or `keras.layers.ReLU`. If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a `keras.layers.Lambda` layer. For example, the following layer will apply the exponential function to its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gorzwzs3Zpaf",
    "outputId": "cfe32541-9b6b-45a3-c2cd-96bd94525051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.36787948 1.         2.7182817 ], shape=(3,), dtype=float32)\n",
      "----------------------------------------\n",
      "{   'arguments': {},\n",
      "    'dtype': 'float32',\n",
      "    'function': (   '4wEAAAAAAAAAAQAAAAMAAABTAAAAcwoAAAB0AKABfAChAVMAKQFOKQLaAnRm2gNleHApAdoBeKkA\\n'\n",
      "                    'cgQAAAD6HzxpcHl0aG9uLWlucHV0LTg1LWY3M2NkNjdkNTkyNT7aCDxsYW1iZGE+IQAAAPMAAAAA\\n',\n",
      "                    None,\n",
      "                    None),\n",
      "    'function_type': 'lambda',\n",
      "    'module': '__main__',\n",
      "    'name': 'lambda',\n",
      "    'output_shape': None,\n",
      "    'output_shape_module': None,\n",
      "    'output_shape_type': 'raw',\n",
      "    'trainable': True}\n",
      "----------------------------------------\n",
      "Epoch 1/5\n",
      "363/363 - 1s - loss: 1.0631 - val_loss: 0.4457 - 1s/epoch - 3ms/step\n",
      "Epoch 2/5\n",
      "363/363 - 1s - loss: 0.4562 - val_loss: 0.3798 - 954ms/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "363/363 - 1s - loss: 0.4029 - val_loss: 0.3548 - 828ms/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "363/363 - 1s - loss: 0.3851 - val_loss: 0.3464 - 790ms/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "363/363 - 1s - loss: 0.3708 - val_loss: 0.3449 - 823ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.3586 - 229ms/epoch - 1ms/step\n",
      "----------------------------------------\n",
      "[test loss, test accuracy]: 0.3586340844631195\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def listing4_6_1():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    \n",
    "    exponential_layer = keras.layers.Lambda(\n",
    "        lambda x: tf.exp(x)\n",
    "    )\n",
    "    \n",
    "    print(exponential_layer([-1., 0., 1.]))\n",
    "    HR()\n",
    "    \n",
    "    pp.pprint(exponential_layer.get_config())\n",
    "    HR()\n",
    "    \n",
    "    \n",
    "    # Adding an exponential layer at the output of a \n",
    "    # regression model can be useful if the values to \n",
    "    # predict are positive and with very different \n",
    "    # scales (e.g., 0.001, 10., 10000):\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "        keras.layers.Dense(1),\n",
    "        exponential_layer\n",
    "    ])\n",
    "    model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=5,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "    HR()\n",
    "    \n",
    "listing4_6_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE1uzC-0Zpag"
   },
   "source": [
    "<a id='4.6.2'></a><a name='4.6.2'></a>\n",
    "### 4.6.2 Custom Layers: Layers containing weights\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "To build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of the `keras.layers.Layer` class. For example, the following class implements a simplified version of the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "GT8RIrD0Zpag"
   },
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config, \n",
    "            \"units\": self.units,\n",
    "            \"activation\": keras.activations.serialize(self.activation)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOOlRm-9Zpag",
    "outputId": "8baee5ba-4b1c-438f-dd96-395089c43377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 2s - loss: 2.2563 - val_loss: 0.9472 - 2s/epoch - 5ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.6485 - val_loss: 0.6219 - 1s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.5474 - 236ms/epoch - 1ms/step\n",
      "Save: chp12/my_model_with_a_custom_layer.h5\n",
      "----------------------------------------\n",
      "Load: chp12/my_model_with_a_custom_layer.h5\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_dense (MyDense)          (None, 30)                270       \n",
      "                                                                 \n",
      " my_dense_1 (MyDense)        (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def listing4_6_2():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "        \n",
    "    model = keras.models.Sequential([\n",
    "        MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "        MyDense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "    print(\"Save: chp12/my_model_with_a_custom_layer.h5\")\n",
    "    model.save(f\"{DATA_ROOT}/my_model_with_a_custom_layer.h5\")\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    print(\"Load: chp12/my_model_with_a_custom_layer.h5\")\n",
    "    model = keras.models.load_model(\n",
    "        f\"{DATA_ROOT}/my_model_with_a_custom_layer.h5\",\n",
    "        custom_objects={\"MyDense\": MyDense}\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "listing4_6_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSAICumoZpah"
   },
   "source": [
    "<a id='4.6.3'></a><a name='4.6.3'></a>\n",
    "### 4.6.3 Custom Layers: Layer with multiple inputs\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "FcfBXCkKZpai"
   },
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxHkR7koZpai",
    "outputId": "b68de922-89bc-4269-f98b-2b7f0f9b1a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# Our custom layer can be called using the functional API like this:\n",
    "\n",
    "# Note that the call() method receives symbolic inputs, \n",
    "# whose shape is only partially specified (at this stage, \n",
    "# we don't know the batch size, which is why the first dimension \n",
    "# is None)\n",
    "\n",
    "def listing4_6_3_test1():\n",
    "    inputs1 = keras.layers.Input(shape=[2])\n",
    "    inputs2 = keras.layers.Input(shape=[2])\n",
    "    outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))\n",
    "\n",
    "listing4_6_3_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "ifA40w_EZpai"
   },
   "outputs": [],
   "source": [
    "# We can also pass actual data to the custom layer. \n",
    "# To test this, let's split each dataset's inputs into two parts, \n",
    "# with four features each:\n",
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51ZNc4ndZpak",
    "outputId": "579f6a78-f499-4cca-a629-683988250fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 4) (11610, 4)\n",
      "----------------------------------------\n",
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n",
      "tf.Tensor(\n",
      "[[-0.17324547 -1.6507294  -0.01412493 -1.4073021 ]\n",
      " [ 2.6134481  -1.6637297  -0.5110694   0.86339283]\n",
      " [-0.5025582  -0.27013135  2.1268167  -0.6402433 ]\n",
      " ...\n",
      " [-0.7709261   0.6388412  -1.2357894   1.4055338 ]\n",
      " [-0.9933209   1.8356445   0.41289914 -0.16435926]\n",
      " [ 0.7240328   0.00968345  1.4208122  -1.4639156 ]], shape=(11610, 4), dtype=float32)\n",
      "----------------------------------------\n",
      "tf.Tensor(\n",
      "[[-0.00402183  0.61749667 -0.8766508  -0.02112347]\n",
      " [ 1.3997903  -0.38343248 -0.37163973 -0.2558276 ]\n",
      " [ 0.03643769 -0.00890543  1.0706553  -1.7933904 ]\n",
      " ...\n",
      " [-0.5534281   0.0678305   0.371412    0.29685235]\n",
      " [ 0.05403009 -0.02504723 -0.0567511   0.0063295 ]\n",
      " [-0.15393297 -0.03349337  0.3358127   0.2048483 ]], shape=(11610, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def listing4_6_3_test2():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "        \n",
    "    X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "    X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "    X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "    # Printing the splitted data shapes\n",
    "    print(X_train_scaled_A.shape, X_train_scaled_B.shape)\n",
    "    HR()\n",
    "    \n",
    "    # Now notice that the shapes are fully specified:\n",
    "    outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))\n",
    "    print(outputs1)\n",
    "    HR()\n",
    "    \n",
    "    print(outputs2)\n",
    "    \n",
    "listing4_6_3_test2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-27b3rKJZpal"
   },
   "source": [
    "Let's build a more complete model using the functional API (this is just a toy example, don't expect awesome performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFZaiTsiZpal",
    "outputId": "9680a069-705d-4e58-e739-489cf50b1b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "----------------------------------------\n",
      "Fit the model:\n",
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 - 2s - loss: 2.1142 - val_loss: 1.3630 - 2s/epoch - 6ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.9684 - val_loss: 0.9773 - 1s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "----------------------------------------\n",
      "Evaluate the model:\n",
      "121/121 - 0s - loss: 0.9773 - 204ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "[test loss, test accuracy]: 0.9772732853889465\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a more complete model using the functional API. This is just a toy example.\n",
    "\n",
    "def listing4_6_3():\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "    X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "    X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "    \n",
    "    input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "    input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "    hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "    hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "    hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "    concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "    output = keras.layers.Dense(1)(concat)\n",
    "    model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "\n",
    "    model.compile(loss='mse', optimizer='nadam')\n",
    "\n",
    "    HR()\n",
    "    \n",
    "    print(\"Fit the model:\")\n",
    "    hist = model.fit(\n",
    "        (X_train_scaled_A, X_train_scaled_B), \n",
    "        y_train, epochs=2,\n",
    "        validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(hist.history.keys())\n",
    "    HR()\n",
    "    \n",
    "    print(\"Evaluate the model:\")\n",
    "    eval_result = model.evaluate(\n",
    "        (X_valid_scaled_A, X_valid_scaled_B), \n",
    "        y_valid,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(\"[test loss, test accuracy]:\", eval_result)\n",
    "    HR()\n",
    "    \n",
    "listing4_6_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "RgHeBcudZpam"
   },
   "outputs": [],
   "source": [
    "# Now let's create a layer with a different behavior during training and testing:\n",
    "# This is called 'MyGaussianNoise' in the book\n",
    "\n",
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuLbar7zZpam"
   },
   "source": [
    "Here's a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_YVBAowZpam",
    "outputId": "6cf02bc4-141f-484f-eaa6-7948b1e0890d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 2s - loss: 2.3857 - accuracy: 0.0022 - val_loss: 7.6082 - val_accuracy: 0.0044 - 2s/epoch - 6ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 1.0571 - accuracy: 0.0029 - val_loss: 4.4597 - val_accuracy: 0.0044 - 1s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.7560 - accuracy: 0.0021 - 252ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "eval result (loss): 0.7559615969657898\n",
      "eval result (accuraacy): 0.0021317829377949238\n"
     ]
    }
   ],
   "source": [
    "# Here's a simple model that uses this custom layer:\n",
    "def listing4_6_3b():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "    X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "    X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        AddGaussianNoise(stddev=1.0),\n",
    "        keras.layers.Dense(30, activation=\"selu\"),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    hist = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(hist.history.keys())\n",
    "    HR()\n",
    "        \n",
    "    # Try to always use return_dict=True, so we can get a \n",
    "    # clearer specification of what's returned.\n",
    "    eval_result = model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test,\n",
    "        verbose=2,\n",
    "        return_dict=True\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(f\"eval result (loss): {eval_result['loss']}\")\n",
    "    print(f\"eval result (accuraacy): {eval_result['accuracy']}\")\n",
    "    \n",
    "listing4_6_3b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLyGPiCFZpan"
   },
   "source": [
    "<a id='4.7'></a><a name='4.7'></a>\n",
    "## 4.7 Custom Models\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Creating custom model classes is straightforward: subclass the\n",
    "class, create layers and variables in the constructor. Then \n",
    "implement the method to do whatever you want the model to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "FSBrSJrgZpan"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n",
    "\n",
    "\n",
    "# Use Subclassing API to define model\n",
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTbGe5kHZpan",
    "outputId": "ed278a66-b0b8-42e6-8409-12a9732764cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 - 3s - loss: 9.1325 - accuracy: 0.0020 - 3s/epoch - 8ms/step\n",
      "Epoch 2/5\n",
      "363/363 - 2s - loss: 1.0578 - accuracy: 0.0026 - 2s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "363/363 - 1s - loss: 0.8869 - accuracy: 0.0026 - 1s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "363/363 - 3s - loss: 0.5831 - accuracy: 0.0026 - 3s/epoch - 7ms/step\n",
      "Epoch 5/5\n",
      "363/363 - 3s - loss: 0.6463 - accuracy: 0.0025 - 3s/epoch - 7ms/step\n",
      "----------------------------------------\n",
      "162/162 - 1s - loss: 0.6513 - accuracy: 0.0019 - 786ms/epoch - 5ms/step\n",
      "----------------------------------------\n",
      "eval result (loss): 0.6512573957443237\n",
      "eval result (accuraacy): 0.0019379844889044762\n",
      "----------------------------------------\n",
      "Save model: chp12/my_custom_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data_chp12/my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data_chp12/my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Load model: chp12/my_custom_model.ckpt\n",
      "Epoch 1/5\n",
      "363/363 - 3s - loss: 0.8017 - accuracy: 0.0027 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "363/363 - 2s - loss: 0.5028 - accuracy: 0.0028 - 2s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "363/363 - 2s - loss: 0.5362 - accuracy: 0.0027 - 2s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "363/363 - 2s - loss: 0.4120 - accuracy: 0.0028 - 2s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "363/363 - 2s - loss: 0.5718 - accuracy: 0.0028 - 2s/epoch - 4ms/step\n",
      "----------------------------------------\n",
      "dict_keys(['loss', 'accuracy'])\n",
      "----------------------------------------\n",
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  270       \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 1860      \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 1860      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def listing4_7():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    X_new_scaled = X_test_scaled\n",
    "\n",
    "    model = ResidualRegressor(1)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=5,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test,\n",
    "        verbose=2,\n",
    "        return_dict=True,\n",
    "    )\n",
    "    HR()\n",
    "        \n",
    "    print(f\"eval result (loss): {eval_result['loss']}\")\n",
    "    print(f\"eval result (accuraacy): {eval_result['accuracy']}\")\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    y_pred = model.predict(X_new_scaled)\n",
    "\n",
    "    print(\"Save model: chp12/my_custom_model.ckpt\")\n",
    "    model.save(f\"{DATA_ROOT}/my_custom_model.ckpt\")\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    print(\"Load model: chp12/my_custom_model.ckpt\")\n",
    "    model = keras.models.load_model(f\"{DATA_ROOT}/my_custom_model.ckpt\")\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=5,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    HR()\n",
    "    model.summary()\n",
    "    \n",
    "listing4_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gh1AUahMZpao",
    "outputId": "252809b6-88c9-42e4-af0c-6f3f06d43cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 - 3s - loss: 0.8695 - accuracy: 0.0025 - 3s/epoch - 9ms/step\n",
      "Epoch 2/5\n",
      "363/363 - 1s - loss: 0.4720 - accuracy: 0.0028 - 1s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "363/363 - 1s - loss: 0.5537 - accuracy: 0.0028 - 1s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "363/363 - 1s - loss: 0.3809 - accuracy: 0.0028 - 1s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "363/363 - 1s - loss: 0.4012 - accuracy: 0.0028 - 1s/epoch - 4ms/step\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.4852 - accuracy: 0.0021 - 363ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "eval result (loss): 0.4851548671722412\n",
      "eval result (accuraacy): 0.0021317829377949238\n",
      "----------------------------------------\n",
      "y_pred: [[0.49208224]\n",
      " [1.7723728 ]\n",
      " [4.461338  ]\n",
      " ...\n",
      " [1.6717831 ]\n",
      " [2.3763793 ]\n",
      " [4.5635967 ]]\n",
      "----------------------------------------\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  (None, 30)               1860      \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  (None, 30)               1860      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Save model: chp12/my_custom_model_sequential.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data_chp12/my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data_chp12/my_custom_model.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start new...\n",
      "Load model: chp12/my_custom_model_sequential.ckpt\n",
      "y_pred: [[0.49208224]\n",
      " [1.7723728 ]\n",
      " [4.461338  ]\n",
      " ...\n",
      " [1.6717831 ]\n",
      " [2.3763793 ]\n",
      " [4.5635967 ]]\n"
     ]
    }
   ],
   "source": [
    "def listing4_7b():\n",
    "# We could have defined the model using the sequential API instead:\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    X_new_scaled = X_test_scaled\n",
    "    \n",
    "    block1 = ResidualBlock(2, 30)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "        block1, \n",
    "        block1, \n",
    "        block1, \n",
    "        block1,\n",
    "        ResidualBlock(2, 30),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=5,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    eval_result = model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test,\n",
    "        verbose=2,\n",
    "        return_dict=True\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(f\"eval result (loss): {eval_result['loss']}\")\n",
    "    print(f\"eval result (accuraacy): {eval_result['accuracy']}\")\n",
    "        \n",
    "    HR()\n",
    "    \n",
    "    y_pred = model.predict(X_new_scaled)\n",
    "    print(f\"y_pred: {y_pred}\")\n",
    "    \n",
    "    HR()\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Save model: chp12/my_custom_model_sequential.ckpt\")\n",
    "    model.save(f\"{DATA_ROOT}/my_custom_model.ckpt\")\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    print(\"Start new...\")\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    print(\"Load model: chp12/my_custom_model_sequential.ckpt\")\n",
    "    model = keras.models.load_model(f\"{DATA_ROOT}/my_custom_model.ckpt\")\n",
    "    \n",
    "    \n",
    "    # Do we really to refit this model? Most likely not!\n",
    "    \n",
    "    # history = model.fit(\n",
    "    #     X_train_scaled, \n",
    "    #     y_train, \n",
    "    #     epochs=5,\n",
    "    #     verbose=2\n",
    "    # )\n",
    "    # HR()\n",
    "    # print(history.history.keys())\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_new_scaled)\n",
    "    print(f\"y_pred: {y_pred}\")\n",
    "        \n",
    "listing4_7b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDBQjMm-Zpao"
   },
   "source": [
    "<a id='4.8'></a><a name='4.8'></a>\n",
    "## 4.8 Losses and Metrics Based on Model Internals\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S8f7wEjZpap"
   },
   "source": [
    "**Note**: \n",
    "\n",
    "The following code has two differences with the code in the book:\n",
    "1. It creates a `keras.metrics.Mean()` metric in the constructor and uses it in the `call()` method to track the mean reconstruction loss. Since we only want to do this during training, we add a `training` argument to the `call()` method, and if `training` is `True`, then we update `reconstruction_mean` and we call `self.add_metric()` to ensure it's displayed properly.\n",
    "2. Due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), we must not call `super().build()` inside the `build()` method.\n",
    "\n",
    "---\n",
    "\n",
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model.\n",
    "\n",
    "To define a custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the `add_loss()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "wTlV0tboZpap"
   },
   "outputs": [],
   "source": [
    "# Custom model with a custom reconstruction loss\n",
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unljCzw0Zpap",
    "outputId": "ddba9ba4-d59f-4f8d-e0b7-e13a82e88399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 - 3s - loss: 0.7886 - accuracy: 0.0029 - reconstruction_error: 1.0473 - 3s/epoch - 8ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 2s - loss: 0.4134 - accuracy: 0.0029 - reconstruction_error: 0.4013 - 2s/epoch - 4ms/step\n",
      "----------------------------------------\n",
      "dict_keys(['loss', 'accuracy', 'reconstruction_error'])\n",
      "121/121 - 0s - loss: 1.0159 - accuracy: 0.0044 - reconstruction_error: 0.0000e+00 - 337ms/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "eval result (loss): 1.0159374475479126\n",
      "eval result (accuraacy): 0.004392764996737242\n",
      "----------------------------------------\n",
      "y_pred: [[0.87845206]\n",
      " [1.5451547 ]\n",
      " [3.9395456 ]\n",
      " ...\n",
      " [1.4461813 ]\n",
      " [2.4412837 ]\n",
      " [4.091943  ]]\n"
     ]
    }
   ],
   "source": [
    "def listing4_8():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    model = ReconstructingRegressor(1)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=\"nadam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(history.history.keys())\n",
    "    \n",
    "    eval_result = model.evaluate(\n",
    "        X_valid_scaled, \n",
    "        y_valid,\n",
    "        verbose=2,\n",
    "        return_dict=True\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    print(f\"eval result (loss): {eval_result['loss']}\")\n",
    "    print(f\"eval result (accuraacy): {eval_result['accuracy']}\")\n",
    "        \n",
    "    HR()\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"y_pred: {y_pred}\")\n",
    "\n",
    "listing4_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZiL07A5Zpaq"
   },
   "source": [
    "<a id='4.9'></a><a name='4.9'></a>\n",
    "## 4.9 Computing Gradients with Autodiff\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "No real end-to-end models here, just examples of functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "mN4fgXMRZpaq"
   },
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxwOp1dIZpaq",
    "outputId": "62f9c98c-6dec-47df-d422-8c83b0546565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RX_HQIAZZpar",
    "outputId": "5a3cce37-3104-4dfc-ad2c-17b4224b860d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "VvFyT5FlZpar"
   },
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPQGZLUMZpar",
    "outputId": "22257ec1-f1e3-4464-ae8a-f6c0c44fe6a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2I90ugbXZpas",
    "outputId": "eb1caa68-eedb-4c55-d347-7264d941c780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "j4vr4GuTZpas"
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poKkFixFZpau",
    "outputId": "d929ece7-c224-4d88-a071-2e6d9479ccdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "9WYxjCirZpau"
   },
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ul4h5JlqZpav",
    "outputId": "07e6ec8d-8544-4e37-d88f-8f844fff5d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "6V2vhvXRZpav"
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XpYRluBZpav",
    "outputId": "762215ba-1c29-4b25-8a66-2ef41d360c2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHC3psXcZpaw",
    "outputId": "097811aa-3301-4e68-c644-bdcc36a58fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "lv7PUEcCZpaw"
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "AB5R8xA0Zpaw"
   },
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-6wQBwYZpaw",
    "outputId": "30a71b77-bd30-4b31-9697-2182710ce709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2KCvn_LxZpax",
    "outputId": "9f6935e7-679a-4897-e859-5f019fd181ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6BbVsppZpax",
    "outputId": "1cc209ac-b33b-48ce-d6d1-102594d41b04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgPWgvMqZpax",
    "outputId": "3822811e-e857-4008-de18-5f03b02caa91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3-2E59MZpax",
    "outputId": "3739d303-1859-47e1-e2a4-5b4326c12f5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbfN9kuvZpax",
    "outputId": "c2e38d95-ce6a-41a7-b91a-e5d93ab5f9c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "GlEDySsLZpax"
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "tcHkqRYeZpay"
   },
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsNG4xi5Zpay",
    "outputId": "7561dfe5-6b01-44ae-b512-c670f9bd9029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-_IUD_SZpay"
   },
   "source": [
    "<a id='4.10'></a><a name='4.10'></a>\n",
    "## 4.10 Custom Training Loops\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDwcY4l9Zpay",
    "outputId": "7d39532b-f4ef-4aa1-861d-94853db3bd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "def listing4_10():\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "    \n",
    "    l2_reg = keras.regularizers.l2(0.05)\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg\n",
    "        ),\n",
    "        keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "    ])\n",
    "\n",
    "    def random_batch(X, y, batch_size=32):\n",
    "        idx = np.random.randint(len(X), size=batch_size)\n",
    "        return X[idx], y[idx]\n",
    "\n",
    "    def print_status_bar(iteration, total, loss, metrics=None):\n",
    "        metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                             for m in [loss] + (metrics or [])])\n",
    "        end = \"\" if iteration < total else \"\\n\"\n",
    "        print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "              end=end)\n",
    "\n",
    "    import time\n",
    "\n",
    "    mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "    mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "    for i in range(1, 50 + 1):\n",
    "        loss = 1 / i\n",
    "        mean_loss(loss)\n",
    "        mean_square(i ** 2)\n",
    "        print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "listing4_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "BxcbUkVbZpaz"
   },
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RgXsdmUZpa0",
    "outputId": "d7b95099-ca8c-4ea9-af0f-80c8d06cfd4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "# A fancier version with a progress bar.\n",
    "def listing4_10b():\n",
    "\n",
    "    import time\n",
    "        \n",
    "    progress_bar(3500, 10000, size=6)\n",
    "\n",
    "    mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "    mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "    for i in range(1, 50 + 1):\n",
    "        loss = 1 / i\n",
    "        mean_loss(loss)\n",
    "        mean_square(i ** 2)\n",
    "        print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "        time.sleep(0.05)\n",
    "\n",
    "listing4_10b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780,
     "referenced_widgets": [
      "5e6ea399bab6447dafcdda568ab309c3",
      "b6d333a0517743109559d35c66aab373",
      "04c7dbffa4874fdf850fe366deb93765",
      "2ac2de18ce0444ec909b681ca6c478b7",
      "e173011b22bb42c98299ba6cf08b9d06",
      "c151a92a58a3489fae3ad03d857d1621",
      "633c18bca02446d3bc2711dc7173e4e1",
      "dd751308a1964eb99ef27035ce6db92f",
      "6b505021892f4f48ba7fc134a3296292",
      "e7ed6ba0c5434424b4f1cfaa31980b4e",
      "883155696d634763800b25a854101dd1",
      "57c8958a639b47a7aa9f71125de1120d",
      "382ef5be5409462181141dc0741d51eb",
      "66c452b137a6408489646762f501a3dd",
      "9cc5eb5c3e6546059be07c9a3aaad054",
      "2ca723ae285f4a86bdcdbc973a716ae8",
      "7a3699316dfa4643918b58f37dbe356b",
      "982f23a445c14d6884fd40ded5be273f",
      "4657fafecfb64b6a9a96f1f6b4b77a59",
      "12d9b1d146e74366a44c5f419f7053d9",
      "6c8cae0169114ec793fe616cf9b9ac5f",
      "36c4bf42815f47e2aef0615c5c492151",
      "2b520020fe244fbdb67f0c3e2a99b385",
      "27c431e5a98b47e6b01bd494baf03334",
      "63281dd48c5f45889c26137aa6a05c37",
      "348bd7073fb147cd91b2a8640bc6d533",
      "a90fa008d4a6470b96a6178408e7c3cb",
      "30b5dd4180b246e29f022500b920b94e",
      "76805a9ff7dc453eafb79689c7b75509",
      "18bd86442f33480a9ad9f5b5d7465e12",
      "6e590534440b4ebfa5c58af48d95ee6c",
      "efa2993512f543079a700e533fd8f856",
      "d0f52524ff3d4d0d99e0f6724586008c",
      "ff4bfae5b356449d93d821bef7c08373",
      "9658900bb988430398208fa658e6a32a",
      "7c5380f4f9684d42bf7f329fbb8af2d8",
      "547e72e3cfee43ee9f9d5bd5358ef295",
      "81b7e6eb90fc43e19b1029840ac69a38",
      "efa19e6d6c894e26a464a7a7445558a7",
      "6dbfb853e68b4d63bfec18880d55027e",
      "aa1901562bba4394ae3dce0edbee1226",
      "f4cce90d1256456a98f8315869d39365",
      "97dee864b9f3469baf0c12fbdcf156eb",
      "cf7fc8151f4b45d9b65bd66d95820f9a",
      "d25addabbb89476aa522cb5dab384e4a",
      "88d8832445bc45a5b86e97545b780f37",
      "898f13138e1647c49e1a542f725c16b7",
      "ffa37d8ed7be4417884979059ff4ce2d",
      "d3589ddd6fbf4db4877adb1aee8f8b69",
      "ab80b8374c854afe80e1553f43187ea2",
      "4f872850a85344729720e2e8cf9adc06",
      "b0eafb9fba49484da46daf2dcc5fd404",
      "5beb87ec9db84c10ad61f4600da1269e",
      "28ef3da02a8440cbb39c028126356aea",
      "7c84558f8fc44d34971f3820dda97fbf",
      "2da3fdd7ee4c4b21ad28d3758c46ee90",
      "f3a5becfa716407b8e0ed2839a8b170f",
      "acf67200c50746a5ada30c7691cb4ca6",
      "db19a0fab6cc4957aa8e086bc12d5fbd",
      "0ff8cab6f1b446348c20a7c10e916c7f",
      "9a2e9a5e0097417a972c636b5e69e59e",
      "6026a582fca7484c9fc004ffc9feda4c",
      "1721781396f4489eb3b504d24b6054ae",
      "07a4e69105004890a70ddff05961292b",
      "0cb76d7074f64de0a91c14a1b57612d9",
      "746e431448f644bf8401ac79560a30e3"
     ]
    },
    "id": "h3qAvlofZpa0",
    "outputId": "69b140f2-bcd3-48ad-af02-f1e5d322c072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.3955 - mean_absolute_error: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6774 - mean_absolute_error: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6351 - mean_absolute_error: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6384 - mean_absolute_error: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6440 - mean_absolute_error: 0.5222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6ea399bab6447dafcdda568ab309c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c8958a639b47a7aa9f71125de1120d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b520020fe244fbdb67f0c3e2a99b385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4bfae5b356449d93d821bef7c08373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25addabbb89476aa522cb5dab384e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da3fdd7ee4c4b21ad28d3758c46ee90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (32, 30)                  270       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 1)                   31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model with a custom-loop\n",
    "def listing4_10c():\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "    \n",
    "    l2_reg = keras.regularizers.l2(0.05)\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2_reg),\n",
    "        keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "    ])\n",
    "    \n",
    "    n_epochs = 5\n",
    "    batch_size = 32\n",
    "    n_steps = len(X_train) // batch_size\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "    loss_fn = keras.losses.mean_squared_error\n",
    "    mean_loss = keras.metrics.Mean()\n",
    "    metrics = [keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "        for step in range(1, n_steps + 1):\n",
    "            X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X_batch)\n",
    "                main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                loss = tf.add_n([main_loss] + model.losses)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            for variable in model.variables:\n",
    "                if variable.constraint is not None:\n",
    "                    variable.assign(variable.constraint(variable))\n",
    "            mean_loss(loss)\n",
    "            for metric in metrics:\n",
    "                metric(y_batch, y_pred)\n",
    "            print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "        print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    try:\n",
    "        from tqdm.notebook import trange\n",
    "        from collections import OrderedDict\n",
    "        with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "            for epoch in epochs:\n",
    "                with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                    for step in steps:\n",
    "                        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                        with tf.GradientTape() as tape:\n",
    "                            y_pred = model(X_batch)\n",
    "                            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                            loss = tf.add_n([main_loss] + model.losses)\n",
    "                        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                        for variable in model.variables:\n",
    "                            if variable.constraint is not None:\n",
    "                                variable.assign(variable.constraint(variable))                    \n",
    "                        status = OrderedDict()\n",
    "                        mean_loss(loss)\n",
    "                        status[\"loss\"] = mean_loss.result().numpy()\n",
    "                        for metric in metrics:\n",
    "                            metric(y_batch, y_pred)\n",
    "                            status[metric.name] = metric.result().numpy()\n",
    "                        steps.set_postfix(status)\n",
    "                for metric in [mean_loss] + metrics:\n",
    "                    metric.reset_states()\n",
    "    except ImportError as ex:\n",
    "        print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "listing4_10c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhBSf5teZpa0"
   },
   "source": [
    "---\n",
    "<a id='5.0'></a><a name='5.0'></a>\n",
    "# 5. TensorFlow Functions and Graphs\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vasudXrUZpa1"
   },
   "source": [
    "<a id='5.1'></a><a name='5.1'></a>\n",
    "## 5.1 TensorFlow Functions \n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Using `tf.function()`\n",
    "\n",
    "Convert Python function to TensorFlow function via tf.function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud8ckJGIZpa1",
    "outputId": "54349174-fefb-41ca-b26e-7a2e86df019e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cube(2): 8\n",
      "----------------------------------------\n",
      "cube(tf.constant(2.0)): 8.0\n",
      "----------------------------------------\n",
      "tf_cube (converted to TF Function via tf.function()):\n",
      "<tensorflow.python.eager.def_function.Function object at 0x7f88d30a6650>\n",
      "----------------------------------------\n",
      "tf_cube(2): 8\n",
      "----------------------------------------\n",
      "tf_cube(tf.constant(2.0)): 8.0\n",
      "----------------------------------------\n",
      "tf_cube_decorated (converted to TF Function via @tf.function decorator):\n",
      "<tensorflow.python.eager.def_function.Function object at 0x7f88d330a910>\n",
      "----------------------------------------\n",
      "tf_cube_decorated(2): 8\n",
      "----------------------------------------\n",
      "View the generated TF Function's source code for tf_cube:\n",
      "\n",
      "def tf__cube(x):\n",
      "    with ag__.FunctionScope('cube', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = (ag__.ld(x) ** 3)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python function\n",
    "def cube(x):\n",
    "    return x ** 3\n",
    "    \n",
    "    \n",
    "def listing5_1():\n",
    "\n",
    "    print(f\"cube(2): {cube(2)}\")\n",
    "    HR()\n",
    "\n",
    "    print(f\"cube(tf.constant(2.0)): {cube(tf.constant(2.0))}\")\n",
    "    HR()\n",
    "    \n",
    "    # Convert to a TensorFlow function\n",
    "    tf_cube = tf.function(cube)\n",
    "    \n",
    "    print(\"tf_cube (converted to TF Function via tf.function()):\")\n",
    "    print(tf_cube)\n",
    "    HR()\n",
    "    \n",
    "    print(f\"tf_cube(2): {tf_cube(2)}\")\n",
    "    HR()\n",
    "    \n",
    "    print(f\"tf_cube(tf.constant(2.0)): {tf_cube(tf.constant(2.0))}\")\n",
    "    HR()\n",
    "    \n",
    "    @tf.function\n",
    "    def tf_cube_decorated(x):\n",
    "        return x ** 3\n",
    "    \n",
    "    print(\"tf_cube_decorated (converted to TF Function via @tf.function decorator):\")\n",
    "    print(tf_cube_decorated)\n",
    "    HR()\n",
    "    \n",
    "    print(f\"tf_cube_decorated(2): {tf_cube_decorated(2)}\")\n",
    "    HR()\n",
    "    \n",
    "    print(\"View the generated TF Function's source code for tf_cube:\\n\")\n",
    "    print(tf.autograph.to_code(tf_cube.python_function))\n",
    "    \n",
    "listing5_1()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWHeEGUSZpa1",
    "tags": []
   },
   "source": [
    "<a id='5.2'></a><a name='5.2'></a>\n",
    "## 5.2 TF Functions and Concrete Functions \n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Using `GenericFunction.get_concrete_function()`\n",
    "\n",
    "Material from Appendix G. TensorFlow Graphs\n",
    "\n",
    "Every time a function is traced, a new concrete function is created. You can directly obtain a concrete function, by using `GenericFunction.get_concrete_function()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggycmqFVZpa1",
    "outputId": "9a090652-ebd2-4778-e042-03140668c7dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction cube(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "----------------------------------------\n",
      "FuncGraph(name=cube, id=140225632721616)\n",
      "----------------------------------------\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "----------------------------------------\n",
      "True\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def listing5_2():\n",
    "    \n",
    "    # Run only the tracing stage with .get_concrete_function.\n",
    "    tf_cube = tf.function(cube)\n",
    "    concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "    \n",
    "    print(concrete_function)\n",
    "    HR()\n",
    "    \n",
    "    print(concrete_function.graph)\n",
    "    HR()\n",
    "    \n",
    "    print(concrete_function(tf.constant(2.0)))\n",
    "    HR()\n",
    "\n",
    "    print(concrete_function is tf_cube.get_concrete_function(tf.constant(2.0)))\n",
    "    HR()\n",
    "    \n",
    "listing5_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unhClAitZpa2"
   },
   "source": [
    "<a id='5.3'></a><a name='5.3'></a>\n",
    "## 5.3 Exploring Function Definitions and Graphs\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Material from Appendix G. TensorFlow Graphs\n",
    "\n",
    "You can access a concrete function’s computation graph using the `graph` attribute, and get the list of its operations by calling the graph’s `get_operations()` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-PgO2LPZpa2"
   },
   "source": [
    "<a id='5.3.1'></a><a name='5.3.1'></a>\n",
    "### 5.3.1 Get list of graph operations via `get_operations()`\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q5aGz9NZpa2",
    "outputId": "c4f08684-a787-4328-8df1-e342676469dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   <tf.Operation 'x' type=Placeholder>,\n",
      "    <tf.Operation 'pow/y' type=Const>,\n",
      "    <tf.Operation 'pow' type=Pow>,\n",
      "    <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "def listing5_3_1():\n",
    "    \n",
    "    tf_cube = tf.function(cube)\n",
    "    concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "\n",
    "    ops = concrete_function.graph.get_operations()\n",
    "    pp.pprint(ops)\n",
    "    \n",
    "listing5_3_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eegUYsPZpa2"
   },
   "source": [
    "<a id='5.3.2'></a><a name='5.3.2'></a>\n",
    "### 5.3.2 Get the list of inputs and outputs of the power operation\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6L0l_r9eZpa2",
    "outputId": "765b4550-108d-4d20-ce4a-e58c3fe388e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'x:0' shape=() dtype=float32>, <tf.Tensor 'pow/y:0' shape=() dtype=float32>]\n",
      "----------------------------------------\n",
      "[<tf.Tensor 'pow:0' shape=() dtype=float32>]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def listing5_3_2():\n",
    "    \n",
    "    tf_cube = tf.function(cube)\n",
    "    concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "    \n",
    "    ops = concrete_function.graph.get_operations()\n",
    "    pow_op = ops[2]\n",
    "    print(list(pow_op.inputs))\n",
    "    HR()\n",
    "    \n",
    "    print(pow_op.outputs)\n",
    "    HR()\n",
    "    \n",
    "listing5_3_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koNl4BeJZpa2"
   },
   "source": [
    "<a id='5.3.3'></a><a name='5.3.3'></a>\n",
    "### 5.3.3 Fetch an operation or a tensor by name via `get_operation_by_name()` or `get_tensor_by_name()` methods\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIFHACCtZpa2",
    "outputId": "b337e7e8-c237-491e-90db-4f81cb79ccdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"x\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"_user_specified_name\"\n",
      "  value {\n",
      "    s: \"x\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "----------------------------------------\n",
      "Tensor(\"Identity:0\", shape=(), dtype=float32)\n",
      "----------------------------------------\n",
      "name: \"__inference_cube_1139472\"\n",
      "input_arg {\n",
      "  name: \"x\"\n",
      "  type: DT_FLOAT\n",
      "}\n",
      "output_arg {\n",
      "  name: \"identity\"\n",
      "  type: DT_FLOAT\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def listing5_3_3():  \n",
    "    \n",
    "    tf_cube = tf.function(cube)\n",
    "    concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "    \n",
    "    print(concrete_function.graph.get_operation_by_name('x'))\n",
    "    HR()\n",
    "    \n",
    "    print(concrete_function.graph.get_tensor_by_name('Identity:0'))\n",
    "    HR()\n",
    "     \n",
    "    print(concrete_function.function_def.signature)\n",
    "    \n",
    "listing5_3_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsBt3GXpZpa3"
   },
   "source": [
    "<a id='5.4'></a><a name='5.4'></a>\n",
    "## 5.4 How TF Functions Trace Python Functions to Extract Their Computation Graphs\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ExK9ZUuZpa3"
   },
   "source": [
    "<a id='5.4.1'></a><a name='5.4.1'></a>\n",
    "### 5.4.1 Trace Python Functions\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "nThC0RBhZpa3"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSRuTN-FZpa3",
    "outputId": "bfb1ef76-d582-41e5-e8b8-a898db0788f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "----------------------------------------\n",
      "print: 2\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "print: 3\n",
      "tf.Tensor(27, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "tf.Tensor([[1. 8.]], shape=(1, 2), dtype=float32)\n",
      "----------------------------------------\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f88d300c710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f88d300c710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 27.  64.]\n",
      " [125. 216.]], shape=(2, 2), dtype=float32)\n",
      "----------------------------------------\n",
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f88d300c710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x7f88d300c710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 342.99997  512.     ]\n",
      " [ 729.00006  999.99994]\n",
      " [1331.      1728.     ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def listing5_4_1():\n",
    "    result = tf_cube(tf.constant(2.0))\n",
    "    print(result)\n",
    "    HR()\n",
    "\n",
    "    result = tf_cube(2)\n",
    "    print(result)\n",
    "    HR()\n",
    "    \n",
    "    result = tf_cube(3)\n",
    "    print(result)\n",
    "    HR()\n",
    "    \n",
    "    result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "    print(result)\n",
    "    HR()\n",
    "    \n",
    "    result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "    print(result)\n",
    "    HR()\n",
    "    \n",
    "    result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!\n",
    "    print(result)\n",
    "\n",
    "listing5_4_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H065KNpVZpa3"
   },
   "source": [
    "<a id='5.4.2'></a><a name='5.4.2'></a>\n",
    "### 5.4.2 Specify a particular input signature of the TF Function\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "kXKeACzkZpa3"
   },
   "outputs": [],
   "source": [
    "# specify a particular input signature\n",
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUIs0XxRZpa4",
    "outputId": "4ec79881-5f25-4075-d846-d46b908c893b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n",
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "def listing5_4_2():\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "    img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "    preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "    preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function.\n",
    "        \n",
    "    img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "    try:\n",
    "        preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "    except ValueError as ex:\n",
    "        print(ex)\n",
    "\n",
    "listing5_4_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJeUbYoBZpa4"
   },
   "source": [
    "<a id='5.5'></a><a name='5.5'></a>\n",
    "## 5.5 Using Autograph To Capture Control Flow\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Material from Appendix G. TensorFlow Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n23zWHz2Zpa4"
   },
   "source": [
    "<a id='5.5.1'></a><a name='5.5.1'></a>\n",
    "### 5.5.1 \"Static\" for loop using range()\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "54bmcFQjZpa4"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnD5LoYTZpa4",
    "outputId": "ee1308cd-acdb-420a-f2a5-38ae3e185d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "[   <tf.Operation 'x' type=Placeholder>,\n",
      "    <tf.Operation 'add/y' type=Const>,\n",
      "    <tf.Operation 'add' type=AddV2>,\n",
      "    <tf.Operation 'add_1/y' type=Const>,\n",
      "    <tf.Operation 'add_1' type=AddV2>,\n",
      "    <tf.Operation 'add_2/y' type=Const>,\n",
      "    <tf.Operation 'add_2' type=AddV2>,\n",
      "    <tf.Operation 'add_3/y' type=Const>,\n",
      "    <tf.Operation 'add_3' type=AddV2>,\n",
      "    <tf.Operation 'add_4/y' type=Const>,\n",
      "    <tf.Operation 'add_4' type=AddV2>,\n",
      "    <tf.Operation 'add_5/y' type=Const>,\n",
      "    <tf.Operation 'add_5' type=AddV2>,\n",
      "    <tf.Operation 'add_6/y' type=Const>,\n",
      "    <tf.Operation 'add_6' type=AddV2>,\n",
      "    <tf.Operation 'add_7/y' type=Const>,\n",
      "    <tf.Operation 'add_7' type=AddV2>,\n",
      "    <tf.Operation 'add_8/y' type=Const>,\n",
      "    <tf.Operation 'add_8' type=AddV2>,\n",
      "    <tf.Operation 'add_9/y' type=Const>,\n",
      "    <tf.Operation 'add_9' type=AddV2>,\n",
      "    <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "def listing5_5_1():\n",
    "\n",
    "    print(add_10(tf.constant(5)))\n",
    "    HR()\n",
    "    \n",
    "    # This will contain 10 addition operations.\n",
    "    # This of the for-loop as a “static” loop that gets unrolled when the graph is created.\n",
    "    pp.pprint(add_10.get_concrete_function(tf.constant(5)).graph.get_operations())\n",
    "    \n",
    "listing5_5_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3j7w_y0Zpa5"
   },
   "source": [
    "<a id='5.5.2'></a><a name='5.5.2'></a>\n",
    "### 5.5.2 \"Dynamic\" loop using tf.while_loop()\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "A \"dynamic\" loop runs when the graph is executed. We can create a graph containing this via:\n",
    "\n",
    "* `tf.while_loop()` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "aUytnjk8Zpa5"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10_a(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ih4t-n3-Zpa5",
    "outputId": "fd6ea8d7-bb67-4136-e138-24f2021a556a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "[   <tf.Operation 'x' type=Placeholder>,\n",
      "    <tf.Operation 'Const' type=Const>,\n",
      "    <tf.Operation 'while/maximum_iterations' type=Const>,\n",
      "    <tf.Operation 'while/loop_counter' type=Const>,\n",
      "    <tf.Operation 'while' type=StatelessWhile>,\n",
      "    <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "def listing5_5_2():\n",
    "    \n",
    "    print(add_10_a(tf.constant(5)))\n",
    "    HR()\n",
    "    \n",
    "    # The graph now contains a while/loop operation.\n",
    "    pp.pprint(add_10_a.get_concrete_function(tf.constant(5)).graph.get_operations())\n",
    "\n",
    "listing5_5_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRQHPCw9Zpa6"
   },
   "source": [
    "<a id='5.5.3'></a><a name='5.5.3'></a>\n",
    "### 5.5.3 \"Dynamic\" for loop using tf.range() (captured by autograph)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We can also create a dynamic loop via:\n",
    "\n",
    "*  AutoGraph feature with `tf.range()` (more intuitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "Nz1-I8lOZpa6"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10_b(x):\n",
    "    # Use tf.range(), instead of range()\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yaf2qfr7Zpa6",
    "outputId": "32b7be3d-1875-464f-bd56-21484d828a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   <tf.Operation 'x' type=Placeholder>,\n",
      "    <tf.Operation 'range/start' type=Const>,\n",
      "    <tf.Operation 'range/limit' type=Const>,\n",
      "    <tf.Operation 'range/delta' type=Const>,\n",
      "    <tf.Operation 'range' type=Range>,\n",
      "    <tf.Operation 'sub' type=Sub>,\n",
      "    <tf.Operation 'floordiv' type=FloorDiv>,\n",
      "    <tf.Operation 'mod' type=FloorMod>,\n",
      "    <tf.Operation 'zeros_like' type=Const>,\n",
      "    <tf.Operation 'NotEqual' type=NotEqual>,\n",
      "    <tf.Operation 'Cast' type=Cast>,\n",
      "    <tf.Operation 'add' type=AddV2>,\n",
      "    <tf.Operation 'zeros_like_1' type=Const>,\n",
      "    <tf.Operation 'Maximum' type=Maximum>,\n",
      "    <tf.Operation 'while/maximum_iterations' type=Const>,\n",
      "    <tf.Operation 'while/loop_counter' type=Const>,\n",
      "    <tf.Operation 'while' type=StatelessWhile>,\n",
      "    <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "def listing5_5_3():\n",
    "    \n",
    "    #The graph now contains a while/loop operation.\n",
    "    pp.pprint(add_10_b.get_concrete_function(tf.constant(0)).graph.get_operations())\n",
    "\n",
    "listing5_5_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYILYLggZpa6"
   },
   "source": [
    "<a id='5.6'></a><a name='5.6'></a>\n",
    "## 5.6 Handling Variables and Other Resources in TF Functions\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "In TensorFlow, variables and other stateful objects, such as queues or datasets, are called resources. TF Functions treat them with special care: any operation that reads or updates a resource is considered stateful, and TF Functions ensure that stateful operations are executed in the order they appear (as opposed to stateless operations, which may be run in parallel, so their order of execution is not guaranteed). Moreover, when you pass a resource as an argument to a TF Function, it gets passed by reference, so the function may modify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "aPKu9OCpZpa6"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Czwqm7bnZpa7",
    "outputId": "7c0bb401-e1d9-44f4-f32d-a3ee0abb7e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "name: \"counter\"\n",
      "type: DT_RESOURCE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def listing5_6():\n",
    "    counter = tf.Variable(0)\n",
    "    \n",
    "    # When you pass a resource as an argument to a TF Function, \n",
    "    # it gets passed by reference\n",
    "    print(increment(counter))\n",
    "    print(increment(counter))\n",
    "    HR()\n",
    "    \n",
    "    # Peek at the function definition, we can see the first argument \n",
    "    # is marked as a resource:\n",
    "    function_def = increment.get_concrete_function(counter).function_def\n",
    "    print(function_def.signature.input_arg[0])\n",
    "\n",
    "listing5_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "dbmli-oiZpa7"
   },
   "outputs": [],
   "source": [
    "# Possible to use a defined outside of the function, \n",
    "# without explicitly passing it as an argument:\n",
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzzXNQdOZpa7",
    "outputId": "4fa201d8-5842-4611-fea0-688c8507d8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "----------------------------------------\n",
      "name: \"assignaddvariableop_resource\"\n",
      "type: DT_RESOURCE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def listing5_6b():\n",
    "    # The TF Function will treat this as an implicit first argument, \n",
    "    # so it will actually end up with the same signature (except for \n",
    "    # the name of the argument). However, using global variables can \n",
    "    # quickly become messy, so you should generally wrap variables \n",
    "    # (and other resources) inside classes.\n",
    "\n",
    "    print(increment())\n",
    "    print(increment())\n",
    "    HR()\n",
    "    \n",
    "    function_def = increment.get_concrete_function().function_def\n",
    "    print(function_def.signature.input_arg[0])\n",
    "    \n",
    "listing5_6b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "Eid3TZ72Zpa8"
   },
   "outputs": [],
   "source": [
    "# @tf.function works fine with Class methods also.\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMLU4kwXZpa8",
    "outputId": "22a13c9e-f5e7-4d9d-f430-d9c10814bd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def listing5_6c():\n",
    "    c = Counter()\n",
    "\n",
    "    print(c.increment())\n",
    "    print(c.increment())\n",
    "    \n",
    "listing5_6c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHHRDbTtZpa8",
    "outputId": "1955baae-415d-4f8e-ec78-51c7acb826f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "lheRd-5cZpa8"
   },
   "outputs": [],
   "source": [
    "def display_tf_code(func):    \n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "        \n",
    "    # Returns the source code generated by AutoGraph, as a string.\n",
    "    code = tf.autograph.to_code(func)\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnxL1lGuZpa9",
    "outputId": "e5432cc9-da2c-429d-c6de-e9fdbba3c3b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Me2IPOZZpa9"
   },
   "source": [
    "<a id='5.7'></a><a name='5.7'></a>\n",
    "## 5.7 Using TF Functions with tf.keras (or Not)\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "By default, any custom function, layer, or model you use with tf.keras will automatically be converted to a TF Function; you do not need to do anything at all. You do not need to manually use `tf.function()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "dYe2NOrMZpa9"
   },
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "JMZ8x57aZpa9"
   },
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "iWJMTlUuZpa9"
   },
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', \n",
    "            shape=(input_shape[1], self.units),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.biases = self.add_weight(\n",
    "            name='bias', \n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "cp3wHM6pZpa-"
   },
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSVfK0A0Zpa-",
    "outputId": "b4a47cd7-f245-4572-e122-fbe7564e6469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 - 2s - loss: 1.3255 - my_mae: 0.7900 - val_loss: 0.5569 - val_my_mae: 0.4819 - 2s/epoch - 7ms/step\n",
      "Epoch 2/2\n",
      "363/363 - 1s - loss: 0.4419 - my_mae: 0.4767 - val_loss: 0.4664 - val_my_mae: 0.4576 - 1s/epoch - 3ms/step\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.4164 - my_mae: 0.4639 - 257ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "def listing5_7():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    input_shape = X_train.shape[1:]\n",
    "\n",
    "    model = MyModel()\n",
    "\n",
    "    model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=2,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    HR()\n",
    "    \n",
    "    model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "listing5_7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7s-K_Uu3Zpa-",
    "outputId": "e5759516-26f4-41fc-a501-6327b6e2aebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(11610, 1)\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "----------------------------------------\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    }
   ],
   "source": [
    "# You can turn this off by creating the model with dynamic=True \n",
    "# (or calling super().__init__(dynamic=True, **kwargs) in \n",
    "# the model's constructor):\n",
    "\n",
    "def listing5_7b():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(X_train_scaled.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    " \n",
    "\n",
    "    # deactivate automatic TF Function conversion via dynamic=True\n",
    "    model = MyModel(dynamic=True)\n",
    "\n",
    "    model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])\n",
    "\n",
    "    # Not the custom code will be called at each iteration. Let's fit, \n",
    "    # validate and evaluate with tiny datasets to avoid getting too\n",
    "    # much output:\n",
    "    model.fit(\n",
    "        X_train_scaled[:64], \n",
    "        y_train[:64], \n",
    "        epochs=1,\n",
    "        validation_data=(X_valid_scaled[:64], y_valid[:64]), \n",
    "        verbose=0\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    model.evaluate(\n",
    "        X_test_scaled[:64], \n",
    "        y_test[:64], \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "listing5_7b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9xurPfLZpa-",
    "outputId": "7ca998d9-4e46-401f-cba5-373075f39e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(11610, 1)\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, you can compile a model with run_eagerly=True:\n",
    "def listing5_7c():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(X_train_scaled.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    " \n",
    "\n",
    "    model = MyModel()\n",
    "\n",
    "    model.compile(\n",
    "        loss=my_mse, \n",
    "        optimizer=\"nadam\", \n",
    "        metrics=[my_mae], \n",
    "        # deactivate automatic TF Function conversion via run_eagerly=True\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    \n",
    "    # Note: the custom code will be called at each iteration. \n",
    "    # Fit, validate and evaluate with tiny datasets to test.\n",
    "    model.fit(\n",
    "        X_train_scaled[:64], \n",
    "        y_train[:64], \n",
    "        epochs=1,\n",
    "        validation_data=(X_valid_scaled[:64], y_valid[:64]), \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    model.evaluate(\n",
    "        X_test_scaled[:64], \n",
    "        y_test[:64], \n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "listing5_7c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn1Qc3N9Zpa_"
   },
   "source": [
    "<a id='5.8'></a><a name='5.8'></a>\n",
    "## 5.8 Custom Optimizers\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD6sfL0nZpa_"
   },
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "roCf61RXZpa_"
   },
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_1kCYJnZpa_",
    "outputId": "be4a1aac-721a-4289-d173-85f6752d7966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 - 1s - loss: 3.8128 - accuracy: 0.0016 - 990ms/epoch - 3ms/step\n",
      "Epoch 2/5\n",
      "363/363 - 1s - loss: 1.4877 - accuracy: 0.0025 - 650ms/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "363/363 - 1s - loss: 0.9162 - accuracy: 0.0029 - 673ms/epoch - 2ms/step\n",
      "Epoch 4/5\n",
      "363/363 - 1s - loss: 0.7587 - accuracy: 0.0028 - 667ms/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "363/363 - 1s - loss: 0.7050 - accuracy: 0.0029 - 651ms/epoch - 2ms/step\n",
      "----------------------------------------\n",
      "162/162 - 0s - loss: 0.6702 - accuracy: 0.0021 - 304ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "def listing5_8():\n",
    "    \n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) \n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        housing.data, \n",
    "        housing.target.reshape(-1, 1), \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train_full, \n",
    "        y_train_full, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_valid_scaled = scaler.transform(X_valid)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    " \n",
    " \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(1, input_shape=[8])\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\", \n",
    "        optimizer=MyMomentumOptimizer(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train, \n",
    "        epochs=5,\n",
    "        verbose=2\n",
    "    )\n",
    "    HR()\n",
    "    \n",
    "    model.evaluate(\n",
    "        X_test_scaled, \n",
    "        y_test, \n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "listing5_8()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "12_custom_models_and_training_with_tf.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04c7dbffa4874fdf850fe366deb93765": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd751308a1964eb99ef27035ce6db92f",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b505021892f4f48ba7fc134a3296292",
      "value": 5
     }
    },
    "07a4e69105004890a70ddff05961292b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cb76d7074f64de0a91c14a1b57612d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ff8cab6f1b446348c20a7c10e916c7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12d9b1d146e74366a44c5f419f7053d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1721781396f4489eb3b504d24b6054ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18bd86442f33480a9ad9f5b5d7465e12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c431e5a98b47e6b01bd494baf03334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30b5dd4180b246e29f022500b920b94e",
      "placeholder": "​",
      "style": "IPY_MODEL_76805a9ff7dc453eafb79689c7b75509",
      "value": "Epoch 2/5: 100%"
     }
    },
    "28ef3da02a8440cbb39c028126356aea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ac2de18ce0444ec909b681ca6c478b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7ed6ba0c5434424b4f1cfaa31980b4e",
      "placeholder": "​",
      "style": "IPY_MODEL_883155696d634763800b25a854101dd1",
      "value": " 5/5 [00:41&lt;00:00,  8.33s/it]"
     }
    },
    "2b520020fe244fbdb67f0c3e2a99b385": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27c431e5a98b47e6b01bd494baf03334",
       "IPY_MODEL_63281dd48c5f45889c26137aa6a05c37",
       "IPY_MODEL_348bd7073fb147cd91b2a8640bc6d533"
      ],
      "layout": "IPY_MODEL_a90fa008d4a6470b96a6178408e7c3cb"
     }
    },
    "2ca723ae285f4a86bdcdbc973a716ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da3fdd7ee4c4b21ad28d3758c46ee90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3a5becfa716407b8e0ed2839a8b170f",
       "IPY_MODEL_acf67200c50746a5ada30c7691cb4ca6",
       "IPY_MODEL_db19a0fab6cc4957aa8e086bc12d5fbd"
      ],
      "layout": "IPY_MODEL_0ff8cab6f1b446348c20a7c10e916c7f"
     }
    },
    "30b5dd4180b246e29f022500b920b94e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "348bd7073fb147cd91b2a8640bc6d533": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efa2993512f543079a700e533fd8f856",
      "placeholder": "​",
      "style": "IPY_MODEL_d0f52524ff3d4d0d99e0f6724586008c",
      "value": " 362/362 [00:08&lt;00:00, 48.63it/s, loss=0.63, mean_absolute_error=0.512]"
     }
    },
    "36c4bf42815f47e2aef0615c5c492151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "382ef5be5409462181141dc0741d51eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a3699316dfa4643918b58f37dbe356b",
      "placeholder": "​",
      "style": "IPY_MODEL_982f23a445c14d6884fd40ded5be273f",
      "value": "Epoch 1/5: 100%"
     }
    },
    "4657fafecfb64b6a9a96f1f6b4b77a59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f872850a85344729720e2e8cf9adc06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "547e72e3cfee43ee9f9d5bd5358ef295": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97dee864b9f3469baf0c12fbdcf156eb",
      "placeholder": "​",
      "style": "IPY_MODEL_cf7fc8151f4b45d9b65bd66d95820f9a",
      "value": " 362/362 [00:08&lt;00:00, 44.82it/s, loss=0.626, mean_absolute_error=0.51]"
     }
    },
    "57c8958a639b47a7aa9f71125de1120d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_382ef5be5409462181141dc0741d51eb",
       "IPY_MODEL_66c452b137a6408489646762f501a3dd",
       "IPY_MODEL_9cc5eb5c3e6546059be07c9a3aaad054"
      ],
      "layout": "IPY_MODEL_2ca723ae285f4a86bdcdbc973a716ae8"
     }
    },
    "5beb87ec9db84c10ad61f4600da1269e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e6ea399bab6447dafcdda568ab309c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6d333a0517743109559d35c66aab373",
       "IPY_MODEL_04c7dbffa4874fdf850fe366deb93765",
       "IPY_MODEL_2ac2de18ce0444ec909b681ca6c478b7"
      ],
      "layout": "IPY_MODEL_e173011b22bb42c98299ba6cf08b9d06"
     }
    },
    "6026a582fca7484c9fc004ffc9feda4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63281dd48c5f45889c26137aa6a05c37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18bd86442f33480a9ad9f5b5d7465e12",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e590534440b4ebfa5c58af48d95ee6c",
      "value": 362
     }
    },
    "633c18bca02446d3bc2711dc7173e4e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66c452b137a6408489646762f501a3dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4657fafecfb64b6a9a96f1f6b4b77a59",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_12d9b1d146e74366a44c5f419f7053d9",
      "value": 362
     }
    },
    "6b505021892f4f48ba7fc134a3296292": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c8cae0169114ec793fe616cf9b9ac5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dbfb853e68b4d63bfec18880d55027e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e590534440b4ebfa5c58af48d95ee6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "746e431448f644bf8401ac79560a30e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76805a9ff7dc453eafb79689c7b75509": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a3699316dfa4643918b58f37dbe356b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c5380f4f9684d42bf7f329fbb8af2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa1901562bba4394ae3dce0edbee1226",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4cce90d1256456a98f8315869d39365",
      "value": 362
     }
    },
    "7c84558f8fc44d34971f3820dda97fbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81b7e6eb90fc43e19b1029840ac69a38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "883155696d634763800b25a854101dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88d8832445bc45a5b86e97545b780f37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab80b8374c854afe80e1553f43187ea2",
      "placeholder": "​",
      "style": "IPY_MODEL_4f872850a85344729720e2e8cf9adc06",
      "value": "Epoch 4/5: 100%"
     }
    },
    "898f13138e1647c49e1a542f725c16b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0eafb9fba49484da46daf2dcc5fd404",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5beb87ec9db84c10ad61f4600da1269e",
      "value": 362
     }
    },
    "9658900bb988430398208fa658e6a32a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efa19e6d6c894e26a464a7a7445558a7",
      "placeholder": "​",
      "style": "IPY_MODEL_6dbfb853e68b4d63bfec18880d55027e",
      "value": "Epoch 3/5: 100%"
     }
    },
    "97dee864b9f3469baf0c12fbdcf156eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "982f23a445c14d6884fd40ded5be273f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a2e9a5e0097417a972c636b5e69e59e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cc5eb5c3e6546059be07c9a3aaad054": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c8cae0169114ec793fe616cf9b9ac5f",
      "placeholder": "​",
      "style": "IPY_MODEL_36c4bf42815f47e2aef0615c5c492151",
      "value": " 362/362 [00:08&lt;00:00, 44.81it/s, loss=0.65, mean_absolute_error=0.522]"
     }
    },
    "a90fa008d4a6470b96a6178408e7c3cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa1901562bba4394ae3dce0edbee1226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab80b8374c854afe80e1553f43187ea2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acf67200c50746a5ada30c7691cb4ca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1721781396f4489eb3b504d24b6054ae",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07a4e69105004890a70ddff05961292b",
      "value": 362
     }
    },
    "b0eafb9fba49484da46daf2dcc5fd404": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d333a0517743109559d35c66aab373": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c151a92a58a3489fae3ad03d857d1621",
      "placeholder": "​",
      "style": "IPY_MODEL_633c18bca02446d3bc2711dc7173e4e1",
      "value": "All epochs: 100%"
     }
    },
    "c151a92a58a3489fae3ad03d857d1621": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf7fc8151f4b45d9b65bd66d95820f9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d0f52524ff3d4d0d99e0f6724586008c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d25addabbb89476aa522cb5dab384e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88d8832445bc45a5b86e97545b780f37",
       "IPY_MODEL_898f13138e1647c49e1a542f725c16b7",
       "IPY_MODEL_ffa37d8ed7be4417884979059ff4ce2d"
      ],
      "layout": "IPY_MODEL_d3589ddd6fbf4db4877adb1aee8f8b69"
     }
    },
    "d3589ddd6fbf4db4877adb1aee8f8b69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db19a0fab6cc4957aa8e086bc12d5fbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cb76d7074f64de0a91c14a1b57612d9",
      "placeholder": "​",
      "style": "IPY_MODEL_746e431448f644bf8401ac79560a30e3",
      "value": " 362/362 [00:08&lt;00:00, 46.81it/s, loss=0.637, mean_absolute_error=0.513]"
     }
    },
    "dd751308a1964eb99ef27035ce6db92f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e173011b22bb42c98299ba6cf08b9d06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7ed6ba0c5434424b4f1cfaa31980b4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa19e6d6c894e26a464a7a7445558a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa2993512f543079a700e533fd8f856": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3a5becfa716407b8e0ed2839a8b170f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a2e9a5e0097417a972c636b5e69e59e",
      "placeholder": "​",
      "style": "IPY_MODEL_6026a582fca7484c9fc004ffc9feda4c",
      "value": "Epoch 5/5: 100%"
     }
    },
    "f4cce90d1256456a98f8315869d39365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ff4bfae5b356449d93d821bef7c08373": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9658900bb988430398208fa658e6a32a",
       "IPY_MODEL_7c5380f4f9684d42bf7f329fbb8af2d8",
       "IPY_MODEL_547e72e3cfee43ee9f9d5bd5358ef295"
      ],
      "layout": "IPY_MODEL_81b7e6eb90fc43e19b1029840ac69a38"
     }
    },
    "ffa37d8ed7be4417884979059ff4ce2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28ef3da02a8440cbb39c028126356aea",
      "placeholder": "​",
      "style": "IPY_MODEL_7c84558f8fc44d34971f3820dda97fbf",
      "value": " 362/362 [00:08&lt;00:00, 48.16it/s, loss=0.612, mean_absolute_error=0.505]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
