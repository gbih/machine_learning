{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a id='top'></a>\n",
        "<a name=\"top\"></a><!--Need for Colab-->\n",
        "# Quick introduction to TensorFlow Serving\n",
        "\n",
        "## MNIST CNN Model on Colab\n",
        "\n",
        "Using subprocess module, trained / saved / loaded MNIST model, and HTTP requests-logging with TensorFlow Serving on Colab.\n",
        "\n",
        "This is a bit more complicated than using Docker."
      ],
      "metadata": {
        "id": "ur3fA5doQ0HU"
      },
      "id": "ur3fA5doQ0HU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/gbih/ml/blob/main/tf_server/03_tfserver_mnist_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "tyuecNHR9ihC"
      },
      "id": "tyuecNHR9ihC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Setup](#setup)\n",
        "2. [Introduction](#2.0)\n",
        "3. [Using subprocess with TensorFlow Serving](#3.0)\n",
        "4. [Train, save and load a MNIST model](#4.0)\n",
        "    * 4.1 [Inspect the SavedModel Signature](#4.1)\n",
        "5. [HTTP Request Logging for TensorFlow Serving](#5.0)\n",
        "6. [Running TensorFlow Serving on Colab](#6.0)\n",
        "7. [Health check](#7.0)\n",
        "    * 7.1 [Verify response](#7.1)\n",
        "    * 7.2 [Verify logs](#7.2)\n",
        "8. [Predict requests via POST](#8.0)\n",
        "9. [End and clean up processes](#9.0)"
      ],
      "metadata": {
        "id": "j8r5-9JQQ-JT"
      },
      "id": "j8r5-9JQQ-JT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the following before initializing TensorFlow \n",
        "import os\n",
        "os.environ[\"TF_CPP_VMODULE\"] = 'http_server=1'"
      ],
      "metadata": {
        "id": "W8eFHZspYJOe"
      },
      "id": "W8eFHZspYJOe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name=\"setup\"></a>\n",
        "# 1. Setup\n",
        "<a href=\"#top\">[back to top]</a>"
      ],
      "metadata": {
        "id": "kOI2CD03RC3n"
      },
      "id": "kOI2CD03RC3n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4cfedd4-a827-4b73-9a1d-0f028e93d3ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4cfedd4-a827-4b73-9a1d-0f028e93d3ae",
        "outputId": "ea0e3eb0-91f1-4ee4-8b55-922fcd6eff8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.13\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "matplotlib: 3.2.2\n",
            "numpy     : 1.21.6\n",
            "requests  : 2.23.0\n",
            "tensorflow: 2.8.2+zzzcolab20220719082949\n",
            "\n",
            "Finished loading packages..\n"
          ]
        }
      ],
      "source": [
        "# standard library imports\n",
        "import asyncio\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pprint\n",
        "import shlex\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# third party imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check platform (Colab or Kaggle)\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    !pip install -q requests\n",
        "    !pip install watermark -q\n",
        "\n",
        "import requests\n",
        "\n",
        "# For debugging, provides version & hardware info\n",
        "# Load watermark magic extension\n",
        "%load_ext watermark\n",
        "%watermark --python --packages matplotlib,numpy,requests,tensorflow\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "\n",
        "def HR():\n",
        "    print(\"-\"*40)\n",
        "\n",
        "print(\"Finished loading packages..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id=\"2.0\"></a><a name=\"2.0\"></a>\n",
        "# 2. Introduction\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "We explore these tasks here:\n",
        "\n",
        "* Using subprocess with TensorFlow Serving.\n",
        "* Train / save / load the MNIST model.\n",
        "* Configuring and running TensorFlow Server without using Docker. "
      ],
      "metadata": {
        "id": "F0w0G4INRGij"
      },
      "id": "F0w0G4INRGij"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id=\"3.0\"></a><a name=\"3.0\"></a>\n",
        "# 3. Using subprocess with TensorFlow Serving\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "The older method of running CLI commands in Python involved using either os.system or os.spawn*. Here, we will instead use the newer subprocess module. This allows us to spawn new processes, connect to their input/output/error pipes, and optionally obtain their return codes. This is a safer analog to os.system().\n",
        "\n",
        "The underlying process creation and management in `subprocess` is done by the [Popen Constructor](https://docs.python.org/3/library/subprocess.html#popen-constructor), `subprocess.Popen`. The underlying Popen interface can be used directly and offers the most flexibility. By default it results in a non-blocking call.\n",
        "\n",
        "Once you've created the Popen instance, some options are:\n",
        "* `wait()`:  to pause until the subprocess has exited.\n",
        "* `poll()`: check if it's exited without pausing.\n",
        "* `communicate()`: interact with process\n",
        "    - Send data to stdin. \n",
        "    - Read data from stdout and stderr, until end-of-file is reached. \n",
        "    - Wait for process to terminate and set the returncode attribute. \n",
        "\n",
        "\n",
        "**Popen Constructor:**\n",
        "\n",
        "```bash\n",
        "class subprocess.Popen(\n",
        "    args, \n",
        "    bufsize=- 1, \n",
        "    executable=None, \n",
        "    stdin=None, \n",
        "    stdout=None, \n",
        "    stderr=None, \n",
        "    preexec_fn=None, \n",
        "    close_fds=True, \n",
        "    shell=False, \n",
        "    cwd=None, \n",
        "    env=None, \n",
        "    universal_newlines=None, \n",
        "    startupinfo=None, \n",
        "    creationflags=0, \n",
        "    restore_signals=True, \n",
        "    start_new_session=False, \n",
        "    pass_fds=(), \n",
        "    *, \n",
        "    group=None, \n",
        "    extra_groups=None, \n",
        "    user=None, \n",
        "    umask=- 1, \n",
        "    encoding=None, \n",
        "    errors=None, \n",
        "    text=None, \n",
        "    pipesize=- 1\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "    \n",
        "A convenience function built upon the underlying Popen interface is `subprocess.run`. This is a blocking call, as it waits for the command(s) to complete, then return a CompletedProcess instance.\n",
        "\n",
        "There are older high-level APIs, existing prior to Python 3.5. The functionality provided by them has been superceded by `subprocess.Popen` and `subprocess.run`:\n",
        "\n",
        "* `subprocess.call`\n",
        "* `subprocess.check_call`\n",
        "* `subprocess.check_output`\n",
        "\n",
        "\n",
        "**Useful resources on subprocess:**\n",
        "\n",
        "- https://peps.python.org/pep-0324/\n",
        "- https://docs.python.org/3/whatsnew/2.4.html#pep-324-new-subprocess-module\n",
        "- https://docs.python.org/3/library/subprocess.html\n",
        "- https://www.bogotobogo.com/python/python_subprocess_module.php\n",
        "- https://qiita.com/HidKamiya/items/e192a55371a2961ca8a4 (JP)\n",
        "- https://www.programcreek.com/python/example/50/subprocess.Popen\n"
      ],
      "metadata": {
        "id": "LSemlbYRRLjh"
      },
      "id": "LSemlbYRRLjh"
    },
    {
      "cell_type": "markdown",
      "id": "2742abe9-e4e2-4ed2-9e6d-b266f1091c64",
      "metadata": {
        "id": "2742abe9-e4e2-4ed2-9e6d-b266f1091c64"
      },
      "source": [
        "---\n",
        "<a id=\"4.0\"></a><a name=\"4.0\"></a>\n",
        "# 4. Train, save and load a MNIST model\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Here, we will train and save a CNN model for the MNIST dataset, then install TensorFlow Server on Debian to deploy this model.  We then make POST HTTP request with a JSON payload that contain test data. TensorFlow Serving will then make inferences, predicting the most probable image from among 10 categories.\n",
        "\n",
        "Reference:\n",
        "* https://www.tensorflow.org/tfx/tutorials/serving/rest_simple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38ad44d-1800-402e-b70e-e0ea3618b7dd",
      "metadata": {
        "id": "c38ad44d-1800-402e-b70e-e0ea3618b7dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44edaf7d-9f40-46bf-9cb5-5bb75ad9ba4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_dir:\t/content/tfs_colab\n",
            "model_name:\tmnist\n",
            "176K\t/content/tfs_colab/1/variables\n",
            "4.0K\t/content/tfs_colab/1/assets\n",
            "268K\t/content/tfs_colab/1\n",
            "272K\t/content/tfs_colab\n"
          ]
        }
      ],
      "source": [
        "MODEL_ROOT = 'tfs_colab'\n",
        "\n",
        "# create pathlib.PosixPath with fullpath via .resolve\n",
        "model_dir = (Path() / MODEL_ROOT).resolve()\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_name = 'mnist'\n",
        "\n",
        "print(f\"model_dir:\\t{model_dir}\")\n",
        "print(f\"model_name:\\t{model_name}\")\n",
        "\n",
        "!du -h {model_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4405f4b3-8a9f-40b9-a9ea-530a74997b74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4405f4b3-8a9f-40b9-a9ea-530a74997b74",
        "outputId": "a839dfa8-e8e6-43ea-b8f5-1c337144eefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 9s - loss: 0.5499 - sparse_categorical_accuracy: 0.8084 - 9s/epoch - 5ms/step\n",
            "Epoch 2/5\n",
            "1875/1875 - 10s - loss: 0.4257 - sparse_categorical_accuracy: 0.8508 - 10s/epoch - 5ms/step\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - loss: 0.3881 - sparse_categorical_accuracy: 0.8639 - 5s/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "1875/1875 - 8s - loss: 0.3654 - sparse_categorical_accuracy: 0.8715 - 8s/epoch - 4ms/step\n",
            "Epoch 5/5\n",
            "1875/1875 - 7s - loss: 0.3481 - sparse_categorical_accuracy: 0.8768 - 7s/epoch - 4ms/step\n",
            "INFO:tensorflow:Assets written to: /content/tfs_colab/1/assets\n",
            "----------------------------------------\n",
            "\n",
            "Saved model:\n",
            "4.0K\t/content/tfs_colab/1/variables/variables.index\n",
            "168K\t/content/tfs_colab/1/variables/variables.data-00000-of-00001\n",
            "176K\t/content/tfs_colab/1/variables\n",
            "72K\t/content/tfs_colab/1/saved_model.pb\n",
            "12K\t/content/tfs_colab/1/keras_metadata.pb\n",
            "4.0K\t/content/tfs_colab/1/assets\n",
            "268K\t/content/tfs_colab/1\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Rescale to [0.0 .. 1.0]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape for feeding into the model\n",
        "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
        "test_images = test_images.reshape(test_images.shape[0],28,28,1)\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(\n",
        "        input_shape=(28,28,1),\n",
        "        filters=8,\n",
        "        kernel_size=3,\n",
        "        strides=2,\n",
        "        activation='relu',\n",
        "        name='conv1'\n",
        "    ),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, name='dense')\n",
        "])\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        ")\n",
        "\n",
        "hist = model.fit(\n",
        "    train_images,\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    verbose=2\n",
        ")\n",
        "                \n",
        "version = 1\n",
        "export_path = Path() / model_dir / str(version)\n",
        "\n",
        "# We will manually save the model here, in SavedModel format.\n",
        "# This creates a protobuf file in a structured directory hierarchy, \n",
        "# and includes a version number.\n",
        "# The model signature is defined by the input and output tensors, \n",
        "# and stored with the serving_default key.\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "HR()\n",
        "\n",
        "print(\"\\nSaved model:\")\n",
        "!du -ah {export_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='4.1'></a><a name='4.1'></a>\n",
        "## 4.1 Inspect the SavedModel Signature\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "We can use the tool `saved_model_cli` to inspect the SignatureDefs (the callable methods) of a model. This allows us to confirm the input Tensor dtype and shape matches the model.\n",
        "\n",
        "Resources:\n",
        "* https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel\n",
        "* https://www.tensorflow.org/guide/saved_model\n",
        "* https://blog.tensorflow.org/2021/03/a-tour-of-savedmodel-signatures.html\n",
        "* https://www.tensorflow.org/tfx/tutorials/serving/rest_simple"
      ],
      "metadata": {
        "id": "xODNDOZNsrPD"
      },
      "id": "xODNDOZNsrPD"
    },
    {
      "cell_type": "code",
      "source": [
        "newest_model = max(glob.glob(f\"{model_dir}/*\"))\n",
        "\n",
        "print(\"All tag-sets in the latest SavedModel:\")\n",
        "HR()\n",
        "!saved_model_cli show \\\n",
        "--dir {newest_model}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBBogXcWsq31",
        "outputId": "67427b58-159f-40e2-82b2-874ccf9d7939"
      },
      "id": "GBBogXcWsq31",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tag-sets in the latest SavedModel:\n",
            "----------------------------------------\n",
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All available SignatureDef keys in the MetaGraphDef specified by tag-set 'serve':\")\n",
        "HR()\n",
        "!saved_model_cli show \\\n",
        "--dir {newest_model} --tag_set serve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUf51MMTsxrJ",
        "outputId": "4730ae01-1cb7-4f24-9940-80317f83bd31"
      },
      "id": "gUf51MMTsxrJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All available SignatureDef keys in the MetaGraphDef specified by tag-set 'serve':\n",
            "----------------------------------------\n",
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All inputs and outputs TensorInfo for the specific SignatureDef 'serving_default' in the MetaGraph:\")\n",
        "print(\"Note that shape: (-1) implies 1-D shape for inference data, eg {'examples': [{...}]}\")\n",
        "HR()\n",
        "\n",
        "!saved_model_cli show \\\n",
        "--dir {newest_model} \\\n",
        "--tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpntfog_szlf",
        "outputId": "6a2c87c0-1ed2-4094-81a4-9696a2400736"
      },
      "id": "jpntfog_szlf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All inputs and outputs TensorInfo for the specific SignatureDef 'serving_default' in the MetaGraph:\n",
            "Note that shape: (-1) implies 1-D shape for inference data, eg {'examples': [{...}]}\n",
            "----------------------------------------\n",
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['conv1_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_conv1_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a id=\"5.0\"></a><a name=\"5.0\"></a>\n",
        "# 5. HTTP Request Logging for TensorFlow Serving\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "* The easiest way to enable logging for TensorFlow-Model-Serving is via environment variables. This is not specific to TensorFlow Serving, but general to TensorFlow.\n",
        "\n",
        "* `TF_CPP_MIN_VLOG_LEVEL` enables logging of the main C++ backend. However, even the lowest setting of `TF_CPP_MIN_VLOG_LEVEL=1` results in too much noise.\n",
        "\n",
        "* `TF_CPP_VMODULE` provides a way to constrain logging to specific modules or source files. The general format is `TF_CPP_VMODULE=<module_name>=1`, where the module name can be either the C++ or Python file name (without the extension).\n",
        "\n",
        "* Here, we can activate logging individually for http_server.cc via \n",
        "`TF_CPP_VMODULE=http_server=1`. This will enable simple HTTP request logging and errors.\n",
        "\n",
        "**To-do:**\n",
        "\n",
        "With a non-Docker platform, we can set the \n",
        "environmental variable via `os.environ[\"TF_CPP_VMODULE\"] = 'http_server=1'`. However, GET and POST requests are not being logged (possible mis-configuration?)"
      ],
      "metadata": {
        "id": "gGe1iohfs83l"
      },
      "id": "gGe1iohfs83l"
    },
    {
      "cell_type": "markdown",
      "id": "f1d0e6c0-ca5f-490b-ac41-edc8c841cd74",
      "metadata": {
        "id": "f1d0e6c0-ca5f-490b-ac41-edc8c841cd74"
      },
      "source": [
        "---\n",
        "<a name=\"6.0\"></a>\n",
        "# 6. Running TensorFlow Serving on Colab\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "To-do: \n",
        "\n",
        "Add explanation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfs_download_colab():\n",
        "    print(\"Running on Colab\")\n",
        "    HR()\n",
        "\n",
        "    # tensorflow-model-server 2.8.2 and 2.9.0 require updated GLIBC versions.\n",
        "    # https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/setup.md\n",
        "    \n",
        "    # Binary debian file\n",
        "    debian_tfs = 'tensorflow-model-server-universal_2.8.0_all.deb'\n",
        "    path = Path(debian_tfs)\n",
        "    if not path.is_file():\n",
        "        !wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-universal-2.8.0/t/tensorflow-model-server-universal/tensorflow-model-server-universal_2.8.0_all.deb'\n",
        "\n",
        "    # Use dpkg to install, remove, and provide information about .deb packages.\n",
        "    !dpkg -i tensorflow-model-server-universal_2.8.0_all.deb\n"
      ],
      "metadata": {
        "id": "dlflpNVXF0jQ"
      },
      "id": "dlflpNVXF0jQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = f\"{model_name}_tfs.log\"\n",
        "print(f\"log_file: {log_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xcv20KgiZZA",
        "outputId": "6ca45bba-8a5f-4926-d57e-cbdb5211b381"
      },
      "id": "8xcv20KgiZZA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_file: mnist_tfs.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9b3bff-c98c-4193-ba12-750e1c6f0eae",
      "metadata": {
        "id": "3b9b3bff-c98c-4193-ba12-750e1c6f0eae"
      },
      "outputs": [],
      "source": [
        "def tfs_start_colab():\n",
        "    \n",
        "    # Use `subprocess.Popen()` to start the tensorflow_model_server. The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.\n",
        "    # To run `tensorflow_model_server` as a process on Debian, we additionaly need these steps:\n",
        "\n",
        "    # * https://stackoverflow.com/questions/6011235/run-a-program-from-python-and-have-it-continue-to-run-after-the-script-is-kille/16928558#16928558\n",
        "    # Run a program from python, and have it continue to run after the script is killed. If use 'setpgrp', this prevents the child from getting SIGHUP from the parent, since it's no longer part of the same process group, hence cannot use 'nohup',\n",
        "    # but we really don't need it anymore.\n",
        "\n",
        "    # * https://pythontect.com/python-subprocess-popen-tutorial/\n",
        "    # If preexec_fn is set to a callable object, this object will be called in \n",
        "    # the child process just before the child is executed. (POSIX only)\n",
        "    \n",
        "    # By default, TensorFlow Model Server listens on port 8500 using the gRPC API. To use a different port, specify --port=<port number> on the command line.\n",
        "    # By default TensorFlow Model Server will not listen for a REST/HTTP request. To specify a port to listen for a REST/HTTP request, include --rest_api_port=<port number> on the command line.\n",
        "\n",
        "    # Can we directly pass environmental variables here?\n",
        "    cmd = f\"\"\"nohup \n",
        "        tensorflow_model_server \n",
        "        --rest_api_port=8501 \n",
        "        --model_name={model_name} \n",
        "        --model_base_path='{model_dir}' \n",
        "        \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Run a program from python, and have it continue to run after the script is killed\n",
        "        # https://stackoverflow.com/questions/6011235/run-a-program-from-python-and-have-it-continue-to-run-after-the-script-is-kille/16928558#16928558\n",
        "        # If use 'setpgrp', this prevents the child from getting SIGHUP from the parent, \n",
        "        # since it's no longer part of the same process group, hence cannot use 'nohup',\n",
        "        # but we really don't need it anymore.s\n",
        "        # https://pythontect.com/python-subprocess-popen-tutorial/\n",
        "        # If preexec_fn is set to a callable object, this object will be called in \n",
        "        # the child process just before the child is executed. (POSIX only)\n",
        "\n",
        "        # popen on Unix is done using fork, so it naturally \"detaches\" from the parent process\n",
        "        proc = subprocess.Popen(\n",
        "            shlex.split(cmd),\n",
        "            stdout=open(log_file, 'w'),\n",
        "            stderr=subprocess.STDOUT,\n",
        "            preexec_fn=os.setpgrp, # keep subprocess alive even when parent stops\n",
        "            shell=False # needed for shell-like features like &\n",
        "        )\n",
        "        # print(f\"-------- PROC HERE: {proc.pid}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    return proc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530eb5ac-74ef-4d99-afde-3181314d5b0c",
      "metadata": {
        "id": "530eb5ac-74ef-4d99-afde-3181314d5b0c"
      },
      "outputs": [],
      "source": [
        "def check_tfp_process():\n",
        "    !ps ax | grep -e tensorflow_model_server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h2-5HumxPMUF",
      "metadata": {
        "id": "h2-5HumxPMUF"
      },
      "outputs": [],
      "source": [
        "def request_status_rest():\n",
        "    try:\n",
        "        resp_data = requests.get(f'http://localhost:8501/v1/models/{model_name}')\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    else:\n",
        "        return resp_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aVFlw850I3Wl",
      "metadata": {
        "id": "aVFlw850I3Wl"
      },
      "outputs": [],
      "source": [
        "def show_tfs_dict(proc):\n",
        "    print(\"Properties of returned container process:\\n\")\n",
        "    for key in proc.__dict__:\n",
        "        if key == 'args':\n",
        "            HR()\n",
        "            print(key, '->', proc.__dict__[key])\n",
        "            HR()\n",
        "        else:\n",
        "            print(key, '->', proc.__dict__[key])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfs_download_colab() # download\n",
        "proc = tfs_start_colab() # start\n",
        "\n",
        "print(f\"tensorflow_model_server proc.pid: {proc.pid}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM6Qy3EwE5Za",
        "outputId": "d3bc421d-0341-4e43-8b18-0d6f5c69376f"
      },
      "id": "OM6Qy3EwE5Za",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Colab\n",
            "----------------------------------------\n",
            "(Reading database ... 155681 files and directories currently installed.)\n",
            "Preparing to unpack tensorflow-model-server-universal_2.8.0_all.deb ...\n",
            "Unpacking tensorflow-model-server-universal (2.8.0) over (2.8.0) ...\n",
            "Setting up tensorflow-model-server-universal (2.8.0) ...\n",
            "tensorflow_model_server proc.pid: 1265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b925d50f-5119-405f-b5a2-800cb2cc65c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b925d50f-5119-405f-b5a2-800cb2cc65c5",
        "outputId": "e35a60e3-16a4-4529-f302-bbea98effc93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Properties of returned container process:\n",
            "\n",
            "_waitpid_lock -> <unlocked _thread.lock object at 0x7f286c238a50>\n",
            "_input -> None\n",
            "_communication_started -> False\n",
            "----------------------------------------\n",
            "args -> ['nohup', 'tensorflow_model_server', '--rest_api_port=8501', '--model_name=mnist', '--model_base_path=/content/tfs_colab']\n",
            "----------------------------------------\n",
            "stdin -> None\n",
            "stdout -> None\n",
            "stderr -> None\n",
            "pid -> 1265\n",
            "returncode -> None\n",
            "encoding -> None\n",
            "errors -> None\n",
            "text_mode -> None\n",
            "_sigint_wait_secs -> 0.25\n",
            "_closed_child_pipe_fds -> True\n",
            "_child_created -> True\n"
          ]
        }
      ],
      "source": [
        "show_tfs_dict(proc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_tfp_process() # check if running"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L975cS107oZ",
        "outputId": "744ae0b4-94ce-438d-cdd2-414930b25d3c"
      },
      "id": "_L975cS107oZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1265 ?        Sl     0:00 tensorflow_model_server --rest_api_port=8501 --model_name=mnist --model_base_path=/content/tfs_colab\n",
            "   1266 ?        S      0:00 /bin/bash -c ps ax | grep -e tensorflow_model_server\n",
            "   1268 ?        S      0:00 grep -e tensorflow_model_server\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name=\"7.0\"></a>\n",
        "# 7. Health check\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Creates a simple http client and send requests.\n",
        "\n",
        "* https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py#L520"
      ],
      "metadata": {
        "id": "f5ywwRv5vrjv"
      },
      "id": "f5ywwRv5vrjv"
    },
    {
      "cell_type": "code",
      "source": [
        "def request_status_rest():\n",
        "    try:\n",
        "        resp_data = requests.get(f'http://localhost:8501/v1/models/{model_name}')\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    else:\n",
        "        return resp_data"
      ],
      "metadata": {
        "id": "pwL06TLWwF7G"
      },
      "id": "pwL06TLWwF7G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='7.1'></a><a name='7.1'></a>\n",
        "## 7.1 Verify response\n",
        "<a href=\"#top\">[back to top]</a>"
      ],
      "metadata": {
        "id": "GyE1OOdUvrqw"
      },
      "id": "GyE1OOdUvrqw"
    },
    {
      "cell_type": "code",
      "source": [
        "request_result = request_status_rest()\n",
        "\n",
        "pp.pprint(request_result.json())\n",
        "\n",
        "assert request_result.json() == {\n",
        "        'model_version_status': [{\n",
        "            'version': '1',\n",
        "            'state': 'AVAILABLE',\n",
        "            'status': {\n",
        "                'error_code': 'OK',\n",
        "                'error_message': ''\n",
        "            }\n",
        "        }]\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPGmcBCOwOIK",
        "outputId": "b76734a4-f798-4312-c8a5-701728118ca9"
      },
      "id": "oPGmcBCOwOIK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 'model_version_status': [ { 'state': 'AVAILABLE',\n",
            "                              'status': { 'error_code': 'OK',\n",
            "                                          'error_message': ''},\n",
            "                              'version': '1'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='7.2'></a><a name='7.2'></a>\n",
        "## 7.2 Verify logs\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "To-do:\n",
        "\n",
        "We are not seeing the log files being updated with these HTTP requests, need to check."
      ],
      "metadata": {
        "id": "D8lRxfsGwiWy"
      },
      "id": "D8lRxfsGwiWy"
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(5):\n",
        "    resp = request_status_rest()\n",
        "    print(f\"===> TFS Status : {resp.headers['Date']} {resp}\")\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "HR()\n",
        "    \n",
        "!du -h {log_file}\n",
        "HR()\n",
        "!tail  {log_file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOsw0bAFwl0u",
        "outputId": "feab7d8e-52e3-41f3-8e77-ed745fe7f4ee"
      },
      "id": "uOsw0bAFwl0u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> TFS Status : Sun, 07 Aug 2022 15:02:23 GMT <Response [200]>\n",
            "===> TFS Status : Sun, 07 Aug 2022 15:02:23 GMT <Response [200]>\n",
            "===> TFS Status : Sun, 07 Aug 2022 15:02:24 GMT <Response [200]>\n",
            "===> TFS Status : Sun, 07 Aug 2022 15:02:24 GMT <Response [200]>\n",
            "===> TFS Status : Sun, 07 Aug 2022 15:02:25 GMT <Response [200]>\n",
            "----------------------------------------\n",
            "4.0K\tmnist_tfs.log\n",
            "----------------------------------------\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2ddc6d1-ea1e-4c65-988a-3f2e82e5562e",
      "metadata": {
        "id": "c2ddc6d1-ea1e-4c65-988a-3f2e82e5562e"
      },
      "source": [
        "---\n",
        "<a id=\"8.0\"></a><a name=\"8.0\"></a>\n",
        "# 8. Predict requests via POST\n",
        "<a href=\"#top\">[back to top]</a>\n",
        "\n",
        "Send a predict request as a POST to our server's REST endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "661bf264-9fd8-46ae-8c57-c3dedf044db1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "661bf264-9fd8-46ae-8c57-c3dedf044db1",
        "outputId": "de6ab9ba-288e-4ce3-a8d2-5649ed89791e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data passed to JSON payload: (3, 28, 28, 1)\n",
            "shape[0] is 3, this means we will pass 3 samples.\n",
            "----------------------------------------\n",
            "Properties of response:\n",
            "\n",
            "{ '_content': b'{\\n    \"predictions\": [[-6.34060574, -9.11874, -5.47733784, -'\n",
            "              b'6.10929585, -5.26067, 1.53467953, -3.39615297, 3.31058621, 0'\n",
            "              b'.699342728, 5.36044407], [-4.21949673, -18.1921597, 3.326071'\n",
            "              b'98, -9.3731575, -3.16625404, -28.6663227, -1.32310343, -33.0'\n",
            "              b'69149, -10.1633339, -23.68013], [-4.2460742, 8.52926, -8.014'\n",
            "              b'11533, -1.56475985, -2.09522104, -17.4982662, -8.7585, -14.3'\n",
            "              b'01878, -9.0443821, -15.0921993]\\n    ]\\n}',\n",
            "  '_content_consumed': True,\n",
            "  '_next': None,\n",
            "  'connection': <requests.adapters.HTTPAdapter object at 0x7f286db8ac10>,\n",
            "  'cookies': <RequestsCookieJar[]>,\n",
            "  'elapsed': datetime.timedelta(microseconds=64386),\n",
            "  'encoding': None,\n",
            "  'headers': {'Content-Type': 'application/json', 'Date': 'Sun, 07 Aug 2022 15:02:35 GMT', 'Content-Length': '399'},\n",
            "  'history': [],\n",
            "  'raw': <urllib3.response.HTTPResponse object at 0x7f286d9e8c10>,\n",
            "  'reason': 'OK',\n",
            "  'request': <PreparedRequest [POST]>,\n",
            "  'status_code': 200,\n",
            "  'url': 'http://localhost:8501/v1/models/mnist:predict'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def show(idx, title):\n",
        "    plt.figure()\n",
        "    plt.imshow(test_images[idx].reshape(28,28))    \n",
        "    plt.axis('off')\n",
        "    plt.title(f'\\n{title}')\n",
        "  \n",
        "# ndarray is not JSON serializable, so we have to transform \n",
        "# test_images to a regular Python list before making the HTTP request.\n",
        "\n",
        "# Check shape of data\n",
        "num_samples = 3\n",
        "test_payload = test_images[0:num_samples]\n",
        "print(f\"Shape of data passed to JSON payload: {test_payload.shape}\")\n",
        "\n",
        "if test_payload.shape[0] == 1:\n",
        "    sample_text = 'sample'\n",
        "else:\n",
        "    sample_text = 'samples'\n",
        "print(f\"shape[0] is {test_payload.shape[0]}, this means we will pass {test_payload.shape[0]} {sample_text}.\")\n",
        "\n",
        "HR()\n",
        "\n",
        "img_data = test_payload.tolist()\n",
        "\n",
        "# Show just a tiny subset\n",
        "data = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": img_data\n",
        "})\n",
        "\n",
        "\n",
        "headers = {\n",
        "    \"Content-type\": \"application_json\"\n",
        "}\n",
        "\n",
        "json_response = requests.post(\n",
        "    f'http://localhost:8501/v1/models/{model_name}:predict',\n",
        "    data=data,\n",
        "    headers=headers\n",
        ")\n",
        "\n",
        "# the JSON object must be str, bytes or bytearray, not Response\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "\n",
        "for i in range(0, num_samples):\n",
        "    forecast = class_names[np.argmax(predictions[i])]\n",
        "    forecast_class = np.argmax(predictions[i])\n",
        "    actual = class_names[test_labels[i]]\n",
        "    actual_class = test_labels[i]\n",
        "    show(\n",
        "        i, \n",
        "        f\"\"\"Predicted: {forecast} (class {forecast_class})\\nActual: {actual} (class {actual_class})\"\"\"\n",
        "    )\n",
        "    \n",
        "print(\"Properties of response:\\n\")\n",
        "pp.pprint(json_response.__dict__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name=\"9.0\"></a>\n",
        "# 9. End and clean up processes\n",
        "<a href=\"#top\">[back to top]</a>"
      ],
      "metadata": {
        "id": "zzSUOUdQyTiv"
      },
      "id": "zzSUOUdQyTiv"
    },
    {
      "cell_type": "code",
      "source": [
        "!killall tensorflow_model_server -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSZdk8UyW2v",
        "outputId": "a10cad92-b01c-4352-b647-a453eec86f01"
      },
      "id": "McSZdk8UyW2v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Killed tensorflow_model_server(1265) with signal 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6a39bc-4e41-4d9d-8491-490b00a3cc89",
      "metadata": {
        "id": "3c6a39bc-4e41-4d9d-8491-490b00a3cc89"
      },
      "source": [
        "---\n",
        "## Content Attribution\n",
        "\n",
        "Portions of this page are modifications based on work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License.\n",
        "\n",
        "This notebook is originally based on [Train and serve a TensorFlow model with TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), created by Google."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a43fed-386a-4f04-b670-3f13ca4a50d3",
      "metadata": {
        "id": "b0a43fed-386a-4f04-b670-3f13ca4a50d3"
      },
      "source": [
        "## Code Attribution\n",
        "\n",
        "Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abc4f90-c2cb-412f-8574-d3f48f879cf9",
      "metadata": {
        "id": "9abc4f90-c2cb-412f-8574-d3f48f879cf9"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ihWi7DY7y0g0"
      },
      "id": "ihWi7DY7y0g0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of 03_tfserver_mnist_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}