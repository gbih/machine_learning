{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cf4736-2749-4110-a6c3-753350bf2f79",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<a name=\"top\"></a><!--Need for Colab-->\n",
    "# Quick introduction to TensorFlow Serving\n",
    "\n",
    "## MNIST CNN Model\n",
    "\n",
    "Use Docker, subprocess module, trained / saved / loaded MNIST model, TensorFlow ModelServer APIs, and HTTP requests-logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9173c60-1fa4-4d9d-9ad6-eea616ec867e",
   "metadata": {},
   "source": [
    "1. [Setup](#setup)\n",
    "2. [Introduction](#2.0)\n",
    "3. [Using subprocess with TensorFlow Serving](#3.0)\n",
    "4. [Train, save and load a MNIST model](#4.0)\n",
    "    * 4.1 [Inspect the SavedModel Signature](#4.1)\n",
    "5. [HTTP Request Logging for TensorFlow Serving](#5.0)\n",
    "6. [Running a minimal Docker image with TensorFlow Serving](#6.0)\n",
    "7. [Subprocess to write logs to file](#7.0)\n",
    "    * [7.1 Verify logs](#7.1)\n",
    "8. [RESTful APIs](#8.0)\n",
    "    * [8.1 Model status API](#8.1)\n",
    "    * [8.2 Model Metadata API](#8.2)\n",
    "    * [8.3 Predict API](#8.3)\n",
    "    * [8.4 Classify and Regress API](#8.4)\n",
    "9. [Miscellaneous](#9.0)\n",
    "10. [End and clean up processes](#10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060391a-78ad-4cdf-9618-d08a5f45a2cf",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"setup\"></a>\n",
    "# 1. Setup\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60da2bc3-2fc7-46e4-9641-14a5c91a6f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.8.12\n",
      "IPython version      : 7.34.0\n",
      "\n",
      "matplotlib: 3.5.1\n",
      "numpy     : 1.22.4\n",
      "requests  : 2.27.1\n",
      "tensorflow: 2.9.1\n",
      "\n",
      "Finished loading packages..\n"
     ]
    }
   ],
   "source": [
    "# stdlib imports\n",
    "import asyncio\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# third party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# For debugging, provides version & hardware info\n",
    "try:\n",
    "    %load_ext watermark\n",
    "except ImportError:\n",
    "    print(\"Installing watermark:\")\n",
    "    !pip install watermark -q\n",
    "    %load_ext watermark\n",
    "finally:\n",
    "    %watermark --python --packages matplotlib,numpy,requests,tensorflow\n",
    "    \n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "def HR():\n",
    "    print(\"-\"*40)\n",
    "\n",
    "print(\"Finished loading packages..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affb1a3-927d-4ea0-aeba-3d2bccf15d68",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"2.0\"></a><a name=\"2.0\"></a>\n",
    "# 2. Introduction\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We explore these tasks here:\n",
    "\n",
    "* Using subprocess with TensorFlow Serving.\n",
    "* HTTP Request Logging for TensorFlow Serving.\n",
    "* Train / save / load the MNIST model.\n",
    "* Running a minimal Docker image with TensorFlow Serving.\n",
    "* Subprocess to write logs to file.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://tf.wiki/en/deployment/serving.html#en-call-serving-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c9298-c5f8-4477-b227-62b626e61ff0",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"3.0\"></a><a name=\"3.0\"></a>\n",
    "# 3. Using subprocess with TensorFlow Serving\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "\n",
    "\n",
    "A convenient way to use TensorFlow Serving is via Docker. We can operate the server and logging functions via Docker Commands on the CLI, but there are certain advantages (readability, maintenance, security, etc) to wrapping them in Python.\n",
    "\n",
    "The older method of doing this involved using either os.system or os.spawn*. Here, we will instead use the newer subprocess module. This allows us to spawn new processes, connect to their input/output/error pipes, and optionally obtain their return codes. This is a safer analog to os.system().\n",
    "\n",
    "The underlying process creation and management in `subprocess` is done by the [Popen Constructor](https://docs.python.org/3/library/subprocess.html#popen-constructor), `subprocess.Popen`. The underlying Popen interface can be used directly and offers the most flexibility. By default it results in a non-blocking call.\n",
    "\n",
    "Once you've created the Popen instance, some options are:\n",
    "* `wait()`:  to pause until the subprocess has exited.\n",
    "* `poll()`: check if it's exited without pausing.\n",
    "* `communicate()`: interact with process\n",
    "    - Send data to stdin. \n",
    "    - Read data from stdout and stderr, until end-of-file is reached. \n",
    "    - Wait for process to terminate and set the returncode attribute. \n",
    "\n",
    "\n",
    "**Popen Constructor:**\n",
    "\n",
    "<sup>\n",
    "\n",
    "```bash\n",
    "class subprocess.Popen(\n",
    "    args, \n",
    "    bufsize=- 1, \n",
    "    executable=None, \n",
    "    stdin=None, \n",
    "    stdout=None, \n",
    "    stderr=None, \n",
    "    preexec_fn=None, \n",
    "    close_fds=True, \n",
    "    shell=False, \n",
    "    cwd=None, \n",
    "    env=None, \n",
    "    universal_newlines=None, \n",
    "    startupinfo=None, \n",
    "    creationflags=0, \n",
    "    restore_signals=True, \n",
    "    start_new_session=False, \n",
    "    pass_fds=(), \n",
    "    *, \n",
    "    group=None, \n",
    "    extra_groups=None, \n",
    "    user=None, \n",
    "    umask=- 1, \n",
    "    encoding=None, \n",
    "    errors=None, \n",
    "    text=None, \n",
    "    pipesize=- 1\n",
    ")\n",
    "\n",
    "```\n",
    "<br>\n",
    "</sup>\n",
    "    \n",
    "A convenience function built upon the underlying Popen interface is `subprocess.run`. This is a blocking call, as it waits for the command(s) to complete, then return a CompletedProcess instance.\n",
    "\n",
    "There are older high-level APIs, existing prior to Python 3.5. The functionality provided by them has been superceded by `subprocess.Popen` and `subprocess.run`:\n",
    "\n",
    "* `subprocess.call`\n",
    "* `subprocess.check_call`\n",
    "* `subprocess.check_output`\n",
    "\n",
    "\n",
    "**Useful resources on subprocess:**\n",
    "\n",
    "- https://peps.python.org/pep-0324/\n",
    "- https://docs.python.org/3/whatsnew/2.4.html#pep-324-new-subprocess-module\n",
    "- https://docs.python.org/3/library/subprocess.html\n",
    "- https://www.bogotobogo.com/python/python_subprocess_module.php\n",
    "- https://qiita.com/HidKamiya/items/e192a55371a2961ca8a4 (JP)\n",
    "- https://www.programcreek.com/python/example/50/subprocess.Popen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b1648-bc50-4321-82c1-95343ae187f2",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"4.0\"></a><a name=\"4.0\"></a>\n",
    "# 4. Train, save and load a MNIST model\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Here, we will train and save a CNN model for the MNIST dataset, then use Docker to deploy TensorFlow Serving to host this model.  We then make POST HTTP request with a JSON payload that contain test data. TensorFlow Serving will then make inferences, predicting the most probable image from among 10 categories.\n",
    "\n",
    "Reference:\n",
    "* https://www.tensorflow.org/tfx/tutorials/serving/rest_simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d71035a-89d5-4f36-9273-1bfe3acd9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir:\t/Users/gb/Desktop/tf_server_01/tf_server_data01\n",
      "model_name:\tmnist\n"
     ]
    }
   ],
   "source": [
    "# Define model_name and model_dir (used to start the Docker container)\n",
    "model_saved = 'tf_server_data01'\n",
    "\n",
    "# Create pathlib.PosixPath with fullpath via .resolve\n",
    "model_dir = (Path() / model_saved).resolve()\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = 'mnist'\n",
    "\n",
    "print(f\"model_dir:\\t{model_dir}\")\n",
    "print(f\"model_name:\\t{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3379973-5195-442d-b4a9-94e1f194e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 11:29:54.410292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 6s - loss: 0.5687 - sparse_categorical_accuracy: 0.8002 - 6s/epoch - 3ms/step\n",
      "Epoch 2/5\n",
      "1875/1875 - 5s - loss: 0.4552 - sparse_categorical_accuracy: 0.8416 - 5s/epoch - 3ms/step\n",
      "Epoch 3/5\n",
      "1875/1875 - 5s - loss: 0.4206 - sparse_categorical_accuracy: 0.8534 - 5s/epoch - 3ms/step\n",
      "Epoch 4/5\n",
      "1875/1875 - 5s - loss: 0.3921 - sparse_categorical_accuracy: 0.8619 - 5s/epoch - 2ms/step\n",
      "Epoch 5/5\n",
      "1875/1875 - 5s - loss: 0.3645 - sparse_categorical_accuracy: 0.8711 - 5s/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/gb/Desktop/tf_server_01/tf_server_data01/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/gb/Desktop/tf_server_01/tf_server_data01/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "Saved model:\n",
      " 12K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/keras_metadata.pb\n",
      "168K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/variables/variables.data-00000-of-00001\n",
      "4.0K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/variables/variables.index\n",
      "172K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/variables\n",
      " 76K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/saved_model.pb\n",
      "  0B\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1/assets\n",
      "260K\t/Users/gb/Desktop/tf_server_01/tf_server_data01/1\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Rescale to [0.0 .. 1.0]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape for feeding into the model\n",
    "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
    "test_images = test_images.reshape(test_images.shape[0],28,28,1)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        input_shape=(28,28,1),\n",
    "        filters=8,\n",
    "        kernel_size=3,\n",
    "        strides=2,\n",
    "        activation='relu',\n",
    "        name='conv1'\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, name='dense')\n",
    "])\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "hist = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=epochs,\n",
    "    verbose=2\n",
    ")\n",
    "                \n",
    "version = 1\n",
    "export_path = Path() / model_dir / str(version)\n",
    "\n",
    "\n",
    "# We will manually save the model here, in SavedModel format.\n",
    "# This creates a protobuf file in a structured directory hierarchy, and includes a version number.\n",
    "# The model signature is defined by the input and output tensors, and stored with the serving_default key.\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "HR()\n",
    "\n",
    "print(\"\\nSaved model:\")\n",
    "!du -ah {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b98257e-a977-4514-a33b-84508df70088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gb/Desktop/tf_server_01/tf_server_data01/1\n"
     ]
    }
   ],
   "source": [
    "# Find the newest saved-model version\n",
    "model_newest = max(glob.glob(f\"{model_dir}/*\"))\n",
    "print(model_newest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0ee70-0146-4e88-bdbe-889919760525",
   "metadata": {},
   "source": [
    "<a id='4.1'></a><a name='4.1'></a>\n",
    "## 4.1 Inspect the SavedModel Signature\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We can use the tool `saved_model_cli` to inspect the SignatureDefs (the callable methods) of a model. This allows us to confirm the input Tensor dtype and shape matches the model.\n",
    "\n",
    "Resources:\n",
    "* https://github.com/tensorflow/docs/blob/master/site/en/r1/guide/saved_model.md#cli-to-inspect-and-execute-savedmodel\n",
    "* https://www.tensorflow.org/guide/saved_model\n",
    "* https://blog.tensorflow.org/2021/03/a-tour-of-savedmodel-signatures.html\n",
    "* https://www.tensorflow.org/tfx/tutorials/serving/rest_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f75ab46-09c2-4e10-9659-077b618ae992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tag-sets in the latest SavedModel:\n",
      "----------------------------------------\n",
      "The given SavedModel contains the following tag-sets:\n",
      "'serve'\n"
     ]
    }
   ],
   "source": [
    "print(\"All tag-sets in the latest SavedModel:\")\n",
    "HR()\n",
    "!saved_model_cli show --dir {model_newest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29eb665c-a926-4902-a6a1-dfba94f14500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All available SignatureDef keys in the MetaGraphDef specified by tag-set 'serve':\n",
      "----------------------------------------\n",
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "print(\"All available SignatureDef keys in the MetaGraphDef specified by tag-set 'serve':\")\n",
    "HR()\n",
    "!saved_model_cli show --dir {model_newest} --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff04ef97-4304-462f-af64-b6aaca910959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All inputs and outputs TensorInfo for the specific SignatureDef 'serving_default' in the MetaGraph:\n",
      "Note that shape: (-1) implies 1-D shape for inference data, eg {'examples': [{...}]}\n",
      "----------------------------------------\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['conv1_input'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 28, 28, 1)\n",
      "      name: serving_default_conv1_input:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "print(\"All inputs and outputs TensorInfo for the specific SignatureDef 'serving_default' in the MetaGraph:\")\n",
    "print(\"Note that shape: (-1) implies 1-D shape for inference data, eg {'examples': [{...}]}\")\n",
    "HR()\n",
    "\n",
    "!saved_model_cli show --dir {model_newest} \\\n",
    "--tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68ef7ad-c63f-4ae4-9df5-7be048ee57cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All available information in the SavedModel:\n",
      "----------------------------------------\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['conv1_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: serving_default_conv1_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv1_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "print(\"All available information in the SavedModel:\")\n",
    "HR()\n",
    "!saved_model_cli show --dir {model_newest} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b96831a-b115-436f-9acb-bafe2afb42f9",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"5.0\"></a><a name=\"5.0\"></a>\n",
    "# 5. HTTP Request Logging for TensorFlow Serving\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "* The easiest way to enable logging for TensorFlow-Model-Serving is via environment variables. This is not specific to TensorFlow Serving, but general to TensorFlow.\n",
    "\n",
    "* `TF_CPP_MIN_VLOG_LEVEL` enables logging of the main C++ backend. However, even the lowest setting of `TF_CPP_MIN_VLOG_LEVEL=1` results in too much noise.\n",
    "\n",
    "* `TF_CPP_VMODULE` provides a way to constrain logging to specific modules or source files. The general format is `TF_CPP_VMODULE=<module_name>=1`, where the module name can be either the C++ or Python file name (without the extension).\n",
    "\n",
    "* Here, we can activate logging individually for http_server.cc via \n",
    "`TF_CPP_VMODULE=http_server=1`. This will enable simple HTTP request logging and errors.\n",
    "\n",
    "* To use this with Docker, we pass it as an environmental variable:  `--env TF_CPP_VMODULE=http_server=1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089282c-ff60-40ff-a90b-4f31f7085ddd",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"6.0\"></a>\n",
    "# 6. Running a minimal Docker image with TensorFlow Serving\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "* This is the original Docker command-line format.\n",
    "\n",
    "* `docker run` also pulls a docker image (or repository) from the docker registry, if it doesn't already exist locally.\n",
    "\n",
    "\n",
    "This docker image features\n",
    "\n",
    "* Port 8500 exposed for gRPC\n",
    "* Port 8501 exposed for the REST API\n",
    "* Optional environment variable MODEL_NAME (defaults to model)\n",
    "* Optional environment variable MODEL_BASE_PATH (defaults to /models)\n",
    "\n",
    "---\n",
    "\n",
    "It can be easier to first to experiment and set up the Docker cli-commands first, then later wrap with subprocess.Popen in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbeb4a9-b1e1-475a-897c-b7d3a83d0569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "docker run \\\n",
      "--rm --tty -p 8500:8500 -p 8501:8501 \\\n",
      "--name mnist \\\n",
      "--mount type=bind,source=/Users/gb/Desktop/tf_server_01/tf_server_data01,target=/models/mnist \\\n",
      "--env MODEL_NAME=mnist \\\n",
      "--env TF_CPP_VMODULE='http_server=1' \\\n",
      "--detach \\\n",
      "--log-driver=json-file \\\n",
      "--log-opt=mode=non-blocking \\\n",
      "tensorflow/serving:latest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd_cli = f\"\"\"\n",
    "docker run \\\\\n",
    "--rm --tty -p 8500:8500 -p 8501:8501 \\\\\n",
    "--name {model_name} \\\\\n",
    "--mount type=bind,source={model_dir},target=/models/{model_name} \\\\\n",
    "--env MODEL_NAME={model_name} \\\\\n",
    "--env TF_CPP_VMODULE='http_server=1' \\\\\n",
    "--detach \\\\\n",
    "--log-driver=json-file \\\\\n",
    "--log-opt=mode=non-blocking \\\\\n",
    "tensorflow/serving:latest\n",
    "\"\"\"\n",
    "\n",
    "print(cmd_cli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9427b25-0a8c-4064-a4d5-facc4242c010",
   "metadata": {},
   "source": [
    "---\n",
    "For more feedback, run these commands in different terminals before instantiating the Docker container:\n",
    "\n",
    "```bash\n",
    "$ watch docker ps\n",
    "$ docker logs -f mnist\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a385010-45b1-4665-b44f-244cbd538cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_docker():  \n",
    "        \n",
    "    cmd=f\"\"\"\n",
    "docker run\n",
    "--rm --tty -p 8500:8500 -p 8501:8501\n",
    "--name {model_name}\n",
    "--mount type=bind,source={model_dir},target=/models/{model_name}\n",
    "--env MODEL_NAME={model_name}\n",
    "--env TF_CPP_VMODULE='http_server=1'\n",
    "--detach\n",
    "--log-driver=json-file\n",
    "--log-opt=mode=non-blocking\n",
    "tensorflow/serving:latest\n",
    "\"\"\"\n",
    "           \n",
    "    try:\n",
    "        proc = subprocess.Popen(\n",
    "            shlex.split(cmd),\n",
    "            stdout = subprocess.PIPE,\n",
    "            stderr = subprocess.PIPE\n",
    "        )\n",
    "        \n",
    "        # The communicate() method returns a tuple (stdoutdata, stderrdata)\n",
    "        # It only reads data from stdout and stderr.\n",
    "        out, err = proc.communicate()\n",
    "        out = out.decode()\n",
    "        err = err.decode()\n",
    "        print(f\"out: {(out.strip())}\")\n",
    "        \n",
    "        if err:\n",
    "            print(f\"err: {err}\")\n",
    "                \n",
    "        HR()\n",
    "        \n",
    "        sleep_time = 0.5 # Small time delay for docker instance to start up\n",
    "        time.sleep(sleep_time)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Subprocess error: {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "    return proc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e9fff1-8e7d-44e6-97ff-654933524083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: fc81a987ec378232a65415cde70ea1834003be641c035588e9e04e950190517d\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TFS with our model \n",
    "proc = server_docker() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a27e02-1b25-4e57-b559-89abe79672ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If need to immediately kill and remove unused containers/networks/images\n",
    "# !docker kill {model_name} && docker system prune --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b6e0c-c033-4d7e-8bf0-352cdb5ce426",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "<a name=\"7.0\"></a>\n",
    "# 7. Subprocess to write logs to file\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "We can always access logs via `docker logs <container name>` on the CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fd673b-6cf8-46f1-8a31-45eb0deb06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-08 02:31:32.652551: I tensorflow_serving/model_servers/server.cc:367] Profiler service is enabled\n",
      "2022-08-08 02:31:32.654519: I tensorflow_serving/model_servers/server.cc:393] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-08-08 02:31:32.655533: I tensorflow_serving/model_servers/server.cc:414] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
     ]
    }
   ],
   "source": [
    "!docker logs --tail 5 {model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83881179-2452-4a25-8f8c-ed0fdd7710cf",
   "metadata": {},
   "source": [
    "---\n",
    "We can also create a subprocess that redirects the logs to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d07d828a-39a5-441f-b723-771f9279546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_docker_process(log_file):  \n",
    "    cmd = f\"docker logs --follow {model_name}\"   \n",
    "    try:\n",
    "        proc = subprocess.Popen(\n",
    "            shlex.split(cmd),\n",
    "            stdout=open(log_file, 'w'),\n",
    "            stderr=subprocess.STDOUT, # redirect to stdout\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff894074-69a5-405e-b659-2090bbc310f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file: mnist_tfs.log\n",
      "  0B\tmnist_tfs.log\n"
     ]
    }
   ],
   "source": [
    "log_file = f\"{model_name}_tfs.log\"\n",
    "print(f\"log_file: {log_file}\")\n",
    "\n",
    "log_docker_process(log_file)\n",
    "\n",
    "!du -hs {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620f920-a617-48a1-a303-d35989687337",
   "metadata": {},
   "source": [
    "<a name=\"7.1\"></a>\n",
    "## 7.1 Verify logs\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Check that requests are being logged to the log file via the subprocess `log_docker_process`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec459889-242e-494e-8a81-002b21215b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> TFS Status : Mon, 08 Aug 2022 02:31:33 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:33 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:33 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:34 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:34 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:34 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:34 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:35 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:35 GMT <Response [200]>\n",
      "===> TFS Status : Mon, 08 Aug 2022 02:31:35 GMT <Response [200]>\n",
      "----------------------------------------\n",
      "8.0K\tmnist_tfs.log\n",
      "----------------------------------------\n",
      "2022-08-08 02:31:33.530977: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:33.759751: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:33.997402: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:34.256851: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:34.480444: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:34.694666: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:34.917989: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:35.140432: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:35.363754: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n",
      "2022-08-08 02:31:35.582534: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    \n",
    "    try:\n",
    "        resp_data = requests.get(f'http://localhost:8501/v1/models/{model_name}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(f\"===> TFS Status : {resp_data.headers['Date']} {resp_data}\")\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "HR()\n",
    "    \n",
    "!du -h {log_file}\n",
    "HR()\n",
    "!tail -10 {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34158591-58d2-4773-a110-43fd22b0bcbc",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"8.0\"></a>\n",
    "# 8. RESTful APIs\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "Send requests with TensorFlow ModelServer RESTful APIs\n",
    "\n",
    "Reference:\n",
    "\n",
    "* https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/api_rest.md\n",
    "* https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py#L520"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eff0c8-1f95-48e5-ad60-2fd14f44d0c0",
   "metadata": {},
   "source": [
    "<a name=\"8.1\"></a>\n",
    "## 8.1 Model status API\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "* Returns the status of a model in the ModelServer.\n",
    "* If successful, returns a JSON representation of `GetModelStatusResponse` protobuf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e6f8574-39aa-4583-b29b-64c20bbd0376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'model_version_status': [ { 'state': 'AVAILABLE',\n",
      "                              'status': { 'error_code': 'OK',\n",
      "                                          'error_message': ''},\n",
      "                              'version': '1'}]}\n",
      "----------------------------------------\n",
      "2022-08-08 02:31:36.099137: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist body: 0 bytes.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resp_data = requests.get(f'http://localhost:8501/v1/models/{model_name}')\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "pp.pprint(resp_data.json())\n",
    "\n",
    "HR()\n",
    "!tail -1 {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccd21e-248d-494f-8ed5-909c5eb63453",
   "metadata": {},
   "source": [
    "<a name=\"8.2\"></a>\n",
    "## 8.2 Model Metadata API\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "* Returns the metadata of a model in the ModelServer. For example, we can inspect the details of the input and output tensors.\n",
    "* Returns a JSON representation of `GetModelMetadataResponse` protobuf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8171c20-aaf8-4324-827e-6ffc18026c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"{'model_spec': {'name': 'mnist', 'signature_name': '', 'version': '1'}, \"\n",
      " \"'metadata': {'signature_def': {'signature_def': {'serving_default': \"\n",
      " \"{'inputs': {'conv1_input': {'dtype': 'DT_FLOAT', 'tensor_shape': {'dim': \"\n",
      " \"[{'size': '-1', 'name': ''}, {'size': '28', 'name': ''}, {'size': '28', \"\n",
      " \"'name': ''}, {'size': '1', 'name': ''}], 'unknown_rank': False}, 'name': \"\n",
      " \"'serving_default_conv1_input:0'}}, 'outputs': {'dense': {'dtype': \"\n",
      " \"'DT_FLOAT', 'tensor_shape': {'dim': [{'size': '-1', 'name': ''}, {'size': \"\n",
      " \"'10', 'name': ''}], 'unknown_rank': False}, 'name': \"\n",
      " \"'StatefulPartitionedCall:0'}}, 'method_name': 'tensorflow/serving/predict'}, \"\n",
      " \"'__saved_model_init_op': {'inputs': {}, 'outputs': {'__saved_model_init_op': \"\n",
      " \"{'dtype': 'DT_INVALID', 'tensor_shape': {'dim': [], 'unknown_rank': True}, \"\n",
      " \"'name': 'NoOp'}}, 'method_name': ''}}}}}\")\n",
      "----------------------------------------\n",
      "HTTP request log output:\n",
      "\n",
      "2022-08-08 02:31:36.270775: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: GET /v1/models/mnist/metadata body: 0 bytes.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resp_data = requests.get(f'http://localhost:8501/v1/models/{model_name}/metadata')\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "json_dump = (resp_data.json())\n",
    "pp.pprint(repr(json_dump))\n",
    "\n",
    "HR()\n",
    "\n",
    "print(\"HTTP request log output:\\n\")\n",
    "!tail -1 {log_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b292fa-d5ae-48dc-a66b-82608aa04410",
   "metadata": {},
   "source": [
    "<a name=\"8.3\"></a>\n",
    "## 8.3 Predict API\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "* The request body for predict API must be JSON object formatted as follows (for clarity, it may be easier to always include the \"signature_name\" field):\n",
    "\n",
    "```bash\n",
    "{\n",
    "  // (Optional) Serving signature to use.\n",
    "  // If unspecifed default serving signature is used.\n",
    "  \"signature_name\": <string>,\n",
    "\n",
    "  // Input Tensors in row (\"instances\") or columnar (\"inputs\") format.\n",
    "  // A request can have either of them but NOT both.\n",
    "  \"instances\": <value>|<(nested)list>|<list-of-objects>\n",
    "  \"inputs\": <value>|<(nested)list>|<object>\n",
    "}\n",
    "```\n",
    "\n",
    "* The predict request returns a JSON object in response body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d703b5-f1da-4855-a48f-ee7b7beb30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data passed to JSON payload: (1, 28, 28, 1)\n",
      "{\n",
      "    \"predictions\": [[-8.13978, -8.8744688, -5.46380091, -5.25820065, -6.30528641, 2.06250715, -3.4312284, 4.34305763, 1.11544907, 6.01798868]\n",
      "    ]\n",
      "}\n",
      "----------------------------------------\n",
      "HTTP request log output:\n",
      "\n",
      "2022-08-08 02:31:36.501953: I tensorflow_serving/model_servers/http_server.cc:162] Processing HTTP request: POST /v1/models/mnist:predict body: 9585 bytes.\n"
     ]
    }
   ],
   "source": [
    "# Command line\n",
    "\n",
    "# Check shape of data\n",
    "num_samples = 1\n",
    "test_payload = test_images[0:num_samples]\n",
    "print(f\"Shape of data passed to JSON payload: {test_payload.shape}\")\n",
    "\n",
    "# Show just a tiny subset\n",
    "img_data = test_payload.tolist()\n",
    "data = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": img_data\n",
    "})\n",
    "\n",
    "!curl -d '{data}' \\\n",
    "    -H 'cache-control: no-cache' \\\n",
    "    -X POST http://localhost:8501/v1/models/mnist:predict\n",
    "\n",
    "print()\n",
    "HR()\n",
    "\n",
    "print(\"HTTP request log output:\\n\")\n",
    "!tail -1 {log_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2622ab20-f515-4bd7-891c-2bfbf38d66fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data passed to JSON payload: (3, 28, 28, 1)\n",
      "shape[0] is 3, this means we will pass 3 samples.\n",
      "----------------------------------------\n",
      "Properties of response:\n",
      "\n",
      "{ '_content': b'{\\n    \"predictions\": [[-8.13977814, -8.87447071, -5.46380186'\n",
      "              b', -5.2582, -6.30528688, 2.06250668, -3.43122959, 4.34305859,'\n",
      "              b' 1.11544895, 6.01798868], [-3.00336146, -10.0945168, 2.55970'\n",
      "              b'287, -7.78681707, 0.0381838679, -27.8272285, -0.0862028897, '\n",
      "              b'-35.2029839, -7.38741636, -22.3393478], [-1.56377709, 12.431'\n",
      "              b'6368, -5.56736517, 0.135994464, -0.749776959, -16.9869976, -'\n",
      "              b'5.71387768, -14.4298296, -4.49142742, -13.6879396]\\n    ]\\n}',\n",
      "  '_content_consumed': True,\n",
      "  '_next': None,\n",
      "  'connection': <requests.adapters.HTTPAdapter object at 0x12f87db20>,\n",
      "  'cookies': <RequestsCookieJar[]>,\n",
      "  'elapsed': datetime.timedelta(microseconds=11380),\n",
      "  'encoding': 'utf-8',\n",
      "  'headers': {'Content-Type': 'application/json', 'Date': 'Mon, 08 Aug 2022 02:31:36 GMT', 'Content-Length': '418'},\n",
      "  'history': [],\n",
      "  'raw': <urllib3.response.HTTPResponse object at 0x12f85afd0>,\n",
      "  'reason': 'OK',\n",
      "  'request': <PreparedRequest [POST]>,\n",
      "  'status_code': 200,\n",
      "  'url': 'http://localhost:8501/v1/models/mnist:predict'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAEVCAYAAAAb2fKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZqUlEQVR4nO3deZxcVZUH8N+pXtJZOmmykAWSIAlJ2MIiu7IJEkYWwRlEArK4DDg6KCriwhAdFfGjyCKDCI7gsCSCzodRBARlWBUISMABAiFgCAlJOksn3UmadHed+ePeSh5FvXM7XUn6tPy+n08+6a5T771br/q87b5zn6gqiMifQm83gIgqY3ISOcXkJHKKyUnkFJOTyCkmJ5FTTE4ip5icRE4xOYmcYnISOcXkJHKKyUnkFJOTyCkmJ5FTTE4ip5icRE4xOYmcYnISOcXkJHKKyUnkFJOTyKm/++QUkZtE5Dvx50NF5KVttFwVkYlbeRlHiMgbmd//JiJHb81ldpeIfE9EvtCN9z0oIp/aBk1KEpHLReQzvd2OEhfJGf+o1otIm4gsjQk1aEsvR1UfUdXJ3WjP2SLy6JZevrG8B0WkPX7+5SLy3yIyelstf0sTkREAzgTw095uS5aIHCQi94vIShFpFpE7ytbzDwF8XUTqe6uNWS6SMzpBVQcB2BfAfgAuLn+DiNRu81ZtO5+Ln38SgCYAV/Ruc9IkqPQ3dDaAu1V1/TZuUsp2AK4HsBOA8QBaAdxYCqrqmwDmAjixNxpXzlNyAgBUdRGAewDsAWw8PPysiMwDMC++dryIzBGRFhH5k4hMLU0vIvuIyF9EpFVEfgmgIRMrPwwcG/dSzSKyQkSuEZFdAVwH4OC4J2uJ7+0nIj8Ukdfj3v06EemfmdeFIvKmiCwWkU9U8flXAvh12effeHicPUy3xPZeGduzOP7cL8ZeFJHjM++tjetg3/j7QXG9tojIsyJyROa9D4rId0XkMQDrAOxcYfH/AOChsvZ8OH5na0RkvogcW6HNE0TkgfhdLBeRW0WkKRO/SEQWxe/2JRE5Kr5+gIg8Fee9VER+VGmdqOo9qnqHqq5R1XUArgHwvrK3PQjguLz1ui25S04RGQvgQwCeybx8EoADAewmIvsA+DmAcwEMQzh0+k38Y6wHcCeAmwEMBXAHgH/MWU4NgLsALEDYku4AYJaqvgjgPAB/VtVBqtoUJ7kMYa+2N4CJ8f2XxHkdC+DLAD4IYBcAbzvvE5HpIvJcNz//8NjmZ1LvTfgGgINie/cCcAA2HY3MBHBa5r3TACxX1b+IyA4AfgfgOwjr8MsAfh0PVUs+DuCfATQirL9yewLYeG4vIgcA+C8AFyIcFRwG4G8VphMA3wMwBsCuAMYC+Gacx2QAnwOwv6o2xjaX5nEVgKtUdTCACQBur7xK3uEwAM+XvfYiwvrqfara6/8QVnIbgBaEL/taAP1jTAF8IPPenwD4dtn0LwE4HGFlLwYgmdifAHwn/nwEgDfizwcDaAZQW6E9ZwN4NPO7AFgLYELmtYMBvBZ//jmAyzKxSbHdE7v5+R9E2Au1AFgE4FYAIzKff2LmvTdV+jyZ9Xh0/Hk+gA9lYtMA/C3+PBHhkG5A/P1WAJfEny8CcHNZ+34P4KxMW/898Xk6AEzJ/P5TAFcYn/1TObGTADyTafMyhA1fXdn7HgbwLQDDN+NvbiqAlQAOLXv9gwBe7e2cUFVXe86TVLVJVcer6r/o289XFmZ+Hg/gS/GQqyUedo5F2NqOAbBI41qOKm3ZEadZoKqd3WjbCAADADydWea98XXE5WbbmLdMy/nx8++gqqeranMP5pE1pqwdC+JrUNVXEPYQJ4jIAIRzrNvi+8YDOKVs/b4fQPbCSfazVrIKYa9aMhZhY2ESkZEiMiseuq4BcAuA4Zk2fwFhT7osvm9MnPSTCBvEuSIyO3vInrOciQinTp9X1UfKwo0IG8le5yk5LdlkWwjgu/EPufRvgKrOBPAmgB1ERDLvH5czz4UAxuVcZCp/utNyAOsB7J5Z5hANF3AQlzu2G8vsiXUIG4aSUd2cbjFCopWMi6+VlA5tPwzghfjHD4T1cnPZ+h2oqpdlpk09/eo5hGQpWYhwuJlyaZz3nhoOUc9AOGoJC1W9TVXfHz+XAvh+fH2eqp4GYPv42q9EZGClBYjIeAB/QDj6urnCW3YF8Gw32rrV9ZXkzLoBwHkicmC8WjhQRI4TkUYAfwbQCeB8EakTkY8gnGtV8iRCUl0W59EgIqWLA0sB7BjPYaGqxbjcK0RkewAQkR1EZFp8/+0AzhaR3eKeaMYW/LxzAEwXkZp4bnt4N6ebCeBiERkRz2MvQdgTlcwCcAyAz2DTXhPxPSeIyLS4zIZ4IW3HzWjz3WXt/E8A54jIUSJSiOtuSoXpGhFOb1bHc98LSwERmSwiH4gXtdoRNpbFGDtDREbE76klTlIsn3mc5wMArlHV63LafjjCXrX39fZxtZadK1WIvePcDcCxAGYjfBFvIlz4aYyx/RAuprQC+GX8l3eONg7hAtIKhL3j1fH1eoSLIisRLpQA4arvpQBeBbAG4bDw/My8vgpgCcLe6RPZdgM4HcDzxud/EPnnXfshXLRoRbjQNdP4PBvXY2zv1XH9vBl/biib9x8RNmajyl4/EOFq60qE8/LfARiXamtm+uEA3kC8bhBfOxlhj9oK4BUA08rnB2B3AE8jJOgcAF/CpmsEUxE2qK2xXXcBGBNjtyCcj7bFdXVSTrtmxO+lLfsvEx8d213f2zmhquHCCdGWJiKXAlimqlf2dlu6S0QuBzBfVa/t7bYAYHISedUXzzmJ3hWYnEROMTmJnGJy9oCIfFNEbkm/s+rlbCynkm1cKWOJ3TNzJXNvcc773nYvc2+KNzi8WLq/uC/ok8kZ/2hXdXdF9+YfdvwDLUq4ib50w/Y5vdGWLeirAG5SZ1UnEgoT5sX1PFdEzizFVHUpgP9FuCe4T+hzySkiOwE4FKG/ykVpTzcs1nA30WCEe1dvEJHderlNSZXunoobxLPw9hsavFgL4AQAQxDaeJWIHJKJ34pQMNEn9LnkRCjifRzhBvCzsgHZvBKwt1Xgl+9dReQqEVkooQzpaRE5tNqGa3Anwr2nu5UfHovIThJKxJJ1qyJySLyPdHX8/5D4+qki8lTZey8Qkd/En3NL30qHoRJKs5YgU+uYcSCAFlXNlt4NFZEbJZSmrRKRO3Pa/FUJ5WKtIvKCiJyciU0UkYfi51kuodyvVDN6hYgsi9/FX0Vkj5z1O0NV56pqUVWfAPAIQoFCyRMAdpZwC597fTU5b43/ponISKBHJWApsxHKrYYi3N52h4g0VHqjiDwnItNTM4y3rp2MUDb11262o9J8hiLctXM1QtncjwD8TkSGAfgtgMkisktmkunYdItebulbNArhM49H5UPAt5WDRTcj3P+7O8L9rXmF4vMRjnqGIFSR3CKbRiL4NoD7EAqidwTw4/j6MQjVRpPidB9FuKPLFDc4+yNTEqahyOEVeCkJS+hTySkipZueb1fVpxG+7FJSHIBQdXGhqq5V1XZV7fF5pqreoqorVLVTVS8H0A9AxSFOVHWqqt5WKRaNiXvs5Qi3kH1cVasZy+g4APNU9ebYvpkIFfwnaCgi/h/Ees2YpFMQal4FIeEuUNWVqtqKcEvixzLzLgKYoapv5ZxTNiHcQoc4/9EIxdXnqeoqVe1Q1YcqTAcNhc6L457tlwjF86V7nzsQvtsxZd9dB8I9t1MQbpp5UcOIBSnXIdzA/vuy11vjZ3CvTyUnwmHsfaq6PP5+GzYd2m5OCViSiHw5Xt1bHRNrCGL5Ug8s1lDdMVRV91bVWVU2r7wcDPH3HeLPt2FTMfV0AHfGpE2VvgFAs6q2G8uuVA62UlVXpRotImfKphEsWhBGeyit068gVKA8KSLPSxxNQlUfQBix4D8QSsWuF5HBieX8IM77o/rOW+DclISl9JnkjIcpHwVwuIgsiedEFwDYS0T2wuaVgAHh4kHFUqx4fvmVuLzt4qHwamTKl7aQ3DYklJeDAeEm/kXx5/sBjBCRvRGStLRXT5W+AT0rBxsqmeFEKonneTcgjGYwLK7T/0Ncp6q6RFU/rapjEC7aXCtxeBZVvVpV3wtgt7jsCyssorScbyHsyY9R1TVlsVqEQ3kXJWEpfSY5EariuxC+oL3jv10RTvrPxGaUgEVzAHxERAbEP4JPZmKNCNUazQBqReQShCutW9ocAIeJyDgRGQLga92c7m4AkyQMf1IrIqcirJe7AEBVOxAqdX6AcP54f3w9VfrWHU8CaJJQfoV4iHkPQjJtJ6FU77AK0w1ESPzmuNxzEMdJir+fIpvK0lbF9xZFZH8J5YF1CBuzdlQoB4vz+BrCkcLRqlrpvPQAhNEgelIMv831peQ8C8CNqvp63MouUdUlCIc8pyNsgU9A2DK+jlD6c2qc9gGECwNLRKR0SHwFgA0IifsLhAtMJb9HONx7GeFwsR1G9X88DDt9cz+Qqt6PUNL2HEKp1F3dnG4FgOMRSqpWIOzlj88c7gNhb3k0gDvKDvUvQrgo8riE0Qb+gJxz6Zxlb0C4Un5G5uWPI5wbzkUo3fpCheleAHA5Qs3tUoQLS49l3rI/gCdEpA3AbxBGKXgVYaN4A0LCLoif9wc5zbsU4QjiFQlX5ttE5OuZ+OkI56J9AqtSaLNJGOzrEQD7eLsRIU88UngIoc3WObUbTE4ip/rSYS3RuwqTk8gpJieRU+Y9nB8snMIT0h6oGTbUjK85cpfc2MBfPbGlm7NZuo7cNzdWu+Ytc1p9unzwdOqO+4t3VOw/556TyCkmJ5FTTE4ip5icRE4xOYmcYnISOcXkJHIqOVbN36PCwIpPh9to/r9NNeOfPO4PZnyP/nPN+IH9fpsbW/zDGnPaqfUVR0rZYpZ3PZYbW9plb8vb1W77+S99zIwXf7F9bmzwzMfNaf8ecc9J5BSTk8gpJieRU0xOIqeYnEROMTmJnGJyEjlljiHUl+s5X77ugNzY3cdeaU67c12dGV/aZdc1LumyH37WWszvqxxV02ZOO6TQZcbrxR5at6XioJKbLO5szI3ViT1e99CCPW7WKLsbFP2MR8R8ftGR5rSvH7jWnrljrOck6mOYnEROMTmJnGJyEjnF5CRyislJ5FSfLRlbdNEhZvy1E6/NjT3cPiA3BgAL19tdKUUMMuOFyg/B2miw0eXQ3GWXszXbPSnoSjylsEvt7fHAgt1NZGku2ut1QafdxdSu+ev9mh0fNKc98Y8nm3Ec9YYdd4h7TiKnmJxETjE5iZxichI5xeQkcorJSeQUk5PIqT7bz/mzc39sxud3rM+NdegQc9qGQocZP6zK0Smf37AhN7ahaNdVrSvafYVja1vM+Igauw92zltNubF6sTtZrX5KABiaKIerQX6F4qPt/c1pr504y4yfv+OpZrzzjUVmvDdwz0nkFJOTyCkmJ5FTTE4ip5icRE4xOYmcYnISOdVn+zkn19l1hyuN7ry6RH9dqh9zwh/PMeM7X29Pf9es/DcsStSSHjvA/tyvddif7c62SWb8ff3n58ZaEn2sR/S3+1DvW2fXezZ3Dc6N7VK/xJx2ZI39p7x+t9FmvI79nETUXUxOIqeYnEROMTmJnGJyEjnF5CRyislJ5FSf7efcribRZ1bMfyRcTWJc2dQ2a/IX7TFQu5qbzXg/ye/LHFXbak575oJjzPjSg9eY8ZSOF/LrST/btNCc9kN7fsCMz7tosh0/4ye5sScTw+nWiV0Hu/j9dv/x+Pvs+fcG7jmJnGJyEjnF5CRyislJ5BSTk8gpJieRU267UgoN1Y0/2WE86m6o8Qi+wO6meWumPUxj7dGJ2Rum1tufO9VVMu+qg8x4Xav9iMA7z81fN7NG1JvT9p9kr9cJMxPdPGfkh+oT3V/tasfr9lxtL9sh7jmJnGJyEjnF5CRyislJ5BSTk8gpJieRU0xOIqfc9nPKhPGJdzxuRq1+zpE19iP+Ug4e/poZnw27fMmy34zPmPFh+LMZn3STXXJWWJvo463Nb3vhkWfsSXfeyYzr6urK2apx1LiXzfiL26gdm4N7TiKnmJxETjE5iZxichI5xeQkcorJSeQUk5PIKbf9nO2jB221eTcW7I/dVrT7Ao8Z/FczPrvw3s1uU8nIe+3hJzsT0589624z/rHGVWZ8zlv5Y1B+8dzPmtPe9LMrzfj3lh1pxl/vbMuNpYa+XFe0H314aGOqn3NnM94buOckcorJSeQUk5PIKSYnkVNMTiKnmJxETjE5iZxy28/ZOtYeIzWlINrjaRd32X1mhyWG1P1uos9t2pi9c2OyX5M57YLLtzPjN9pP2cONsOtkT34h//GFK3a1v5NPHXKqGX/pgrFm/OrTZufGnttg9z23FO39zLQBy8z49eznJKLuYnISOcXkJHKKyUnkFJOTyCkmJ5FTTE4ip9z2c7aPsJ8jmWKNW9svURs4QOyqSavuEADmXXOgGdfa/D7YTx/ykDntvcNfMuMX/mUfM75Tw3Izfl7TotzYlPOvM6f9/g32s0HH7NHzvusGsfuOre8bAAYVqnvea2/gnpPIKSYnkVNMTiKnmJxETjE5iZxichI55bYrZf3IYlXTd2h+d0lqmMWBYm+zXuroZ8Zf/chPzbjl5Y61Zvyx9v5m/F+HP9LjZQPAw+35Q5Ie0M8u27rnlT9Vtewuzf/OGxIlgB09rxAEAEitnQramRqUdMvjnpPIKSYnkVNMTiKnmJxETjE5iZxichI5xeQkcsptP2dx+IatNu/VxfVm/PRX/smMXzfhdjN+77phZrxd63JjTQV7ezmgkP+IPgB4tWOwGU9pLOT3ZT7aPtCcdliN3Uc7v2OEGX+5fXRu7OLhc81prUcXdofsvosZ12dfrGr+PcE9J5FTTE4ip5icRE4xOYmcYnISOcXkJHKKyUnklNt+zkFD7L7IlPG1+dPfs9Z+FN3SWfZj8sbNyK95BIDFnevMuKUuMQRkDRKFi4l+0JQu5A9JOjAx76EFu296be1qM/71+07LjV083e7nrFb7KLsPt/7Zrbr4irjnJHKKyUnkFJOTyCkmJ5FTTE4ip5icRE4xOYmcctvPueMQu0/MGuMUAEbX5vdFzm57jzltw6rqBkFdU7QfN2f1FxaMfsZtoWg8Sq8h8WjE1EjDTUatKABsP9sITrfnbfXPAsCyLrvWVAu9u94r4Z6TyCkmJ5FTTE4ip5icRE4xOYmcYnISOcXkJHLKbT/nzoNWmPFVibFnh9fk1+ctam8yp105pbpt1jq1n985GHZ/nyXVn1etguT3VqaWnYrvWpc/Xi8AJB7BaUrVudYl2rZ+hJ0K9je6dXDPSeQUk5PIKSYnkVNMTiKnmJxETjE5iZxy25XSr9BhxlPlSZbZr9pDXxbfU+XwkkbZFWAPf5nqjkgOjVkla/kNiWE7V3bZpXKT6mrM+IA3e77e+yXaVpBUV4odb9rcBm0B3HMSOcXkJHKKyUnkFJOTyCkmJ5FTTE4ip5icRE657efsX2P3c7Zrz/v76l/pb8aHHbykx/MG0o/Ks6T6MVPxakvKrPnXJXqX12p9Yu52X2T9q0tzY/eus4u29u1nD32JxHrpsJ8A2Cu45yRyislJ5BSTk8gpJieRU0xOIqeYnEROMTmJnHLbz7ky0fHUrj3vzzNGfwQAnDr2aTPeVrSHtqwTu26xN9UlPnzRWK8diW15u9pDX6b6OdftMSY39nDrZHPawxqeMuOrixvMeNeArVsn2xPccxI5xeQkcorJSeQUk5PIKSYnkVNMTiKnmJxETrnt51zfZfeZNVTxvLhinT3tvv1fM+OLu+z+ugaxa1G3plQ9Z6on0tKRGI+32s+94MT8/uH2JbuY087Y3u6btr8xoKMp9Y5tj3tOIqeYnEROMTmJnGJyEjnF5CRyislJ5JTbrpS3uuymDS+khmHMV9xlnRlvSgxtmXrU3cBEl8IGY5tY7SP+qh1as1jF0JrprhR7X9A0tiU31vz8CHPafnvZnURFJIYrra3moZJbB/ecRE4xOYmcYnISOcXkJHKKyUnkFJOTyCkmJ5FTbvs52zrtR77VSM/744Y1tZnxkTV2n1dL0V621Y+Z0qH2sJqpnsRUyVgqXjTKwgqJYTVTfagvd9iP6fvGlHtyY1+ZP92cNqUr0X1c058lY0TUTUxOIqeYnEROMTmJnGJyEjnF5CRyislJ5JTbfs71nXZ93tIuuz5vXG3+9P2uHmrP+yf2NmtUjV0P2p7oqzQlum/T/ZR2vJAaUlTy+/sajBiQ/twTavub8XNfPjI3ttNdiR7eU+1we2JYz9q6TnsGvYB7TiKnmJxETjE5iZxichI5xeQkcorJSeQUk5PIKbf9nMMa7Nq/9kR/XluxPTdWrLennd0+3oyfPXiZGb+1dZgZr5Ot16dW9bi3Rs3mhkQ/5rqiXYM7td5eb4uWN+XGJi6xa3BT3kq0fe8dFpnxVVUtvWe45yRyislJ5BSTk8gpJieRU0xOIqeYnEROMTmJnHLbz/nkU5PMeONYuz+vuSu/L7HxuaXmtDOnjLHjsONUWWq9vQfP5sZ06hRz2tc67H7Q4YkS2yeenWjGJ+FJewZbAfecRE4xOYmcYnISOcXkJHKKyUnkFJOTyCm3XSkjnrLLukafMsiMry6uzw8W7UfZkT9ab/+pDq2x+0qGFOxhOWvbqhjOdCvhnpPIKSYnkVNMTiKnmJxETjE5iZxichI5xeQkcsptP2fjQvsRfzOadzfjKzbk94Pq6jU9alOJ1NWbce1MPK5O3p3bRCnYfdfaaQwZOmeuOe0Jz0834zsOajHjI5/01/f97vwrIeoDmJxETjE5iZxichI5xeQkcorJSeQUk5PIKVGt7pFxRLR1cM9J5BSTk8gpJieRU0xOIqeYnEROMTmJnPp/9LkQVsNe2PcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In Python\n",
    "\n",
    "def show(idx, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[idx].reshape(28,28))    \n",
    "    plt.axis('off')\n",
    "    plt.title(f'\\n{title}')\n",
    "  \n",
    "# ndarray is not JSON serializable, so we have to transform \n",
    "# test_images to a regular Python list before making the HTTP request.\n",
    "\n",
    "# Check shape of data\n",
    "num_samples = 3\n",
    "test_payload = test_images[0:num_samples]\n",
    "print(f\"Shape of data passed to JSON payload: {test_payload.shape}\")\n",
    "\n",
    "if test_payload.shape[0] == 1:\n",
    "    sample_text = 'sample'\n",
    "else:\n",
    "    sample_text = 'samples'\n",
    "print(f\"shape[0] is {test_payload.shape[0]}, this means we will pass {test_payload.shape[0]} {sample_text}.\")\n",
    "\n",
    "HR()\n",
    "\n",
    "img_data = test_payload.tolist()\n",
    "\n",
    "# Show just a tiny subset\n",
    "data = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": img_data\n",
    "})\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Content-type\": \"application_json\"\n",
    "}\n",
    "\n",
    "json_response = requests.post(\n",
    "    f'http://localhost:8501/v1/models/{model_name}:predict',\n",
    "    data=data,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# the JSON object must be str, bytes or bytearray, not Response\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "for i in range(0, num_samples):\n",
    "    forecast = class_names[np.argmax(predictions[i])]\n",
    "    forecast_class = np.argmax(predictions[i])\n",
    "    actual = class_names[test_labels[i]]\n",
    "    actual_class = test_labels[i]\n",
    "    show(\n",
    "        i, \n",
    "        f\"\"\"Predicted: {forecast} (class {forecast_class})\\nActual: {actual} (class {actual_class})\"\"\"\n",
    "    )\n",
    "    \n",
    "print(\"Properties of response:\\n\")\n",
    "pp.pprint(json_response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfa05c-0db6-4573-9b97-ba7e19cd472f",
   "metadata": {},
   "source": [
    "<a name=\"8.4\"></a>\n",
    "## 8.4 Classify and Regress API\n",
    "<a href=\"#top\">[back to top]</a>\n",
    "\n",
    "To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc75b1-c520-4ece-85ac-5836a01155c8",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"9.0\"></a>\n",
    "# 9. Miscellaneous\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9211b5ea-7ae9-4180-8742-325e17c83dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "HOSTNAME=fc81a987ec37\n",
      "MODEL_NAME=mnist\n",
      "TF_CPP_VMODULE=http_server=1\n",
      "MODEL_BASE_PATH=/models\n",
      "HOME=/root\n"
     ]
    }
   ],
   "source": [
    "# Check environmental variables of this container\n",
    "!docker exec {model_name} env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc70e1e-d4a8-4f83-8619-cc98ef52a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[0;32m\"MODEL_NAME=mnist\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"TF_CPP_VMODULE=http_server=1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"MODEL_BASE_PATH=/models\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Using jq:\n",
    "!docker inspect {model_name} | jq '.[] | .Config.Env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "796e8de2-21f6-44b6-a28a-5016610350d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_CPP_VMODULE\n"
     ]
    }
   ],
   "source": [
    "# As a toy example, we log into the container and check this environmental variable:\n",
    "!docker exec -it {model_name} /bin/bash | echo TF_CPP_VMODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c53de55d-3939-4e4e-868f-feb547e88e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of returned container process:\n",
      "\n",
      "_waitpid_lock -> <unlocked _thread.lock object at 0x12eab9300>\n",
      "_input -> None\n",
      "_communication_started -> True\n",
      "----------------------------------------\n",
      "args -> ['docker', 'run', '--rm', '--tty', '-p', '8500:8500', '-p', '8501:8501', '--name', 'mnist', '--mount', 'type=bind,source=/Users/gb/Desktop/tf_server_01/tf_server_data01,target=/models/mnist', '--env', 'MODEL_NAME=mnist', '--env', 'TF_CPP_VMODULE=http_server=1', '--detach', '--log-driver=json-file', '--log-opt=mode=non-blocking', 'tensorflow/serving:latest']\n",
      "----------------------------------------\n",
      "stdin -> None\n",
      "stdout -> <_io.BufferedReader name=82>\n",
      "stderr -> <_io.BufferedReader name=84>\n",
      "pid -> 20409\n",
      "returncode -> 0\n",
      "encoding -> None\n",
      "errors -> None\n",
      "text_mode -> None\n",
      "_sigint_wait_secs -> 0.25\n",
      "_closed_child_pipe_fds -> True\n",
      "_child_created -> True\n",
      "_fileobj2output -> {<_io.BufferedReader name=82>: [b'fc81a987ec378232a65415cde70ea1834003be641c035588e9e04e950190517d\\n', b''], <_io.BufferedReader name=84>: [b'']}\n"
     ]
    }
   ],
   "source": [
    "def show_tfs_dict(proc):\n",
    "    print(\"Properties of returned container process:\\n\")\n",
    "    for key in proc.__dict__:\n",
    "        if key == 'args':\n",
    "            HR()\n",
    "            print(key, '->', proc.__dict__[key])\n",
    "            HR()\n",
    "        else:\n",
    "            print(key, '->', proc.__dict__[key])\n",
    " \n",
    "show_tfs_dict(proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca736e07-ec30-4199-8db6-08dacb4502f8",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"10.0\"></a>\n",
    "# 10. End and clean up processes\n",
    "<a href=\"#top\">[back to top]</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e960478f-93f8-4cff-aa4d-0571124394e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\n",
      "Total reclaimed space: 0B\n"
     ]
    }
   ],
   "source": [
    "# Kill and remove unused containers, networks, image\n",
    "!docker kill {model_name} && docker system prune --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c3d5a-f78f-49cd-9cef-f62bf5be2e13",
   "metadata": {},
   "source": [
    "---\n",
    "## Content Attribution\n",
    "\n",
    "Portions of this page are modifications based on work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License.\n",
    "\n",
    "This notebook is originally based on [Train and serve a TensorFlow model with TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), created by Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3752af-5c40-4882-9af9-c757cc8bfa54",
   "metadata": {},
   "source": [
    "## Code Attribution\n",
    "\n",
    "Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd9b2223-eca3-4468-93e7-6911658450e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
